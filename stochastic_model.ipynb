{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pulp as plp\n",
    "import networkx as nx\n",
    "from ALB_instance_tools import *\n",
    "from report_functions import *\n",
    "from milp_models import *\n",
    "from scenario_trees import *\n",
    "from collections import namedtuple\n",
    "import glob\n",
    "import os\n",
    "import string\n",
    "import time\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from timeit import default_timer as timer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NO_TAKTS = 4\n",
    "# scenario_tree_graph, final_sequences = make_scenario_tree(NO_TAKTS, {'A':0.60, 'B':0.4})\n",
    "# restricted_graph, restricted_sequences = make_consecutive_luxury_models_restricted_scenario_tree(NO_TAKTS, {'A':0.75, 'B':0.25}, max_consecutive=3, luxury_models=['A', 'B'])\n",
    "# restricted_total = sum_prob(restricted_sequences)\n",
    "# restricted_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance_dicts = [\n",
    "#    {'fp': \"SALBP_benchmark/debugging_ds/instance_n=5_1.alb\",'name':'A', 'probability':0.75},\n",
    "#    {'fp': \"SALBP_benchmark/debugging_ds/instance_n=5_2.alb\",'name':'B', 'probability':0.25}\n",
    "# ]\n",
    "\n",
    "\n",
    "#instance_list = read_instance_folder(\"SALBP_benchmark/small data set_n=20/\")[1:3]\n",
    "# instance_dicts = [\n",
    "#    {'fp': \"SALBP_benchmark/small data set_n=20/instance_n=20_1.alb\",'name':'A', 'probability':0.75},\n",
    "#    {'fp': \"SALBP_benchmark/small data set_n=20/instance_n=20_2.alb\",'name':'B', 'probability':0.25}\n",
    "# ]\n",
    "instance_list = [ \"SALBP_benchmark/small data set_n=20/instance_n=20_1.alb\",\n",
    "   \"SALBP_benchmark/small data set_n=20/instance_n=20_3.alb\",\n",
    "   ]\n",
    "# instance_list = [ \"SALBP_benchmark/small data set_n=20/instance_n=20_1.alb\",\n",
    "#    \"SALBP_benchmark/small data set_n=20/instance_n=20_18.alb\",]\n",
    "#test_instances = create_instance_pair_stochastic(instance_list)\n",
    "\n",
    "\n",
    "# NO_EQUIPMENT = 4\n",
    "# seed = 1\n",
    "# NO_WORKERS =4\n",
    "# NO_STATIONS = 4\n",
    "# WORKER_COST = 500\n",
    "# RECOURSE_COST = WORKER_COST * 2\n",
    "# TAKT_TIME = 1000\n",
    "# SEQUENCE_LENGTH = 4\n",
    "# #MODEL_MIXTURES = {'A':0.34, 'B':0.33, 'C':0.33}\n",
    "# MODEL_MIXTURES = {'A':0.60, 'B':0.40}\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# def multi_run(instance_list, milp_model, NO_EQUIPMENT,  NO_WORKERS, \n",
    "#               NO_STATIONS, WORKER_COST, TAKT_TIME, SEQUENCE_LENGTH, MODEL_MIXTURES, seed, RECOURSE_COST = WORKER_COST * 2,\n",
    "#               scenario_generator= make_scenario_tree, file_name = 'test', **kwargs):\n",
    "#    instance_groups = pair_instances(instance_list, MODEL_MIXTURES)\n",
    "#    test_results = []\n",
    "#    group_counter = 0\n",
    "#    test_instances = []\n",
    "#    instance_results = []\n",
    "#    for group in instance_groups:\n",
    "#       test_instance = MultiModelInstance(model_dicts=group, takt_time=TAKT_TIME, sequence_length=SEQUENCE_LENGTH, max_workers=NO_WORKERS, no_stations=NO_STATIONS, worker_cost=WORKER_COST, recourse_cost=RECOURSE_COST)\n",
    "#       print('Running instance', test_instance.name)\n",
    "#       test_instances.append(test_instance)\n",
    "#       #create equipment\n",
    "#       equipment = Equipment( no_tasks= test_instance.no_tasks, no_equipment=NO_EQUIPMENT,no_stations=NO_STATIONS,generation_method='new_method', seed = seed)\n",
    "#       #create scenario tree\n",
    "#       print('generating scenario tree')\n",
    "#       scenario_tree_graph, final_sequences = scenario_generator(SEQUENCE_LENGTH, MODEL_MIXTURES, **kwargs)\n",
    "#       print('defining problem')\n",
    "#       milp_prob = milp_model(problem_instance = test_instance, equipment_instance = equipment, sequence_length=SEQUENCE_LENGTH, prod_sequences=final_sequences, **kwargs)\n",
    "#       #prob = milp_model(test_instance, equipment,test_instance.no_tasks, NO_WORKERS, NO_STATIONS, TAKT_TIME, SEQUENCE_LENGTH, final_sequences, worker_cost=WORKER_COST)\n",
    "#       solver = plp.GUROBI_CMD(options=[('TimeLimit', 300)])#\n",
    "#       milp_prob.solve(solver=solver, file_name=file_name + str(group_counter))\n",
    "#       result = milp_prob.get_obj_val_dict_old()\n",
    "#       instance_results.append(result)\n",
    "#       group_counter += 1\n",
    "#    instance_results = pd.DataFrame(instance_results)\n",
    "#    instance_results.to_csv(file_name + '_results.csv')\n",
    "#    return instance_results, test_instances\n",
    "\n",
    "# today = datetime.today().strftime('%Y_%m_%d')\n",
    "# xp_name = f\"xp_{today}_split_60_40_Debug\"\n",
    "# #makes a folder of xp_name if it does not exist already\n",
    "\n",
    "# if not os.path.exists('model_runs/'+ xp_name):\n",
    "#    os.makedirs('model_runs/'+xp_name)\n",
    "\n",
    "\n",
    "# start_time = time.time()\n",
    "# file_name = 'model_runs/'+xp_name+f'/Model_dependent_{NO_STATIONS}_E{NO_EQUIPMENT}_L{NO_WORKERS}_T{SEQUENCE_LENGTH}_C{TAKT_TIME}_LC{WORKER_COST}_'\n",
    "# results_md_df, instances_md = multi_run(instance_list, model_dependent_problem_linear_labour_recourse, NO_EQUIPMENT,  NO_WORKERS, \n",
    "#           NO_STATIONS, WORKER_COST, TAKT_TIME, SEQUENCE_LENGTH, MODEL_MIXTURES, seed, RECOURSE_COST,\n",
    "#           scenario_generator=make_scenario_tree,\n",
    "#            file_name=file_name)\n",
    "# md_time = time.time() - start_time\n",
    "# start_time = time.time()\n",
    "# file_name = 'model_runs/'+xp_name+f'/dynamic_{NO_STATIONS}_E{NO_EQUIPMENT}_L{NO_WORKERS}_T{SEQUENCE_LENGTH}_C{TAKT_TIME}_LC{WORKER_COST}_'\n",
    "# results_md_df, instances_md = multi_run(instance_list, dynamic_problem_linear_labour_recourse, NO_EQUIPMENT,  NO_WORKERS, \n",
    "#           NO_STATIONS, WORKER_COST, TAKT_TIME, SEQUENCE_LENGTH, MODEL_MIXTURES, seed, RECOURSE_COST,\n",
    "#           scenario_generator=make_scenario_tree,\n",
    "#            file_name=file_name)\n",
    "# dynamic_time = time.time() - start_time\n",
    "# print(\"--- %s seconds ---\" % (dynamic_time), \"model dependent time\", md_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_from_config(config_file, milp_model, seed = None, scenario_generator= make_scenario_tree, file_name = 'test', **kwargs):\n",
    "#    instance_results = []\n",
    "#    test_instances = []\n",
    "#    instance_results = []\n",
    "#    with open(config_file) as f:\n",
    "#       print('Opening config file', config_file)\n",
    "#       #Removes file extension from config file name\n",
    "#       conf_name = config_file.split('.')[0].split('/')[-1]\n",
    "#       print('conf_name', conf_name)\n",
    "#       xp_yaml = yaml.load(f, Loader=yaml.FullLoader)\n",
    "#       SEQUENCE_LENGTH = xp_yaml['sequence_length']\n",
    "#       NO_WORKERS = xp_yaml['max_workers']\n",
    "#       NO_STATIONS = xp_yaml['no_stations']\n",
    "#       WORKER_COST = xp_yaml['worker_cost']\n",
    "#       RECOURSE_COST = xp_yaml['recourse_cost']\n",
    "#       group_counter = 0\n",
    "#       shutil.copyfile(config_file, file_name + conf_name + '_config.yaml')\n",
    "#       for model_file in xp_yaml['model_files']:\n",
    "#          test_instance = MultiModelInstance( init_type='model_data_from_yaml',\n",
    "#                                             model_yaml=model_file, \n",
    "#                                             sequence_length=SEQUENCE_LENGTH, \n",
    "#                                             max_workers=NO_WORKERS, \n",
    "#                                             no_stations=NO_STATIONS, \n",
    "#                                             worker_cost=WORKER_COST, \n",
    "#                                             recourse_cost=RECOURSE_COST)\n",
    "#          print('Running instance', test_instance.name)\n",
    "#          test_instances.append(test_instance)\n",
    "#          #create equipment\n",
    "#          if xp_yaml['equipment_files']:\n",
    "#             print('loading equipment from', xp_yaml['equipment_files'][0])\n",
    "#             equipment = Equipment(generation_method='import_yaml', equipment_file=xp_yaml['equipment_files'][0])\n",
    "#             if equipment.no_tasks != test_instance.no_tasks:\n",
    "#                #raises an error if the equipment and instance have different number of tasks\n",
    "#                raise ValueError('Equipment and instance have different number of tasks')\n",
    "#          else:\n",
    "#             print('creating equipment')\n",
    "#             NO_EQUIPMENT = xp_yaml['no_equipment']\n",
    "#             equipment = Equipment(test_instance.no_tasks, NO_EQUIPMENT, NO_STATIONS, generate_equipment, seed)\n",
    "#          #create scenario tree\n",
    "#          print('generating scenario tree')\n",
    "#          model_mixtures = test_instance.model_mixtures\n",
    "#          scenario_tree_graph, final_sequences = scenario_generator(SEQUENCE_LENGTH, model_mixtures, **kwargs)\n",
    "#          print('defining problem')\n",
    "#          milp_prob = milp_model(problem_instance = test_instance, equipment_instance = equipment, sequence_length=SEQUENCE_LENGTH, prod_sequences=final_sequences, **kwargs)\n",
    "#          #prob = milp_model(test_instance, equipment,test_instance.no_tasks, NO_WORKERS, NO_STATIONS, TAKT_TIME, SEQUENCE_LENGTH, final_sequences, worker_cost=WORKER_COST)\n",
    "#          start = timer()\n",
    "#          solver = plp.GUROBI_CMD(options=[('TimeLimit', 300), ('LogFile', file_name+conf_name + str(group_counter) + \".log\")])#\n",
    "#          milp_prob.solve(solver=solver, file_name=file_name + conf_name+ str(group_counter))\n",
    "#          end = timer()\n",
    "#          result = milp_prob.get_obj_val_dict()\n",
    "#          result['run_time'] = end - start\n",
    "#          instance_results.append(result)\n",
    "#          group_counter += 1\n",
    "#          instance_results = pd.DataFrame(instance_results)\n",
    "#          output_path=file_name + conf_name +  '_results.csv'\n",
    "#          instance_results.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n",
    "     \n",
    "\n",
    "#    return instance_results, test_instances\n",
    "\n",
    "# today = datetime.today().strftime('%Y_%m_%d')\n",
    "# xp_name = f\"xp_{today}_config_test2\"\n",
    "# if not os.path.exists('model_runs/'+ xp_name):\n",
    "#    os.makedirs('model_runs/'+xp_name)\n",
    "   \n",
    "# start_time = time.time()\n",
    "# file_name = 'model_runs/'+xp_name+f'/model_dependent_'\n",
    "# results_md_df, instances_md = run_from_config('SALBP_benchmark/MM_instances/medium_instance_config_S4.yaml', model_dependent_problem_linear_labor_recourse, \n",
    "#           scenario_generator=make_scenario_tree,\n",
    "#            file_name=file_name)\n",
    "# md_time = time.time() - start_time\n",
    "# start_time = time.time()\n",
    "# file_name = 'model_runs/'+xp_name+f'/dynamic_'\n",
    "# results_md_df, instances_md =  run_from_config('SALBP_benchmark/MM_instances/medium_instance_config_S4.yaml', dynamic_problem_linear_labor_recourse, \n",
    "#           scenario_generator=make_scenario_tree,\n",
    "#            file_name=file_name)\n",
    "# dynamic_time = time.time() - start_time\n",
    "# print(\"--- %s seconds ---\" % (dynamic_time), \"model dependent time\", md_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening config file SALBP_benchmark/MM_instances/small_instance_debug.yaml\n",
      "base_file_name model_runs/xp_2023_11_18_mc_debug\n",
      "conf_name small_instance_debug\n",
      "copying config file to results folder SALBP_benchmark/MM_instances/small_instance_debug.yaml model_runs/xp_2023_11_18_mc_debug/SALBP_benchmark/MM_instances/small_instance_debug.yaml\n",
      "running milp_model <class 'milp_models.model_dependent_problem_multi_labor_recourse'>\n",
      "using this file SALBP_benchmark/MM_instances/model_data/small_instances/2_models/n=20_1_n=20_2.yaml\n",
      "Running instance n=20_1_n=20_2\n",
      "loading equipment from SALBP_benchmark/MM_instances/equipment_data/random_O20_E4_S4_seed42.yaml\n",
      "generating scenario tree\n",
      "kwargs {}\n",
      "defining problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/letshopethisworks2/Documents/Phd Paper material/MMABPWW/ALB_instance_tools.py:153: UserWarning: Model probabilities do not sum to 1: 0.9999999999999999\n",
      "  warnings.warn(f'Model probabilities do not sum to 1: {total_probability}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter LogFile to value \"model_runs/xp_2023_11_18_mc_debug/model_dependent/d_small_instance_debug0.log\"\n",
      "Using license file /Users/letshopethisworks2/gurobi.lic\n",
      "\n",
      "Gurobi Optimizer version 10.0.2 build v10.0.2rc0 (mac64[rosetta2])\n",
      "Copyright (c) 2023, Gurobi Optimization, LLC\n",
      "\n",
      "Read LP format model from file /var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/32942efce4b44210ab40c1790bb39b0c-pulp.lp\n",
      "Reading time = 0.01 seconds\n",
      "Total_cost: 5923 rows, 1121 columns, 30096 nonzeros\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 5923 rows, 1121 columns and 30096 nonzeros\n",
      "Model fingerprint: 0x97a0116f\n",
      "Variable types: 0 continuous, 1121 integer (656 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 4e+02]\n",
      "  Objective range  [8e+00, 6e+03]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "Presolve removed 448 rows and 192 columns\n",
      "Presolve time: 0.07s\n",
      "Presolved: 5475 rows, 929 columns, 29176 nonzeros\n",
      "Variable types: 0 continuous, 929 integer (656 binary)\n",
      "Found heuristic solution: objective 9730.0000000\n",
      "\n",
      "Root relaxation: objective 5.367000e+03, 2622 iterations, 0.09 seconds (0.11 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5367.00000    0  125 9730.00000 5367.00000  44.8%     -    0s\n",
      "H    0     0                    6817.0000000 6222.15081  8.73%     -    0s\n",
      "     0     0 6816.51904    0  306 6817.00000 6816.51904  0.01%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 20\n",
      "  Cover: 20\n",
      "  Clique: 24\n",
      "  MIR: 404\n",
      "  StrongCG: 64\n",
      "  GUB cover: 20\n",
      "  Zero half: 33\n",
      "  RLT: 19\n",
      "  Relax-and-lift: 107\n",
      "\n",
      "Explored 1 nodes (4354 simplex iterations) in 0.50 seconds (0.53 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 6817 9730 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.817000000000e+03, best bound 6.816519041516e+03, gap 0.0071%\n",
      "\n",
      "Wrote result file '/var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/32942efce4b44210ab40c1790bb39b0c-pulp.sol'\n",
      "\n",
      "running milp_model <class 'milp_models.model_dependent_problem_multi_labor_recourse'>\n",
      "using this file SALBP_benchmark/MM_instances/model_data/small_instances/2_models/n=20_2_n=20_3.yaml\n",
      "Running instance n=20_2_n=20_3\n",
      "loading equipment from SALBP_benchmark/MM_instances/equipment_data/random_O20_E4_S4_seed42.yaml\n",
      "generating scenario tree\n",
      "kwargs {}\n",
      "defining problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/letshopethisworks2/Documents/Phd Paper material/MMABPWW/milp_models.py:1137: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  task_assignments_df = task_assignments_df.groupby(['station', 'model'])['task', 'task_times'].agg({'task':lambda x: ','.join(x.astype(str)), 'task_times': sum }).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter LogFile to value \"model_runs/xp_2023_11_18_mc_debug/model_dependent/d_small_instance_debug1.log\"\n",
      "Using license file /Users/letshopethisworks2/gurobi.lic\n",
      "\n",
      "Gurobi Optimizer version 10.0.2 build v10.0.2rc0 (mac64[rosetta2])\n",
      "Copyright (c) 2023, Gurobi Optimization, LLC\n",
      "\n",
      "Read LP format model from file /var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/72d46a347e684ba9ba347ab55357fe4a-pulp.lp\n",
      "Reading time = 0.01 seconds\n",
      "Total_cost: 5925 rows, 1121 columns, 30160 nonzeros\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 5925 rows, 1121 columns and 30160 nonzeros\n",
      "Model fingerprint: 0xc09d7be6\n",
      "Variable types: 0 continuous, 1121 integer (656 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 4e+02]\n",
      "  Objective range  [5e+01, 6e+03]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "Presolve removed 448 rows and 192 columns\n",
      "Presolve time: 0.06s\n",
      "Presolved: 5477 rows, 929 columns, 29224 nonzeros\n",
      "Variable types: 0 continuous, 929 integer (656 binary)\n",
      "Found heuristic solution: objective 13795.181158\n",
      "\n",
      "Root relaxation: objective 5.367000e+03, 2271 iterations, 0.09 seconds (0.11 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5367.00000    0  119 13795.1812 5367.00000  61.1%     -    0s\n",
      "H    0     0                    13640.362316 5367.00000  60.7%     -    0s\n",
      "H    0     0                    12789.986317 5367.00000  58.0%     -    0s\n",
      "H    0     0                    11605.000000 5367.00000  53.8%     -    0s\n",
      "     0     0 6592.90285    0  448 11605.0000 6592.90285  43.2%     -    0s\n",
      "H    0     0                    6817.0000000 6592.90285  3.29%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 25\n",
      "  Cover: 5\n",
      "  MIR: 883\n",
      "  StrongCG: 1\n",
      "  GUB cover: 9\n",
      "  Zero half: 78\n",
      "  RLT: 4\n",
      "  Relax-and-lift: 607\n",
      "\n",
      "Explored 1 nodes (3930 simplex iterations) in 0.73 seconds (0.71 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 5: 6817 11605 12790 ... 13795.2\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.817000000000e+03, best bound 6.817000000000e+03, gap 0.0000%\n",
      "\n",
      "Wrote result file '/var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/72d46a347e684ba9ba347ab55357fe4a-pulp.sol'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/letshopethisworks2/Documents/Phd Paper material/MMABPWW/milp_models.py:1137: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  task_assignments_df = task_assignments_df.groupby(['station', 'model'])['task', 'task_times'].agg({'task':lambda x: ','.join(x.astype(str)), 'task_times': sum }).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running milp_model <class 'milp_models.model_dependent_problem_multi_labor_recourse'>\n",
      "using this file SALBP_benchmark/MM_instances/model_data/small_instances/3_models/n=20_2_n=20_3_n=20_4.yaml\n",
      "Running instance n=20_2_n=20_3_n=20_4\n",
      "loading equipment from SALBP_benchmark/MM_instances/equipment_data/random_O20_E4_S4_seed42.yaml\n",
      "generating scenario tree\n",
      "kwargs {}\n",
      "defining problem\n",
      "Set parameter LogFile to value \"model_runs/xp_2023_11_18_mc_debug/model_dependent/d_small_instance_debug2.log\"\n",
      "Using license file /Users/letshopethisworks2/gurobi.lic\n",
      "\n",
      "Gurobi Optimizer version 10.0.2 build v10.0.2rc0 (mac64[rosetta2])\n",
      "Copyright (c) 2023, Gurobi Optimization, LLC\n",
      "\n",
      "Read LP format model from file /var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/f5e8e4f78d6a45e98228f178667d10e8-pulp.lp\n",
      "Reading time = 0.07 seconds\n",
      "Total_cost: 29122 rows, 3326 columns, 140414 nonzeros\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 29122 rows, 3326 columns and 140414 nonzeros\n",
      "Model fingerprint: 0xf4684bc7\n",
      "Variable types: 0 continuous, 3326 integer (976 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 4e+02]\n",
      "  Objective range  [4e-01, 6e+03]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "Presolve removed 2268 rows and 972 columns\n",
      "Presolve time: 0.28s\n",
      "Presolved: 26854 rows, 2354 columns, 136734 nonzeros\n",
      "Variable types: 0 continuous, 2354 integer (976 binary)\n",
      "Found heuristic solution: objective 12843.000000\n",
      "Root relaxation presolved: 2354 rows, 29208 columns, 139088 nonzeros\n",
      "\n",
      "\n",
      "Root relaxation: objective 5.367000e+03, 10569 iterations, 1.14 seconds (1.81 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5367.00000    0  531 12843.0000 5367.00000  58.2%     -    1s\n",
      "H    0     0                    12620.000000 5367.00000  57.5%     -    1s\n",
      "H    0     0                    11530.000000 5367.00000  53.5%     -    2s\n",
      "H    0     0                    6817.0000000 6547.78262  3.95%     -    5s\n",
      "     0     0 6817.00000    0 1605 6817.00000 6817.00000  0.00%     -    6s\n",
      "\n",
      "Cutting planes:\n",
      "  Cover: 11\n",
      "  Clique: 23\n",
      "  MIR: 602\n",
      "  GUB cover: 17\n",
      "  Zero half: 61\n",
      "  RLT: 10\n",
      "  Relax-and-lift: 486\n",
      "\n",
      "Explored 1 nodes (22737 simplex iterations) in 6.64 seconds (9.61 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 4: 6817 11530 12620 12843 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.817000000000e+03, best bound 6.817000000000e+03, gap 0.0000%\n",
      "\n",
      "Wrote result file '/var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/f5e8e4f78d6a45e98228f178667d10e8-pulp.sol'\n",
      "\n",
      "time for <class 'milp_models.model_dependent_problem_multi_labor_recourse'> 10.436521053314209\n",
      "running milp_model <class 'milp_models.model_dependent_problem_linear_labor_recourse'>\n",
      "using this file SALBP_benchmark/MM_instances/model_data/small_instances/2_models/n=20_1_n=20_2.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/letshopethisworks2/Documents/Phd Paper material/MMABPWW/milp_models.py:1137: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  task_assignments_df = task_assignments_df.groupby(['station', 'model'])['task', 'task_times'].agg({'task':lambda x: ','.join(x.astype(str)), 'task_times': sum }).reset_index()\n",
      "/Users/letshopethisworks2/Documents/Phd Paper material/MMABPWW/ALB_instance_tools.py:153: UserWarning: Model probabilities do not sum to 1: 0.9999999999999999\n",
      "  warnings.warn(f'Model probabilities do not sum to 1: {total_probability}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running instance n=20_1_n=20_2\n",
      "loading equipment from SALBP_benchmark/MM_instances/equipment_data/random_O20_E4_S4_seed42.yaml\n",
      "generating scenario tree\n",
      "kwargs {}\n",
      "defining problem\n",
      "Set parameter LogFile to value \"model_runs/xp_2023_11_18_mc_debug/model_dependent_linear/lmd_small_instance_debug3.log\"\n",
      "Using license file /Users/letshopethisworks2/gurobi.lic\n",
      "\n",
      "Gurobi Optimizer version 10.0.2 build v10.0.2rc0 (mac64[rosetta2])\n",
      "Copyright (c) 2023, Gurobi Optimization, LLC\n",
      "\n",
      "Read LP format model from file /var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/c21fba12354040cfb480e812652f9990-pulp.lp\n",
      "Reading time = 0.01 seconds\n",
      "Total_cost: 1051 rows, 641 columns, 7432 nonzeros\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 1051 rows, 641 columns and 7432 nonzeros\n",
      "Model fingerprint: 0x19116d53\n",
      "Variable types: 0 continuous, 641 integer (176 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+03]\n",
      "  Objective range  [8e+00, 6e+03]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Presolve removed 448 rows and 192 columns\n",
      "Presolve time: 0.02s\n",
      "Presolved: 603 rows, 449 columns, 6722 nonzeros\n",
      "Variable types: 0 continuous, 449 integer (176 binary)\n",
      "Found heuristic solution: objective 15637.000000\n",
      "Found heuristic solution: objective 7730.0000000\n",
      "\n",
      "Root relaxation: objective 5.553449e+03, 688 iterations, 0.02 seconds (0.02 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5553.44915    0  258 7730.00000 5553.44915  28.2%     -    0s\n",
      "H    0     0                    6817.0000000 6768.17206  0.72%     -    0s\n",
      "     0     0 6817.00000    0   67 6817.00000 6817.00000  0.00%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 16\n",
      "  Cover: 8\n",
      "  Implied bound: 64\n",
      "  Clique: 64\n",
      "  MIR: 81\n",
      "  GUB cover: 4\n",
      "  RLT: 8\n",
      "\n",
      "Explored 1 nodes (941 simplex iterations) in 0.11 seconds (0.07 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 6817 7730 15637 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.817000000000e+03, best bound 6.817000000000e+03, gap 0.0000%\n",
      "\n",
      "Wrote result file '/var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/c21fba12354040cfb480e812652f9990-pulp.sol'\n",
      "\n",
      "running milp_model <class 'milp_models.model_dependent_problem_linear_labor_recourse'>\n",
      "using this file SALBP_benchmark/MM_instances/model_data/small_instances/2_models/n=20_2_n=20_3.yaml\n",
      "Running instance n=20_2_n=20_3\n",
      "loading equipment from SALBP_benchmark/MM_instances/equipment_data/random_O20_E4_S4_seed42.yaml\n",
      "generating scenario tree\n",
      "kwargs {}\n",
      "defining problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/letshopethisworks2/Documents/Phd Paper material/MMABPWW/milp_models.py:944: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  task_assignments_df = task_assignments_df.groupby(['station', 'model'])['task', 'task_times'].agg({'task':lambda x: ','.join(x.astype(str)), 'task_times': sum }).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter LogFile to value \"model_runs/xp_2023_11_18_mc_debug/model_dependent_linear/lmd_small_instance_debug4.log\"\n",
      "Using license file /Users/letshopethisworks2/gurobi.lic\n",
      "\n",
      "Gurobi Optimizer version 10.0.2 build v10.0.2rc0 (mac64[rosetta2])\n",
      "Copyright (c) 2023, Gurobi Optimization, LLC\n",
      "\n",
      "Read LP format model from file /var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/f416b2642f7e48699dfb858dfaebdb11-pulp.lp\n",
      "Reading time = 0.01 seconds\n",
      "Total_cost: 1053 rows, 641 columns, 7448 nonzeros\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 1053 rows, 641 columns and 7448 nonzeros\n",
      "Model fingerprint: 0x72d6aa29\n",
      "Variable types: 0 continuous, 641 integer (176 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+03]\n",
      "  Objective range  [5e+01, 6e+03]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Presolve removed 448 rows and 192 columns\n",
      "Presolve time: 0.02s\n",
      "Presolved: 605 rows, 449 columns, 6734 nonzeros\n",
      "Variable types: 0 continuous, 449 integer (176 binary)\n",
      "Found heuristic solution: objective 13129.000000\n",
      "Found heuristic solution: objective 6817.0000000\n",
      "\n",
      "Root relaxation: objective 5.540216e+03, 660 iterations, 0.01 seconds (0.02 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5540.21589    0  247 6817.00000 5540.21589  18.7%     -    0s\n",
      "     0     0     cutoff    0      6817.00000 6817.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (796 simplex iterations) in 0.05 seconds (0.05 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 6817 13129 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.817000000000e+03, best bound 6.817000000000e+03, gap 0.0000%\n",
      "\n",
      "Wrote result file '/var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/f416b2642f7e48699dfb858dfaebdb11-pulp.sol'\n",
      "\n",
      "running milp_model <class 'milp_models.model_dependent_problem_linear_labor_recourse'>\n",
      "using this file SALBP_benchmark/MM_instances/model_data/small_instances/3_models/n=20_2_n=20_3_n=20_4.yaml\n",
      "Running instance n=20_2_n=20_3_n=20_4\n",
      "loading equipment from SALBP_benchmark/MM_instances/equipment_data/random_O20_E4_S4_seed42.yaml\n",
      "generating scenario tree\n",
      "kwargs {}\n",
      "defining problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/letshopethisworks2/Documents/Phd Paper material/MMABPWW/milp_models.py:944: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  task_assignments_df = task_assignments_df.groupby(['station', 'model'])['task', 'task_times'].agg({'task':lambda x: ','.join(x.astype(str)), 'task_times': sum }).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter LogFile to value \"model_runs/xp_2023_11_18_mc_debug/model_dependent_linear/lmd_small_instance_debug5.log\"\n",
      "Using license file /Users/letshopethisworks2/gurobi.lic\n",
      "\n",
      "Gurobi Optimizer version 10.0.2 build v10.0.2rc0 (mac64[rosetta2])\n",
      "Copyright (c) 2023, Gurobi Optimization, LLC\n",
      "\n",
      "Read LP format model from file /var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/f0df2d92b29c4748a277108c79c04b9d-pulp.lp\n",
      "Reading time = 0.02 seconds\n",
      "Total_cost: 4486 rows, 2606 columns, 34310 nonzeros\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 4486 rows, 2606 columns and 34310 nonzeros\n",
      "Model fingerprint: 0x9555cbce\n",
      "Variable types: 0 continuous, 2606 integer (256 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+03]\n",
      "  Objective range  [4e-01, 6e+03]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Presolve removed 2268 rows and 972 columns\n",
      "Presolve time: 0.08s\n",
      "Presolved: 2218 rows, 1634 columns, 30960 nonzeros\n",
      "Variable types: 0 continuous, 1634 integer (256 binary)\n",
      "Found heuristic solution: objective 13676.000000\n",
      "\n",
      "Root relaxation: objective 5.510120e+03, 2470 iterations, 0.10 seconds (0.21 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5510.12046    0 1490 13676.0000 5510.12046  59.7%     -    0s\n",
      "H    0     0                    11921.000000 5510.12046  53.8%     -    0s\n",
      "H    0     0                    6817.0000000 6733.92034  1.22%     -    0s\n",
      "     0     0     cutoff    0      6817.00000 6817.00000  0.00%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 22\n",
      "  Cover: 14\n",
      "  Implied bound: 401\n",
      "  Clique: 105\n",
      "  MIR: 23\n",
      "  StrongCG: 3\n",
      "  Zero half: 9\n",
      "  RLT: 16\n",
      "  Relax-and-lift: 108\n",
      "\n",
      "Explored 1 nodes (4023 simplex iterations) in 0.53 seconds (0.66 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 6817 11921 13676 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.817000000000e+03, best bound 6.817000000000e+03, gap 0.0000%\n",
      "\n",
      "Wrote result file '/var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/f0df2d92b29c4748a277108c79c04b9d-pulp.sol'\n",
      "\n",
      "time for <class 'milp_models.model_dependent_problem_linear_labor_recourse'> 1.7958979606628418\n",
      "running milp_model <class 'milp_models.dynamic_problem_linear_labor_recourse'>\n",
      "using this file SALBP_benchmark/MM_instances/model_data/small_instances/2_models/n=20_1_n=20_2.yaml\n",
      "Running instance n=20_1_n=20_2\n",
      "loading equipment from SALBP_benchmark/MM_instances/equipment_data/random_O20_E4_S4_seed42.yaml\n",
      "generating scenario tree\n",
      "kwargs {}\n",
      "defining problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/letshopethisworks2/Documents/Phd Paper material/MMABPWW/milp_models.py:944: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  task_assignments_df = task_assignments_df.groupby(['station', 'model'])['task', 'task_times'].agg({'task':lambda x: ','.join(x.astype(str)), 'task_times': sum }).reset_index()\n",
      "/Users/letshopethisworks2/Documents/Phd Paper material/MMABPWW/ALB_instance_tools.py:153: UserWarning: Model probabilities do not sum to 1: 0.9999999999999999\n",
      "  warnings.warn(f'Model probabilities do not sum to 1: {total_probability}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter LogFile to value \"model_runs/xp_2023_11_18_mc_debug/dynamic_linear/ld_small_instance_debug6.log\"\n",
      "Using license file /Users/letshopethisworks2/gurobi.lic\n",
      "\n",
      "Gurobi Optimizer version 10.0.2 build v10.0.2rc0 (mac64[rosetta2])\n",
      "Copyright (c) 2023, Gurobi Optimization, LLC\n",
      "\n",
      "Read LP format model from file /var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/aecab49322b1438b93e1c6dab1a50149-pulp.lp\n",
      "Reading time = 0.03 seconds\n",
      "Total_cost: 10896 rows, 5601 columns, 41568 nonzeros\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 10896 rows, 5601 columns and 41568 nonzeros\n",
      "Model fingerprint: 0xd13f6028\n",
      "Variable types: 0 continuous, 5601 integer (5136 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+03]\n",
      "  Objective range  [8e+00, 6e+03]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Presolve removed 4708 rows and 1592 columns\n",
      "Presolve time: 0.06s\n",
      "Presolved: 6188 rows, 4009 columns, 27748 nonzeros\n",
      "Variable types: 0 continuous, 4009 integer (3736 binary)\n",
      "Found heuristic solution: objective 35198.963983\n",
      "Found heuristic solution: objective 8317.0000000\n",
      "\n",
      "Root relaxation: objective 5.406571e+03, 16869 iterations, 0.90 seconds (0.82 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5406.57063    0 2267 8317.00000 5406.57063  35.0%     -    1s\n",
      "H    0     0                    6817.0000000 5406.57063  20.7%     -    1s\n",
      "     0     0 6758.00000    0   65 6817.00000 6758.00000  0.87%     -    2s\n",
      "     0     0 6758.00000    0   65 6817.00000 6758.00000  0.87%     -    2s\n",
      "\n",
      "Cutting planes:\n",
      "  Cover: 68\n",
      "  Implied bound: 11\n",
      "  Clique: 769\n",
      "  MIR: 116\n",
      "  GUB cover: 129\n",
      "  RLT: 217\n",
      "\n",
      "Explored 1 nodes (28969 simplex iterations) in 2.33 seconds (1.88 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 6817 8317 35199 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.817000000000e+03, best bound 6.817000000000e+03, gap 0.0000%\n",
      "\n",
      "Wrote result file '/var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/aecab49322b1438b93e1c6dab1a50149-pulp.sol'\n",
      "\n",
      "running milp_model <class 'milp_models.dynamic_problem_linear_labor_recourse'>\n",
      "using this file SALBP_benchmark/MM_instances/model_data/small_instances/2_models/n=20_2_n=20_3.yaml\n",
      "Running instance n=20_2_n=20_3\n",
      "loading equipment from SALBP_benchmark/MM_instances/equipment_data/random_O20_E4_S4_seed42.yaml\n",
      "generating scenario tree\n",
      "kwargs {}\n",
      "defining problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/letshopethisworks2/Documents/Phd Paper material/MMABPWW/milp_models.py:420: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  task_assignments_df = task_assignments_df.groupby(['scenario','station', 'sequence_loc','model'])['task', 'task_times'].agg({'task':lambda x: ','.join(x.astype(str)), 'task_times': sum }).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter LogFile to value \"model_runs/xp_2023_11_18_mc_debug/dynamic_linear/ld_small_instance_debug7.log\"\n",
      "Using license file /Users/letshopethisworks2/gurobi.lic\n",
      "\n",
      "Gurobi Optimizer version 10.0.2 build v10.0.2rc0 (mac64[rosetta2])\n",
      "Copyright (c) 2023, Gurobi Optimization, LLC\n",
      "\n",
      "Read LP format model from file /var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/6ee39e6ba548461799437142502afdce-pulp.lp\n",
      "Reading time = 0.03 seconds\n",
      "Total_cost: 10960 rows, 5601 columns, 42080 nonzeros\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 10960 rows, 5601 columns and 42080 nonzeros\n",
      "Model fingerprint: 0x629d060e\n",
      "Variable types: 0 continuous, 5601 integer (5136 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+03]\n",
      "  Objective range  [5e+01, 6e+03]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Presolve removed 4716 rows and 1592 columns\n",
      "Presolve time: 0.07s\n",
      "Presolved: 6244 rows, 4009 columns, 28084 nonzeros\n",
      "Variable types: 0 continuous, 4009 integer (3736 binary)\n",
      "Found heuristic solution: objective 35266.720276\n",
      "Found heuristic solution: objective 8317.0000000\n",
      "\n",
      "Root relaxation: objective 5.408643e+03, 14614 iterations, 0.64 seconds (0.55 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5408.64287    0 2261 8317.00000 5408.64287  35.0%     -    1s\n",
      "H    0     0                    6817.0000000 5408.64287  20.7%     -    1s\n",
      "     0     0 6817.00000    0   65 6817.00000 6817.00000  0.00%     -    2s\n",
      "\n",
      "Cutting planes:\n",
      "  Cover: 173\n",
      "  Implied bound: 17\n",
      "  Clique: 829\n",
      "  MIR: 129\n",
      "  StrongCG: 4\n",
      "  GUB cover: 78\n",
      "  RLT: 83\n",
      "\n",
      "Explored 1 nodes (22264 simplex iterations) in 2.02 seconds (1.49 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 6817 8317 35266.7 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.817000000000e+03, best bound 6.817000000000e+03, gap 0.0000%\n",
      "\n",
      "Wrote result file '/var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/6ee39e6ba548461799437142502afdce-pulp.sol'\n",
      "\n",
      "running milp_model <class 'milp_models.dynamic_problem_linear_labor_recourse'>\n",
      "using this file SALBP_benchmark/MM_instances/model_data/small_instances/3_models/n=20_2_n=20_3_n=20_4.yaml\n",
      "Running instance n=20_2_n=20_3_n=20_4\n",
      "loading equipment from SALBP_benchmark/MM_instances/equipment_data/random_O20_E4_S4_seed42.yaml\n",
      "generating scenario tree\n",
      "kwargs {}\n",
      "defining problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/letshopethisworks2/Documents/Phd Paper material/MMABPWW/milp_models.py:420: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  task_assignments_df = task_assignments_df.groupby(['scenario','station', 'sequence_loc','model'])['task', 'task_times'].agg({'task':lambda x: ','.join(x.astype(str)), 'task_times': sum }).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter LogFile to value \"model_runs/xp_2023_11_18_mc_debug/dynamic_linear/ld_small_instance_debug8.log\"\n",
      "Using license file /Users/letshopethisworks2/gurobi.lic\n",
      "\n",
      "Gurobi Optimizer version 10.0.2 build v10.0.2rc0 (mac64[rosetta2])\n",
      "Copyright (c) 2023, Gurobi Optimization, LLC\n",
      "\n",
      "Read LP format model from file /var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/e790ea47a0a6423da9a05c75ffcedffc-pulp.lp\n",
      "Reading time = 0.21 seconds\n",
      "Total_cost: 81351 rows, 28286 columns, 264438 nonzeros\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 81351 rows, 28286 columns and 264438 nonzeros\n",
      "Model fingerprint: 0xe2e436f9\n",
      "Variable types: 0 continuous, 28286 integer (25936 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+03]\n",
      "  Objective range  [4e-01, 6e+03]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Presolve removed 51978 rows and 9732 columns\n",
      "Presolve time: 0.47s\n",
      "Presolved: 29373 rows, 18554 columns, 134142 nonzeros\n",
      "Variable types: 0 continuous, 18554 integer (17176 binary)\n",
      "Found heuristic solution: objective 35447.721767\n",
      "Found heuristic solution: objective 8317.0000000\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex\n",
      "Showing first log only...\n",
      "\n",
      "Concurrent spin time: 0.00s\n",
      "\n",
      "Solved with dual simplex\n",
      "\n",
      "Root relaxation: objective 5.282664e+03, 27154 iterations, 3.07 seconds (2.74 work units)\n",
      "Total elapsed time = 5.12s\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5282.66445    0 5674 8317.00000 5282.66445  36.5%     -    6s\n",
      "H    0     0                    6817.0000000 5282.66445  22.5%     -    6s\n",
      "     0     0 6817.00000    0 10025 6817.00000 6817.00000  0.00%     -   26s\n",
      "\n",
      "Cutting planes:\n",
      "  Cover: 290\n",
      "  Implied bound: 42\n",
      "  Clique: 1981\n",
      "  MIR: 91\n",
      "  StrongCG: 15\n",
      "  GUB cover: 50\n",
      "\n",
      "Explored 1 nodes (70070 simplex iterations) in 26.25 seconds (21.44 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 6817 8317 35447.7 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.817000000000e+03, best bound 6.817000000000e+03, gap 0.0000%\n",
      "\n",
      "Wrote result file '/var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/e790ea47a0a6423da9a05c75ffcedffc-pulp.sol'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/letshopethisworks2/Documents/Phd Paper material/MMABPWW/milp_models.py:420: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  task_assignments_df = task_assignments_df.groupby(['scenario','station', 'sequence_loc','model'])['task', 'task_times'].agg({'task':lambda x: ','.join(x.astype(str)), 'task_times': sum }).reset_index()\n",
      "/Users/letshopethisworks2/Documents/Phd Paper material/MMABPWW/ALB_instance_tools.py:153: UserWarning: Model probabilities do not sum to 1: 0.9999999999999999\n",
      "  warnings.warn(f'Model probabilities do not sum to 1: {total_probability}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for <class 'milp_models.dynamic_problem_linear_labor_recourse'> 38.64230680465698\n",
      "running milp_model <class 'milp_models.dynamic_problem_multi_labor_recourse'>\n",
      "using this file SALBP_benchmark/MM_instances/model_data/small_instances/2_models/n=20_1_n=20_2.yaml\n",
      "Running instance n=20_1_n=20_2\n",
      "loading equipment from SALBP_benchmark/MM_instances/equipment_data/random_O20_E4_S4_seed42.yaml\n",
      "generating scenario tree\n",
      "kwargs {}\n",
      "defining problem\n",
      "Set parameter LogFile to value \"model_runs/xp_2023_11_18_mc_debug/dynamic/md_small_instance_debug9.log\"\n",
      "Using license file /Users/letshopethisworks2/gurobi.lic\n",
      "\n",
      "Gurobi Optimizer version 10.0.2 build v10.0.2rc0 (mac64[rosetta2])\n",
      "Copyright (c) 2023, Gurobi Optimization, LLC\n",
      "\n",
      "Read LP format model from file /var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/2bcb4401bc854c1482afde35df6f140e-pulp.lp\n",
      "Reading time = 0.11 seconds\n",
      "Total_cost: 23696 rows, 20961 columns, 155232 nonzeros\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 23696 rows, 20961 columns and 155232 nonzeros\n",
      "Model fingerprint: 0xb79b61d1\n",
      "Variable types: 0 continuous, 20961 integer (20496 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 4e+02]\n",
      "  Objective range  [8e+00, 6e+03]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "Presolve removed 11990 rows and 5152 columns\n",
      "Presolve time: 0.24s\n",
      "Presolved: 11706 rows, 15809 columns, 112628 nonzeros\n",
      "Variable types: 0 continuous, 15809 integer (15536 binary)\n",
      "Found heuristic solution: objective 31455.000000\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex\n",
      "Showing first log only...\n",
      "\n",
      "Concurrent spin time: 0.00s\n",
      "\n",
      "Solved with dual simplex\n",
      "\n",
      "Root relaxation: objective 5.367000e+03, 10525 iterations, 0.59 seconds (0.38 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5367.00000    0 1268 31455.0000 5367.00000  82.9%     -    1s\n",
      "H    0     0                    28024.087342 5367.00000  80.8%     -    1s\n",
      "H    0     0                    24396.339757 5367.00000  78.0%     -    1s\n",
      "H    0     0                    18098.081660 5367.00000  70.3%     -    2s\n",
      "     0     0 5710.77330    0 3581 18098.0817 5710.77330  68.4%     -    3s\n",
      "H    0     0                    17642.163320 5710.77330  67.6%     -    3s\n",
      "H    0     0                    17598.081660 5710.77330  67.5%     -    3s\n",
      "     0     0 6133.04532    0 2467 17598.0817 6133.04532  65.1%     -    4s\n",
      "     0     0 6142.46227    0 2463 17598.0817 6142.46227  65.1%     -    4s\n",
      "     0     0 6142.46227    0 2463 17598.0817 6142.46227  65.1%     -    4s\n",
      "H    0     0                    6817.0000000 6549.37840  3.93%     -    7s\n",
      "     0     0 6817.00000    0 2470 6817.00000 6817.00000  0.00%     -    7s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 3\n",
      "  Cover: 307\n",
      "  Clique: 313\n",
      "  MIR: 633\n",
      "  StrongCG: 6\n",
      "  GUB cover: 507\n",
      "  Zero half: 118\n",
      "  RLT: 126\n",
      "  Relax-and-lift: 325\n",
      "\n",
      "Explored 1 nodes (50962 simplex iterations) in 8.00 seconds (7.20 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 7: 6817 17598.1 17642.2 ... 31455\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.817000000000e+03, best bound 6.817000000000e+03, gap 0.0000%\n",
      "\n",
      "Wrote result file '/var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/2bcb4401bc854c1482afde35df6f140e-pulp.sol'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/letshopethisworks2/Documents/Phd Paper material/MMABPWW/milp_models.py:595: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  task_assignments_df = task_assignments_df.groupby(['scenario','station', 'sequence_loc','model'])['task', 'task_times'].agg({'task':lambda x: ','.join(x.astype(str)), 'task_times': sum }).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running milp_model <class 'milp_models.dynamic_problem_multi_labor_recourse'>\n",
      "using this file SALBP_benchmark/MM_instances/model_data/small_instances/2_models/n=20_2_n=20_3.yaml\n",
      "Running instance n=20_2_n=20_3\n",
      "loading equipment from SALBP_benchmark/MM_instances/equipment_data/random_O20_E4_S4_seed42.yaml\n",
      "generating scenario tree\n",
      "kwargs {}\n",
      "defining problem\n",
      "Set parameter LogFile to value \"model_runs/xp_2023_11_18_mc_debug/dynamic/md_small_instance_debug10.log\"\n",
      "Using license file /Users/letshopethisworks2/gurobi.lic\n",
      "\n",
      "Gurobi Optimizer version 10.0.2 build v10.0.2rc0 (mac64[rosetta2])\n",
      "Copyright (c) 2023, Gurobi Optimization, LLC\n",
      "\n",
      "Read LP format model from file /var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/cab669cba760426583c080a352880ad3-pulp.lp\n",
      "Reading time = 0.11 seconds\n",
      "Total_cost: 23760 rows, 20961 columns, 157280 nonzeros\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 23760 rows, 20961 columns and 157280 nonzeros\n",
      "Model fingerprint: 0xce104944\n",
      "Variable types: 0 continuous, 20961 integer (20496 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 4e+02]\n",
      "  Objective range  [5e+01, 6e+03]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "Presolve removed 11990 rows and 5152 columns\n",
      "Presolve time: 0.24s\n",
      "Presolved: 11770 rows, 15809 columns, 114164 nonzeros\n",
      "Variable types: 0 continuous, 15809 integer (15536 binary)\n",
      "Found heuristic solution: objective 31455.000000\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex\n",
      "Showing first log only...\n",
      "\n",
      "Concurrent spin time: 0.00s\n",
      "\n",
      "Solved with dual simplex\n",
      "\n",
      "Root relaxation: objective 5.367000e+03, 9977 iterations, 0.62 seconds (0.41 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5367.00000    0 1235 31455.0000 5367.00000  82.9%     -    1s\n",
      "H    0     0                    27234.188695 5367.00000  80.3%     -    1s\n",
      "H    0     0                    27165.678386 5367.00000  80.2%     -    1s\n",
      "H    0     0                    17554.000000 5367.00000  69.4%     -    2s\n",
      "     0     0 6776.56653    0 4503 17554.0000 6776.56653  61.4%     -    7s\n",
      "     0     0 6776.56653    0 4369 17554.0000 6776.56653  61.4%     -    8s\n",
      "     0     0 6776.56653    0 4363 17554.0000 6776.56653  61.4%     -    8s\n",
      "H    0     0                    8073.4821749 6776.56653  16.1%     -    9s\n",
      "H    0     0                    7128.6292259 6776.56653  4.94%     -    9s\n",
      "     0     0 6779.17587    0 4322 7128.62923 6779.17587  4.90%     -    9s\n",
      "     0     0 6786.00123    0 4374 7128.62923 6786.00123  4.81%     -   10s\n",
      "     0     0 6787.91831    0 4359 7128.62923 6787.91831  4.78%     -   11s\n",
      "H    0     0                    6879.2099668 6787.91831  1.33%     -   11s\n",
      "H    0     0                    6817.0000000 6789.09071  0.41%     -   14s\n",
      "     0     0 6816.32002    0 1258 6817.00000 6816.32002  0.01%     -   14s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 3\n",
      "  Cover: 166\n",
      "  MIR: 720\n",
      "  StrongCG: 32\n",
      "  GUB cover: 150\n",
      "  Zero half: 307\n",
      "  RLT: 6\n",
      "  Relax-and-lift: 643\n",
      "\n",
      "Explored 1 nodes (71320 simplex iterations) in 14.05 seconds (12.15 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 8: 6817 6879.21 7128.63 ... 31455\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.817000000000e+03, best bound 6.816320017890e+03, gap 0.0100%\n",
      "\n",
      "Wrote result file '/var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/cab669cba760426583c080a352880ad3-pulp.sol'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/letshopethisworks2/Documents/Phd Paper material/MMABPWW/milp_models.py:595: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  task_assignments_df = task_assignments_df.groupby(['scenario','station', 'sequence_loc','model'])['task', 'task_times'].agg({'task':lambda x: ','.join(x.astype(str)), 'task_times': sum }).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running milp_model <class 'milp_models.dynamic_problem_multi_labor_recourse'>\n",
      "using this file SALBP_benchmark/MM_instances/model_data/small_instances/3_models/n=20_2_n=20_3_n=20_4.yaml\n",
      "Running instance n=20_2_n=20_3_n=20_4\n",
      "loading equipment from SALBP_benchmark/MM_instances/equipment_data/random_O20_E4_S4_seed42.yaml\n",
      "generating scenario tree\n",
      "kwargs {}\n",
      "defining problem\n",
      "Set parameter LogFile to value \"model_runs/xp_2023_11_18_mc_debug/dynamic/md_small_instance_debug11.log\"\n",
      "Using license file /Users/letshopethisworks2/gurobi.lic\n",
      "\n",
      "Gurobi Optimizer version 10.0.2 build v10.0.2rc0 (mac64[rosetta2])\n",
      "Copyright (c) 2023, Gurobi Optimization, LLC\n",
      "\n",
      "Read LP format model from file /var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/d404a5797c1a48d181c47ab9d78676e1-pulp.lp\n",
      "Reading time = 0.69 seconds\n",
      "Total_cost: 223911 rows, 106046 columns, 1001862 nonzeros\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 223911 rows, 106046 columns and 1001862 nonzeros\n",
      "Model fingerprint: 0x66a71cbf\n",
      "Variable types: 0 continuous, 106046 integer (103696 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 4e+02]\n",
      "  Objective range  [4e-01, 6e+03]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "Presolve removed 165852 rows and 31692 columns\n",
      "Presolve time: 1.53s\n",
      "Presolved: 58059 rows, 74354 columns, 562494 nonzeros\n",
      "Variable types: 0 continuous, 74354 integer (72976 binary)\n",
      "Found heuristic solution: objective 31455.000000\n",
      "Deterministic concurrent LP optimizer: primal simplex, dual simplex, and barrier\n",
      "Showing barrier log only...\n",
      "\n",
      "Root barrier log...\n",
      "\n",
      "Ordering time: 1.42s\n",
      "\n",
      "Barrier statistics:\n",
      " Dense cols : 17\n",
      " AA' NZ     : 8.296e+05\n",
      " Factor NZ  : 5.611e+06 (roughly 100 MB of memory)\n",
      " Factor Ops : 1.435e+09 (less than 1 second per iteration)\n",
      " Threads    : 6\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   3.98678998e+06 -4.52623122e+06  2.80e+03 3.52e+00  5.74e+04     4s\n",
      "   1   3.14600434e+06 -9.93546427e+07  1.70e+03 4.02e+02  3.17e+04     4s\n",
      "   2   2.65891380e+06 -1.48988762e+08  1.18e+03 8.58e+01  2.03e+04     4s\n",
      "   3   2.07408658e+06 -1.45129834e+08  8.22e+02 1.14e+01  1.36e+04     5s\n",
      "   4   1.92879626e+05 -1.25920671e+08  5.52e+01 1.57e-07  1.50e+03     5s\n",
      "   5   9.92705574e+04 -5.31337193e+07  1.77e+01 4.12e-08  4.39e+02     5s\n",
      "   6   5.78146868e+04 -1.37237210e+07  2.17e+00 4.86e-08  8.13e+01     5s\n",
      "   7   4.63600221e+04 -3.93723768e+06  9.57e-02 1.17e-08  2.01e+01     5s\n",
      "   8   4.38431738e+04 -1.09752612e+06  3.93e-02 3.22e-09  5.72e+00     5s\n",
      "   9   4.12018658e+04 -5.05091492e+05  2.72e-02 1.41e-09  2.74e+00     5s\n",
      "  10   3.21303744e+04 -2.23685054e+05  8.83e-03 5.28e-10  1.28e+00     6s\n",
      "  11   2.27854302e+04 -9.72688361e+04  2.82e-03 2.38e-10  6.00e-01     6s\n",
      "  12   1.56363112e+04 -3.52499019e+04  9.74e-04 9.69e-11  2.54e-01     6s\n",
      "  13   1.34414565e+04 -2.46232928e+04  6.99e-04 7.59e-11  1.90e-01     6s\n",
      "  14   1.23268133e+04 -1.47169013e+04  5.48e-04 5.50e-11  1.35e-01     6s\n",
      "  15   1.00596665e+04 -5.47327445e+03  3.08e-04 3.64e-11  7.76e-02     7s\n",
      "  16   8.87120715e+03 -1.65073565e+03  1.98e-04 1.09e-11  5.25e-02     7s\n",
      "  17   8.26185446e+03  1.37134335e+03  1.50e-04 1.36e-11  3.44e-02     7s\n",
      "  18   6.80611564e+03  3.06871042e+03  7.55e-05 3.32e-11  1.87e-02     7s\n",
      "  19   6.47478656e+03  3.50437001e+03  5.95e-05 2.25e-11  1.48e-02     7s\n",
      "  20   6.03422886e+03  4.33020639e+03  3.71e-05 2.14e-11  8.51e-03     8s\n",
      "  21   5.74995349e+03  4.92697582e+03  2.12e-05 4.46e-11  4.11e-03     8s\n",
      "  22   5.55924150e+03  5.15778481e+03  1.01e-05 5.37e-11  2.00e-03     8s\n",
      "  23   5.49221772e+03  5.25557238e+03  6.32e-06 4.00e-11  1.18e-03     8s\n",
      "  24   5.43778644e+03  5.31354582e+03  3.36e-06 1.74e-10  6.20e-04     8s\n",
      "  25   5.39491264e+03  5.34852044e+03  1.22e-06 4.62e-10  2.32e-04     8s\n",
      "  26   5.36813620e+03  5.36600413e+03  2.43e-08 4.47e-10  1.06e-05     9s\n",
      "  27   5.36700115e+03  5.36699896e+03  1.28e-09 4.41e-09  1.10e-08     9s\n",
      "  28   5.36700000e+03  5.36700000e+03  2.97e-09 3.88e-09  2.79e-11     9s\n",
      "\n",
      "Barrier solved model in 28 iterations and 8.93 seconds (5.55 work units)\n",
      "Optimal objective 5.36700000e+03\n",
      "\n",
      "\n",
      "Root crossover log...\n",
      "\n",
      "   21012 DPushes remaining with DInf 0.0000000e+00                 9s\n",
      "       0 DPushes remaining with DInf 0.0000000e+00                 9s\n",
      "\n",
      "   22034 PPushes remaining with PInf 0.0000000e+00                 9s\n",
      "       0 PPushes remaining with PInf 0.0000000e+00                10s\n",
      "\n",
      "  Push phase complete: Pinf 0.0000000e+00, Dinf 5.6024525e-12     10s\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   36144    5.3670000e+03   0.000000e+00   0.000000e+00     10s\n",
      "Concurrent spin time: 0.22s\n",
      "\n",
      "Solved with barrier\n",
      "\n",
      "Root relaxation: objective 5.367000e+03, 36144 iterations, 8.07 seconds (3.82 work units)\n",
      "Total elapsed time = 11.11s\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5367.00000    0 5490 31455.0000 5367.00000  82.9%     -   13s\n",
      "H    0     0                    30955.000000 5367.00000  82.7%     -   13s\n",
      "     0     0 6463.77606    0 17979 30955.0000 6463.77606  79.1%     -   84s\n",
      "H    0     0                    30455.000000 6463.77606  78.8%     -   84s\n",
      "H    0     0                    19757.805758 6463.77606  67.3%     -   84s\n",
      "     0     0 6512.89821    0 20050 19757.8058 6512.89821  67.0%     -  100s\n",
      "     0     0 6519.89432    0 19969 19757.8058 6519.89432  67.0%     -  110s\n",
      "     0     0 6519.90687    0 19927 19757.8058 6519.90687  67.0%     -  110s\n",
      "     0     0 6554.58563    0 10724 19757.8058 6554.58563  66.8%     -  123s\n",
      "     0     0 6565.04701    0 10850 19757.8058 6565.04701  66.8%     -  126s\n",
      "     0     0 6565.84698    0 10857 19757.8058 6565.84698  66.8%     -  128s\n",
      "     0     0 6565.84816    0 10857 19757.8058 6565.84816  66.8%     -  128s\n",
      "     0     0 6573.54173    0 11067 19757.8058 6573.54173  66.7%     -  132s\n",
      "H    0     0                    13679.909258 6573.54173  51.9%     -  133s\n",
      "     0     0 6576.83193    0 11013 13679.9093 6576.83193  51.9%     -  135s\n",
      "     0     0 6576.94038    0 11024 13679.9093 6576.94038  51.9%     -  136s\n",
      "     0     0 6580.45369    0 11045 13679.9093 6580.45369  51.9%     -  140s\n",
      "     0     0 6582.14381    0 10975 13679.9093 6582.14381  51.9%     -  142s\n",
      "     0     0 6582.53352    0 10999 13679.9093 6582.53352  51.9%     -  143s\n",
      "     0     0 6584.23571    0 10941 13679.9093 6584.23571  51.9%     -  145s\n",
      "H    0     0                    13245.000000 6584.23571  50.3%     -  145s\n",
      "     0     0 6585.02059    0 10903 13245.0000 6585.02059  50.3%     -  146s\n",
      "     0     0 6585.10904    0 10898 13245.0000 6585.10904  50.3%     -  146s\n",
      "     0     0 6585.46834    0 10922 13245.0000 6585.46834  50.3%     -  149s\n",
      "     0     0 6585.46834    0 10682 13245.0000 6585.46834  50.3%     -  153s\n",
      "H    0     0                    11655.000000 6585.46834  43.5%     -  173s\n",
      "H    0     0                    9537.0000000 6585.46834  30.9%     -  178s\n",
      "     0     2 6585.46834    0 10536 9537.00000 6585.46834  30.9%     -  181s\n",
      "     1     4 6750.51407    1 17247 9537.00000 6586.44166  30.9% 219104  259s\n",
      "     3     8 8708.38650    2 11284 9537.00000 6750.54506  29.2% 189165  281s\n",
      "     7    16 8743.96418    3 11895 9537.00000 6765.74402  29.1% 107777  305s\n",
      "    15    18 9033.50410    4 9964 9537.00000 6766.05351  29.1% 73671  405s\n",
      "    23    24 9284.90631    4 11216 9537.00000 6766.08455  29.1% 70412  434s\n",
      "    31    24 9037.53713    5 7352 9537.00000 6766.77219  29.0% 56856  465s\n",
      "H   33    24                    7317.0000000 6766.77219  7.52% 54347  465s\n",
      "    51    24 7070.46131    6 18387 7317.00000 6775.69955  7.40% 40966  524s\n",
      "H   61    33                    6817.0000000 6775.69955  0.61% 35851  536s\n",
      "\n",
      "Cutting planes:\n",
      "  Cover: 429\n",
      "  MIR: 4519\n",
      "  StrongCG: 312\n",
      "  GUB cover: 847\n",
      "  Zero half: 1703\n",
      "  RLT: 3\n",
      "  Relax-and-lift: 4756\n",
      "\n",
      "Explored 90 nodes (2811350 simplex iterations) in 536.40 seconds (1433.73 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 10: 6817 7317 9537 ... 31455\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.817000000000e+03, best bound 6.817000000000e+03, gap 0.0000%\n",
      "\n",
      "Wrote result file '/var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/d404a5797c1a48d181c47ab9d78676e1-pulp.sol'\n",
      "\n",
      "time for <class 'milp_models.dynamic_problem_multi_labor_recourse'> 579.4670829772949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/letshopethisworks2/Documents/Phd Paper material/MMABPWW/milp_models.py:595: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  task_assignments_df = task_assignments_df.groupby(['scenario','station', 'sequence_loc','model'])['task', 'task_times'].agg({'task':lambda x: ','.join(x.astype(str)), 'task_times': sum }).reset_index()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_from_config(config_file, seed = None, scenario_generator= make_scenario_tree, base_file_name = 'test', **kwargs):\n",
    "   test_instances = []\n",
    "   with open(config_file) as f:\n",
    "      print('Opening config file', config_file)\n",
    "      print('base_file_name', base_file_name)\n",
    "      #Removes file extension from config file name\n",
    "      conf_name = config_file.split('.')[0].split('/')[-1]\n",
    "      print('conf_name', conf_name)\n",
    "      xp_yaml = yaml.load(f, Loader=yaml.FullLoader)\n",
    "      #configuring problem\n",
    "      SEQUENCE_LENGTH = xp_yaml['sequence_length']\n",
    "      NO_WORKERS = xp_yaml['max_workers']\n",
    "      NO_STATIONS = xp_yaml['no_stations']\n",
    "      WORKER_COST = xp_yaml['worker_cost']\n",
    "      RECOURSE_COST = xp_yaml['recourse_cost']\n",
    "      #configuring scenario tree generator\n",
    "      tree_kwargs = {}\n",
    "      if xp_yaml['scenario_generator']== 'monte_carlo_tree':\n",
    "         scenario_generator = monte_carlo_tree\n",
    "         tree_kwargs['n_samples'] = xp_yaml['scenario_generator']['n_samples']\n",
    "         tree_kwargs['enum_depth'] = xp_yaml['scenario_generator']['enum_depth']\n",
    "      else:\n",
    "         scenario_generator = make_scenario_tree\n",
    "      group_counter = 0\n",
    "      #copying config file to results folder\n",
    "      print('copying config file to results folder',  config_file, base_file_name +'/'+ config_file)\n",
    "      shutil.copyfile(config_file, base_file_name +'/'+ conf_name + '_config.yaml')\n",
    "      for milp_model in xp_yaml['milp_models']:\n",
    "         if milp_model == 'model_dependent_problem_multi_labor_recourse':\n",
    "            milp_model = model_dependent_problem_multi_labor_recourse\n",
    "            file_name = base_file_name + '/model_dependent/'\n",
    "            #if model_dependent directory does not exist, make it\n",
    "            if not os.path.exists(file_name):\n",
    "               os.makedirs(file_name)\n",
    "            file_name = file_name + 'md_'\n",
    "         elif milp_model == 'dynamic_problem_multi_labor_recourse':\n",
    "            milp_model = dynamic_problem_multi_labor_recourse\n",
    "            file_name = base_file_name + '/dynamic/'\n",
    "            #if model_dependent directory does not exist, make it\n",
    "            if not os.path.exists(file_name):\n",
    "               os.makedirs(file_name)\n",
    "            file_name = file_name + 'd_'\n",
    "         elif milp_model == 'model_dependent_problem_linear_labor_recourse':\n",
    "            milp_model = model_dependent_problem_linear_labor_recourse\n",
    "            file_name = base_file_name + '/model_dependent_linear/'\n",
    "            #if model_dependent directory does not exist, make it\n",
    "            if not os.path.exists(file_name):\n",
    "               os.makedirs(file_name)\n",
    "            file_name = file_name + 'lmd_'\n",
    "         elif milp_model == 'dynamic_problem_linear_labor_recourse':\n",
    "            milp_model = dynamic_problem_linear_labor_recourse\n",
    "            file_name = base_file_name + '/dynamic_linear/'\n",
    "            #if model_dependent directory does not exist, make it\n",
    "            if not os.path.exists(file_name):\n",
    "               os.makedirs(file_name)\n",
    "            file_name = file_name + 'ld_'\n",
    "         else:\n",
    "            raise ValueError('milp_model not recognized')\n",
    "         start_time = time.time()\n",
    "         for model_file in xp_yaml['model_files']:\n",
    "            print('running milp_model', milp_model)\n",
    "            test_instance = MultiModelTaskTimesInstance( init_type='model_data_from_yaml',\n",
    "                                             model_yaml=model_file, \n",
    "                                             sequence_length=SEQUENCE_LENGTH, \n",
    "                                             max_workers=NO_WORKERS, \n",
    "                                             no_stations=NO_STATIONS, \n",
    "                                             worker_cost=WORKER_COST, \n",
    "                                             recourse_cost=RECOURSE_COST)\n",
    "            print('Running instance', test_instance.name)\n",
    "            test_instances.append(test_instance)\n",
    "            #create equipment\n",
    "            if xp_yaml['equipment_files']:\n",
    "               print('loading equipment from', xp_yaml['equipment_files'][0])\n",
    "               equipment = Equipment(generation_method='import_yaml', equipment_file=xp_yaml['equipment_files'][0])\n",
    "               if equipment.no_tasks != test_instance.no_tasks:\n",
    "                  print('equipmen no tasks', equipment.no_tasks)\n",
    "                  print('instance no tasks', test_instance.no_tasks)\n",
    "                  #raises an error if the equipment and instance have different number of tasks\n",
    "                  raise ValueError('Equipment and instance have different number of tasks')\n",
    "            else:\n",
    "               print('creating equipment')\n",
    "               NO_EQUIPMENT = xp_yaml['no_equipment']\n",
    "               equipment = Equipment(test_instance.no_tasks, \n",
    "                                     NO_EQUIPMENT, \n",
    "                                     NO_STATIONS, \n",
    "                                     generate_equipment, \n",
    "                                     seed)\n",
    "            #create scenario tree\n",
    "            print('generating scenario tree')\n",
    "            model_mixtures = test_instance.model_mixtures\n",
    "            scenario_tree_graph, final_sequences = scenario_generator(SEQUENCE_LENGTH, model_mixtures, **tree_kwargs)\n",
    "            print('defining problem')\n",
    "            milp_prob = milp_model(problem_instance = test_instance, \n",
    "                                   equipment_instance = equipment, \n",
    "                                   sequence_length=SEQUENCE_LENGTH, \n",
    "                                   prod_sequences=final_sequences)\n",
    "            #prob = milp_model(test_instance, equipment,test_instance.no_tasks, NO_WORKERS, NO_STATIONS, TAKT_TIME, SEQUENCE_LENGTH, final_sequences, worker_cost=WORKER_COST)\n",
    "            start = timer()\n",
    "            solver = plp.GUROBI_CMD(options=[ ('LogFile', file_name+conf_name + str(group_counter) + \".log\")])#\n",
    "            milp_prob.solve(solver=solver, \n",
    "                            file_name=file_name + conf_name+ str(group_counter))\n",
    "            end = timer()\n",
    "            result = milp_prob.get_obj_val_dict()\n",
    "            result['run_time'] = end - start\n",
    "            result_df = pd.DataFrame([result])\n",
    "            if group_counter == 0:\n",
    "               results_df = result_df.copy()\n",
    "               \n",
    "            else:\n",
    "               results_df = pd.concat([results_df, result_df])\n",
    "            output_path=file_name + conf_name +  '_results.csv'\n",
    "            result_df.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n",
    "            group_counter += 1\n",
    "         end_time = time.time()\n",
    "         print('time for', milp_model, end_time - start_time)\n",
    "   return 1\n",
    "\n",
    "today = datetime.today().strftime('%Y_%m_%d')\n",
    "xp_name = f\"xp_{today}_mc_debug\"\n",
    "if not os.path.exists('model_runs/'+ xp_name):\n",
    "   os.makedirs('model_runs/'+xp_name)\n",
    "   \n",
    "file_name = 'model_runs/'+xp_name\n",
    "run_from_config('SALBP_benchmark/MM_instances/small_instance_debug.yaml',\n",
    "           base_file_name=file_name)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary = glt.parse(\"model_runs/xp_2023_10_06_config_test2/dynamic_small_instance_config0.log\")\n",
    "nl = summary.progress(\"nodelog\")\n",
    "nl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "plot_incumbent_vs_bound(\"model_runs/xp_2023_10_06_config_test2/\", \"dynamic_small_instance_config0.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "NO_EQUIPMENT = 4\n",
    "seed = 1\n",
    "NO_WORKERS =4\n",
    "NO_STATIONS = 4\n",
    "WORKER_COST = 500\n",
    "RECOURSE_COST = WORKER_COST * 2\n",
    "TAKT_TIME = 1000\n",
    "SEQUENCE_LENGTH = 4\n",
    "#MODEL_MIXTURES = {'A':0.34, 'B':0.33, 'C':0.33}\n",
    "MODEL_MIXTURES = {'A':0.60, 'B':0.40}\n",
    "\n",
    "instances = [\n",
    "    {'fp': 'SALBP_benchmark/small data set_n=20/instance_n=20_200.alb', 'name': 'A', 'probability': 0.6},\n",
    "     #{'fp': 'SALBP_benchmark/small data set_n=20/instance_n=20_17.alb', 'name': 'C', 'probability': 0.4},\n",
    "     {'fp': 'SALBP_benchmark/small data set_n=20/instance_n=20_16.alb', 'name': 'B', 'probability': 0.4}]\n",
    "#mm_instance = MultiModelInstance( init_type='from_yaml',mm_yaml_file='/Users/letshopethisworks2/Documents/Phd Paper material/MMABPWW/SALBP_benchmark/MM_instances/n=20_1_n=20_2_n=20_3_.yaml', sequence_length=SEQUENCE_LENGTH, max_workers=NO_WORKERS, no_stations=NO_STATIONS, worker_cost=WORKER_COST, recourse_cost=RECOURSE_COST)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_instances = get_instance_list('SALBP_benchmark/MM_instances/model_data', extension='.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_groups = pair_instances(instances, MODEL_MIXTURES)\n",
    "mm_instance = MultiModelTaskTimesInstance(model_dicts=instances, takt_time=TAKT_TIME, sequence_length=SEQUENCE_LENGTH, max_workers=NO_WORKERS, no_stations=NO_STATIONS, worker_cost=WORKER_COST, recourse_cost=RECOURSE_COST)\n",
    "\n",
    "print(mm_instance.name)\n",
    "print(mm_instance.data)\n",
    "print(mm_instance.takt_time)\n",
    "\n",
    "\n",
    "mm_instance.genererate_task_times(change_func=change_task_times_linear)\n",
    "\n",
    "mm_instance.model_data_to_yaml(f'SALBP_benchmark/MM_instances/model_data/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_instance = MultiModelTaskTimesInstance(init_type = 'instance_from_yaml',instance_config_yaml='SALBP_benchmark/MM_instances/small_instance_config.yaml', model_yaml= 'SALBP_benchmark/MM_instances/model_data/n=20_200_n=20_25.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_instance.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mm_instance.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equip = Equipment(mm_instance.no_tasks, NO_EQUIPMENT, NO_STATIONS,  seed, mean = 200, variance = 100)\n",
    "equip.to_yaml(f'SALBP_benchmark/MM_instances/equipment_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equip2 = Equipment(mm_instance.all_tasks, NO_EQUIPMENT, NO_STATIONS, generation_method='import_yaml', equipment_file='SALBP_benchmark/MM_instances/equipment_data/random_E4_S4_seed42.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_MALBPW_config('small_instance', NO_WORKERS, NO_STATIONS, \n",
    "                   WORKER_COST, RECOURSE_COST, SEQUENCE_LENGTH, \n",
    "                   'SALBP_benchmark/MM_instances/small_instance_config.yaml', \n",
    "                   equipment_files =[ 'SALBP_benchmark/MM_instances/equipment_data/random_O20_E4_S4_seed42.yaml'], instance_files=small_instances )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equip2.r_oe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance_groups = pair_instances(instance_list, MODEL_MIXTURES)\n",
    "# group = instance_groups[0]\n",
    "# test_instance = MultiModelInstance(group, takt_time=TAKT_TIME, sequence_length=SEQUENCE_LENGTH, \n",
    "#                                    max_workers=NO_WORKERS, no_stations=NO_STATIONS, worker_cost=WORKER_COST)\n",
    "# print('Running instance', test_instance.name)\n",
    "\n",
    "# #create equipment\n",
    "# print('creating equipment')\n",
    "# equipment = Equipment(test_instance.all_tasks, NO_EQUIPMENT, NO_STATIONS, generate_equipment, seed)\n",
    "# #create scenario tree\n",
    "# print('generating scenario tree')\n",
    "# scenario_tree_graph, final_sequences = make_scenario_tree(SEQUENCE_LENGTH, MODEL_MIXTURES)\n",
    "# print('defining problem')\n",
    "# milp_prob = dynamic_problem_linear_labour(problem_instance = test_instance, \n",
    "#                                           equipment_instance = equipment, sequence_length=SEQUENCE_LENGTH, prod_sequences=final_sequences)\n",
    "# #prob = milp_model(test_instance, equipment,test_instance.no_tasks, NO_WORKERS, NO_STATIONS, TAKT_TIME, SEQUENCE_LENGTH, final_sequences, worker_cost=WORKER_COST)\n",
    "# solver = plp.GUROBI_CMD(options=[('TimeLimit', 30)])#\n",
    "# milp_prob.solve(solver=solver, file_name=file_name + str('blarg'))\n",
    "# result = milp_prob.get_obj_val_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "task_assignment, labor_assignment = milp_prob.generate_report(file_name=file_name + str('blarg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labor_assignment[labor_assignment['scenario'] == '1'].head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm starting dynamic with model dependent solution for faster solutions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_warm_start_model(model_instance_obj, start_solution, equipment_instance,no_tasks, \n",
    "                                     NO_WORKERS, NO_STATIONS,takt_time, sequence_length, \n",
    "                                     prod_sequences, worker_cost =100, fix_task_assignment = False):\n",
    "    '''Uses provided task assignments to warm start the dynamic task assignment version of the problem\n",
    "    For now we assume that the start solution is the model dependent version of the problem'''\n",
    "\n",
    "    print('Writing problem')\n",
    "    print('Number of tasks:', no_tasks, 'Number of workers:', NO_WORKERS, '\\n','Number of stations:', NO_STATIONS, 'Takt time:', takt_time, 'Sequence length:', sequence_length, 'worker_cost:', worker_cost)\n",
    "    workers = list(range(0, NO_WORKERS+1))\n",
    "    stations = list(range(NO_STATIONS))\n",
    "    model_instance = model_instance_obj.data\n",
    "    c_se = equipment_instance.c_se\n",
    "    R_oe = equipment_instance.r_oe\n",
    "    equipment = list( range(R_oe.shape[1]))\n",
    "    takts = list(range(sequence_length+NO_STATIONS-1))\n",
    "    u_se = plp.LpVariable.dicts('u_se', (stations, equipment), lowBound=0, cat='Binary')\n",
    "    b_wtsl = plp.LpVariable.dicts('b_wtsl', (prod_sequences.keys(), takts, stations, workers), lowBound=0, cat='Binary') \n",
    "    #TODO: maybe make this dictionary work different number of tasks for each model\n",
    "    x_wsoj = plp.LpVariable.dicts('x_wsoj', (prod_sequences.keys(), stations, range(no_tasks), range(sequence_length) ), lowBound=0, cat='Binary')\n",
    "    Y_w = plp.LpVariable.dicts('Y_w', (prod_sequences.keys()), lowBound=0, cat='Integer')\n",
    "    #Adding in the start solution\n",
    "    print('adding in start solution')\n",
    "    for v in start_solution.variables():\n",
    "        if 'x_soi' in v.name:\n",
    "            model_md = v.name.split('_')[4]\n",
    "            #change the task number to match with the instances\n",
    "            o = int(v.name.split('_')[3])\n",
    "            s = int(v.name.split('_')[2])\n",
    "            for w in prod_sequences.keys():\n",
    "                #setting x_wsoj values from the start solution\n",
    "                for j, model in enumerate(prod_sequences[w]['sequence']):\n",
    "                    if model_md == model:\n",
    "                        x_wsoj[w][s][o][j].setInitialValue(round(v.varValue))\n",
    "        elif 'b_wtsl' in v.name:\n",
    "            w = int(v.name.split('_')[2])\n",
    "            t = int(v.name.split('_')[3])\n",
    "            s = int(v.name.split('_')[4])\n",
    "            l = int(v.name.split('_')[5])\n",
    "            b_wtsl[w][t][s][l].setInitialValue(round(v.varValue)) \n",
    "        elif 'Y_w' in v.name:\n",
    "            w = int(v.name.split('_')[2])\n",
    "            Y_w[w].setInitialValue(round(v.varValue))\n",
    "        elif 'u_se' in v.name:\n",
    "            print('equipment', v.name.split('_'))\n",
    "            s = int(v.name.split('_')[2])\n",
    "            e = int(v.name.split('_')[3])\n",
    "            u_se[s][e].setInitialValue(round(v.varValue))\n",
    "    #Defining LP problem\n",
    "    prob = plp.LpProblem(\"stochastic_problem\", plp.LpMinimize)\n",
    "    #Objective function\n",
    "    prob += (plp.lpSum([c_se[s][e]*u_se[s][e]\n",
    "                         for s in stations\n",
    "                           for e in equipment]\n",
    "                      +\n",
    "                      [prod_sequences[w]['probability']*Y_w[w]* worker_cost\n",
    "                         for w in prod_sequences.keys()\n",
    "                        ]),\n",
    "                \"Total cost\")\n",
    "    #Constraints\n",
    "    #Constraint 1 -- Must hire Y workers if we use Y workers in a given takt\n",
    "    for w in prod_sequences.keys():\n",
    "        for t in takts:\n",
    "            prob += (plp.lpSum([l*b_wtsl[w][t][s][l] for s in stations for l in workers]) <= Y_w[w], f'Y_w_{w}_{t}')\n",
    "    #Constraint 2 -- can only assign l number of workers to a station for a given scenario and stage\n",
    "    for w in prod_sequences.keys():\n",
    "        for t in takts:\n",
    "            for s in stations:\n",
    "                prob += (plp.lpSum([b_wtsl[w][t][s][l] for l in workers]) == 1, f'b_wtsl_{w}_{t}_{s}')\n",
    "        #Constraint 3 all tasks must be assigned to a station\n",
    "    for w in prod_sequences.keys():\n",
    "        for j, model in enumerate(prod_sequences[w]['sequence']):\n",
    "            #Not strictly necessary if all models have the same number of tasks, could have just looped over no tasks\n",
    "            #but this is more general\n",
    "            for o in range(model_instance[model]['num_tasks']): \n",
    "                prob += (plp.lpSum([x_wsoj[w][s][o][j] for s in stations]) == 1, f'x_wsoj_{w}_s_{o}_{j}')\n",
    "        #Constraint 4 -- sum of task times for assigned tasks must be less than takt time times the number of workers for a given station\n",
    "    for w in prod_sequences.keys():\n",
    "        for t in takts:\n",
    "            for s in stations:\n",
    "                #Get the model at the current scenario, stage, and station\n",
    "                if 0<= t-s < sequence_length:\n",
    "                    j = t-s\n",
    "                    model = prod_sequences[w]['sequence'][j]\n",
    "                    task_times = model_instance[model]['task_times']\n",
    "                    prob += (plp.lpSum([task_times[o]*x_wsoj[w][s][int(o)-1][j] \n",
    "                                        for o in task_times]) \n",
    "                                        <= \n",
    "                                        takt_time*plp.lpSum([l * b_wtsl[w][t][s][l] for l in workers]), f'task_time_wts_{w}_{t}_{s}')\n",
    "\n",
    "    #Constraint 5 -- tasks can only be assigned to a station with the correct equipment\n",
    "    for w in prod_sequences.keys():\n",
    "        for j, model in enumerate(prod_sequences[w]['sequence']):\n",
    "            for s in stations:\n",
    "                for o in range(model_instance[model]['num_tasks']):\n",
    "                    prob += x_wsoj[w][s][o][j] <= plp.lpSum([R_oe[o][e]*u_se[s][e] for  e in equipment]), f'equipment_wsoj_{w}_{s}_{o}_{j}'\n",
    "        #Constraint 6 -- precedence constraints\n",
    "    for w in prod_sequences.keys():\n",
    "        for j, model in enumerate(prod_sequences[w]['sequence']):\n",
    "            for (pred, suc) in model_instance[model]['precedence_relations']:\n",
    "                prob += (plp.lpSum([ (s+1)  * x_wsoj[w][s][int(pred)-1][j] for s in stations])\n",
    "                         <=  \n",
    "                         plp.lpSum([ (s+1)  * x_wsoj[w][s][int(suc)-1][j] for s in stations]), \n",
    "                         f'task{pred} before task{suc} for model{model}, item {j} seq {w}' )\n",
    "        #Constraint 7 -- non-anticipativity constraints\n",
    "    for w in prod_sequences.keys():\n",
    "        for w_prime in prod_sequences.keys():\n",
    "            if w_prime > w:\n",
    "                add_non_anticipation(prob, w, w_prime , prod_sequences, model_instance, x_wsoj, sequence_length, NO_STATIONS)\n",
    "\n",
    "                \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warm_start_dynamic(instance_list, NO_EQUIPMENT,  NO_WORKERS, NO_STATIONS, WORKER_COST, TAKT_TIME, NO_TAKTS, MODEL_MIXTURES, seed, scenario_generator= make_scenario_tree, file_name = 'test', **kwargs):\n",
    "    instance_groups = pair_instances(instance_list, MODEL_MIXTURES)\n",
    "    print(instance_groups)\n",
    "    test_results = []\n",
    "    group_counter = 0\n",
    "    test_instances = []\n",
    "    instance_results = []\n",
    "    for group in instance_groups:\n",
    "        test_instance = MultiModelInstance(group)\n",
    "        print('Running instances', group)\n",
    "        print('\\n test_instance', test_instance)\n",
    "        test_instances.append(test_instance)\n",
    "        #create equipment\n",
    "        print('creating equipment')\n",
    "        equipment = Equipment(test_instance.all_tasks, NO_EQUIPMENT, NO_STATIONS, generate_equipment, seed)\n",
    "        #create scenario tree\n",
    "        print('generating scenario tree')\n",
    "        scenario_tree_graph, final_sequences = scenario_generator(NO_TAKTS, MODEL_MIXTURES, **kwargs)\n",
    "        print('defining problem')\n",
    "        md_prob = model_dependent_eq_linear_labour(test_instance, equipment,test_instance.no_tasks, NO_WORKERS, NO_STATIONS, TAKT_TIME, NO_TAKTS, final_sequences, worker_cost=WORKER_COST)\n",
    "        print('solving problem')\n",
    "        solver = plp.GUROBI_CMD(options=[('TimeLimit', 300),( 'LPWarmStart',2)])#\n",
    "        md_prob.solve(solver=solver)\n",
    "        print('\\n writing results')\n",
    "        print('model dependent objective value: ', md_prob.objective.value())\n",
    "        print('\\n solving dynamic problem')\n",
    "        dynamic_prob = dynamic_warm_start_model(test_instance, md_prob, equipment,test_instance.no_tasks, NO_WORKERS, NO_STATIONS, TAKT_TIME, NO_TAKTS, final_sequences, worker_cost=WORKER_COST)\n",
    "        dynamic_prob.solve(solver=solver)\n",
    "        md_result = obj_val_dict(group, md_prob.objective.value(),md_prob.status, test_instance.data)\n",
    "        dynamic_result = obj_val_dict(group, dynamic_prob.objective.value(),dynamic_prob.status, test_instance.data)\n",
    "        result = {**md_result, **dynamic_result}\n",
    "        instance_results.append(result)\n",
    "        print('test_instance', test_instance)\n",
    "        out_name = file_name + str(group_counter)\n",
    "        task_assignment, labor_assignment = generate_report_md(md_prob, final_sequences, test_instance.data, out_name + 'md')\n",
    "        task_assignment, labor_assignment = generate_report_dynamic(dynamic_prob, final_sequences, test_instance.data, out_name + 'dynamic')\n",
    "        group_counter += 1\n",
    "\n",
    "    instance_results = pd.DataFrame(instance_results)\n",
    "    instance_results.to_csv(file_name + '_results.csv')\n",
    "    return instance_results, test_instances\n",
    "\n",
    "start_time = time.time()\n",
    "file_name = 'model_runs/'+xp_name+f'/Warm_start_{NO_STATIONS}_E{NO_EQUIPMENT}_L{NO_WORKERS}_T{NO_TAKTS}_C{TAKT_TIME}_LC{WORKER_COST}_'\n",
    "print('writing to ', file_name)\n",
    "results_df, instances = warm_start_dynamic(instance_list, NO_EQUIPMENT,  NO_WORKERS, NO_STATIONS, WORKER_COST, TAKT_TIME, NO_TAKTS, MODEL_MIXTURES, seed, file_name = file_name)\n",
    "warm_start_time= time.time() - start_time\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('time for normal run', normal_time)\n",
    "print('time for warm start run', warm_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heuristic section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructive heuristic for model dependent task assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tasks selection methods\n",
    "def longest_processing_time(model, candidate_list, **kwargs):\n",
    "    max_task_time = 0\n",
    "    for candidate in candidate_list:\n",
    "        if model['task_times'][candidate] > max_task_time:\n",
    "            max_task_time = model['task_times'][candidate]\n",
    "            selected_task = candidate\n",
    "    return selected_task\n",
    "\n",
    "\n",
    "#Methods for the construction heurisitc\n",
    "\n",
    "def calculate_takt_time(model, NO_S, TAKT_TIME):\n",
    "    \"\"\"\n",
    "    Calculate the takt time for the model dependent model\n",
    "    \"\"\"\n",
    "    total_task_time = sum(model['task_times'].values())\n",
    "    new_takt_time = max(total_task_time/NO_S, TAKT_TIME)\n",
    "    return new_takt_time\n",
    "\n",
    "def model_task_assignment(model, all_tasks, NO_S, TAKT_TIME, selection_method, **kwargs):\n",
    "    '''This function assigns the tasks of a model '''\n",
    "    print('model', model)\n",
    "    x_so = np.zeros((NO_S,len(all_tasks)))\n",
    "    new_takt_time = calculate_takt_time( model, NO_S, TAKT_TIME)\n",
    "    prec_matrix = construct_precedence_matrix(model)\n",
    "    number_of_predecessor = np.sum(prec_matrix, axis=0)\n",
    "    for station in range(NO_S):\n",
    "        s_total_assingments = 0\n",
    "        while s_total_assingments < new_takt_time and np.any(number_of_predecessor != -1):\n",
    "            candidate_list = []\n",
    "            for task in model['task_times']:\n",
    "                task_in = int(task)-1\n",
    "                if number_of_predecessor[task_in] == 0:\n",
    "                    candidate_list.append(task)\n",
    "            selected_task = selection_method(model, candidate_list,  **kwargs)\n",
    "            selected_task_in = int(selected_task)-1\n",
    "            x_so[station, selected_task_in] = 1\n",
    "            s_total_assingments += model['task_times'][selected_task]\n",
    "            number_of_predecessor -= prec_matrix[selected_task_in]\n",
    "            number_of_predecessor[selected_task_in] = -1\n",
    "        #If all the elements in number of predecessor are -1, then all tasks are assigned\n",
    "        if np.all(number_of_predecessor == -1):\n",
    "            break\n",
    "    return x_so\n",
    "\n",
    "def constructive_heurisitc(instance, NO_S, TAKT_TIME, selection_method):\n",
    "    \"\"\"\n",
    "    Constructive heuristic for the model dependent model\n",
    "    \"\"\"\n",
    "    print('instance', instance)\n",
    "    all_tasks = get_task_union(instance, 'A', 'B')\n",
    "    print('all_tasks', all_tasks)\n",
    "    assignments = []\n",
    "    #heuristic asssigns tasks for each model in instance\n",
    "    for model in instance:\n",
    "        x_so = model_task_assignment( instance[model], all_tasks, NO_S, TAKT_TIME, selection_method)\n",
    "        assignments.append(x_so)\n",
    "    #combines assignments list into a single numpy array, where eac\n",
    "    x_soi = np.stack(assignments, axis=-1)\n",
    "    return x_soi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_constructive_heuristic(instance_list, NO_S, TAKT_TIME, MODEL_MIXTURES):\n",
    "    \"\"\"\n",
    "    Runs the constructive heuristic for all instances in the instance list\n",
    "    \"\"\"\n",
    "    heuristics = []\n",
    "    instance_groups = pair_instances(instance_list, MODEL_MIXTURES)\n",
    "    for group in instance_groups:\n",
    "        instance = create_instance_pair_stochastic(group)\n",
    "        heuristics.append(constructive_heurisitc(instance, NO_S, TAKT_TIME, longest_processing_time))\n",
    "    return heuristics\n",
    "\n",
    "def solve_from_initial_task_asssingments(instance, NO_S, TAKT_TIME, task_assignments):\n",
    "    \"\"\"\n",
    "    Solves the instance using the given task assignments\n",
    "    \"\"\"\n",
    "\n",
    "instance_list = [ \"SALBP_benchmark/small data set_n=20/instance_n=20_1.alb\",\n",
    "   \"SALBP_benchmark/small data set_n=20/instance_n=20_2.alb\",\n",
    "   ]\n",
    "NO_S = 4\n",
    "MODEL_MIXTURES = {'A': 0.5, 'B': 0.5}\n",
    "results_heuristic = run_constructive_heuristic(instance_list, NO_S, TAKT_TIME, MODEL_MIXTURES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix and Optimize LNS, starting with model dependent and going to dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will take a solution of the model depedent problem and use it as the first solution for the dynamic case. Here, instead of reoptimizing the entire thing, we choose 2-3 adjacent stations and reoptimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_and_optimize(instance, seed, no_iterations = 10, scenario_generator= make_scenario_tree, file_name = 'fix_and_optimize test', **kwargs):\n",
    "    \"\"\"\n",
    "    Fixes the task assignments and solves the instance\n",
    "    \"\"\"\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
