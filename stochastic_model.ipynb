{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pulp as plp\n",
    "import networkx as nx\n",
    "from ALB_instance_tools import *\n",
    "from report_functions import *\n",
    "from milp_models import *\n",
    "from scenario_trees import *\n",
    "from collections import namedtuple\n",
    "import glob\n",
    "import os\n",
    "import string\n",
    "import time\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from timeit import default_timer as timer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening config file SALBP_benchmark/MM_instances/small_instance_debug.yaml\n",
      "base_file_name model_runs/xp_2023_12_03_mc_debug\n",
      "conf_name small_instance_debug\n",
      "copying config file to results folder SALBP_benchmark/MM_instances/small_instance_debug.yaml model_runs/xp_2023_12_03_mc_debug/SALBP_benchmark/MM_instances/small_instance_debug.yaml\n",
      "\n",
      "\n",
      "\n",
      "running milp_model <class 'milp_models.model_dependent_problem_linear_labor_recourse'>\n",
      "using this file SALBP_benchmark/MM_instances/model_data/small_instances/2_models/n=20_1_n=20_2.yaml\n",
      "Running instance n=20_1_n=20_2\n",
      "loading equipment from SALBP_benchmark/MM_instances/equipment_data/random_O20_E4_S4_seed42.yaml\n",
      "generating scenario tree\n",
      "defining problem\n",
      "Set parameter TimeLimit to value 600\n",
      "Set parameter LogFile to value \"model_runs/xp_2023_12_03_mc_debug/model_dependent_linear/lmd_small_instance_debug0.log\"\n",
      "Using license file /Users/letshopethisworks2/gurobi.lic\n",
      "\n",
      "Gurobi Optimizer version 10.0.2 build v10.0.2rc0 (mac64[rosetta2])\n",
      "Copyright (c) 2023, Gurobi Optimization, LLC\n",
      "\n",
      "Read LP format model from file /var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/4da19b5dd8e54cc9aa3c0bacea0548fb-pulp.lp\n",
      "Reading time = 0.01 seconds\n",
      "Total_cost: 1051 rows, 641 columns, 7432 nonzeros\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 1051 rows, 641 columns and 7432 nonzeros\n",
      "Model fingerprint: 0x19116d53\n",
      "Variable types: 0 continuous, 641 integer (176 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+03]\n",
      "  Objective range  [8e+00, 6e+03]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Presolve removed 448 rows and 192 columns\n",
      "Presolve time: 0.02s\n",
      "Presolved: 603 rows, 449 columns, 6722 nonzeros\n",
      "Variable types: 0 continuous, 449 integer (176 binary)\n",
      "Found heuristic solution: objective 15637.000000\n",
      "Found heuristic solution: objective 7730.0000000\n",
      "\n",
      "Root relaxation: objective 5.553449e+03, 688 iterations, 0.01 seconds (0.02 work units)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/letshopethisworks2/Documents/Phd Paper material/MMABPWW/ALB_instance_tools.py:153: UserWarning: Model probabilities do not sum to 1: 0.9999999999999999\n",
      "  warnings.warn(f'Model probabilities do not sum to 1: {total_probability}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5553.44915    0  258 7730.00000 5553.44915  28.2%     -    0s\n",
      "H    0     0                    6817.0000000 6768.17206  0.72%     -    0s\n",
      "     0     0 6817.00000    0   67 6817.00000 6817.00000  0.00%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 16\n",
      "  Cover: 8\n",
      "  Implied bound: 64\n",
      "  Clique: 64\n",
      "  MIR: 81\n",
      "  GUB cover: 4\n",
      "  RLT: 8\n",
      "\n",
      "Explored 1 nodes (941 simplex iterations) in 0.08 seconds (0.07 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 6817 7730 15637 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.817000000000e+03, best bound 6.817000000000e+03, gap 0.0000%\n",
      "\n",
      "Wrote result file '/var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/4da19b5dd8e54cc9aa3c0bacea0548fb-pulp.sol'\n",
      "\n",
      "here are the x_soi variables\n",
      "{0: {0: {'A': x_soi_0_0_A, 'B': x_soi_0_0_B}, 1: {'A': x_soi_0_1_A, 'B': x_soi_0_1_B}, 2: {'A': x_soi_0_2_A, 'B': x_soi_0_2_B}, 3: {'A': x_soi_0_3_A, 'B': x_soi_0_3_B}, 4: {'A': x_soi_0_4_A, 'B': x_soi_0_4_B}, 5: {'A': x_soi_0_5_A, 'B': x_soi_0_5_B}, 6: {'A': x_soi_0_6_A, 'B': x_soi_0_6_B}, 7: {'A': x_soi_0_7_A, 'B': x_soi_0_7_B}, 8: {'A': x_soi_0_8_A, 'B': x_soi_0_8_B}, 9: {'A': x_soi_0_9_A, 'B': x_soi_0_9_B}, 10: {'A': x_soi_0_10_A, 'B': x_soi_0_10_B}, 11: {'A': x_soi_0_11_A, 'B': x_soi_0_11_B}, 12: {'A': x_soi_0_12_A, 'B': x_soi_0_12_B}, 13: {'A': x_soi_0_13_A, 'B': x_soi_0_13_B}, 14: {'A': x_soi_0_14_A, 'B': x_soi_0_14_B}, 15: {'A': x_soi_0_15_A, 'B': x_soi_0_15_B}, 16: {'A': x_soi_0_16_A, 'B': x_soi_0_16_B}, 17: {'A': x_soi_0_17_A, 'B': x_soi_0_17_B}, 18: {'A': x_soi_0_18_A, 'B': x_soi_0_18_B}, 19: {'A': x_soi_0_19_A, 'B': x_soi_0_19_B}}, 1: {0: {'A': x_soi_1_0_A, 'B': x_soi_1_0_B}, 1: {'A': x_soi_1_1_A, 'B': x_soi_1_1_B}, 2: {'A': x_soi_1_2_A, 'B': x_soi_1_2_B}, 3: {'A': x_soi_1_3_A, 'B': x_soi_1_3_B}, 4: {'A': x_soi_1_4_A, 'B': x_soi_1_4_B}, 5: {'A': x_soi_1_5_A, 'B': x_soi_1_5_B}, 6: {'A': x_soi_1_6_A, 'B': x_soi_1_6_B}, 7: {'A': x_soi_1_7_A, 'B': x_soi_1_7_B}, 8: {'A': x_soi_1_8_A, 'B': x_soi_1_8_B}, 9: {'A': x_soi_1_9_A, 'B': x_soi_1_9_B}, 10: {'A': x_soi_1_10_A, 'B': x_soi_1_10_B}, 11: {'A': x_soi_1_11_A, 'B': x_soi_1_11_B}, 12: {'A': x_soi_1_12_A, 'B': x_soi_1_12_B}, 13: {'A': x_soi_1_13_A, 'B': x_soi_1_13_B}, 14: {'A': x_soi_1_14_A, 'B': x_soi_1_14_B}, 15: {'A': x_soi_1_15_A, 'B': x_soi_1_15_B}, 16: {'A': x_soi_1_16_A, 'B': x_soi_1_16_B}, 17: {'A': x_soi_1_17_A, 'B': x_soi_1_17_B}, 18: {'A': x_soi_1_18_A, 'B': x_soi_1_18_B}, 19: {'A': x_soi_1_19_A, 'B': x_soi_1_19_B}}, 2: {0: {'A': x_soi_2_0_A, 'B': x_soi_2_0_B}, 1: {'A': x_soi_2_1_A, 'B': x_soi_2_1_B}, 2: {'A': x_soi_2_2_A, 'B': x_soi_2_2_B}, 3: {'A': x_soi_2_3_A, 'B': x_soi_2_3_B}, 4: {'A': x_soi_2_4_A, 'B': x_soi_2_4_B}, 5: {'A': x_soi_2_5_A, 'B': x_soi_2_5_B}, 6: {'A': x_soi_2_6_A, 'B': x_soi_2_6_B}, 7: {'A': x_soi_2_7_A, 'B': x_soi_2_7_B}, 8: {'A': x_soi_2_8_A, 'B': x_soi_2_8_B}, 9: {'A': x_soi_2_9_A, 'B': x_soi_2_9_B}, 10: {'A': x_soi_2_10_A, 'B': x_soi_2_10_B}, 11: {'A': x_soi_2_11_A, 'B': x_soi_2_11_B}, 12: {'A': x_soi_2_12_A, 'B': x_soi_2_12_B}, 13: {'A': x_soi_2_13_A, 'B': x_soi_2_13_B}, 14: {'A': x_soi_2_14_A, 'B': x_soi_2_14_B}, 15: {'A': x_soi_2_15_A, 'B': x_soi_2_15_B}, 16: {'A': x_soi_2_16_A, 'B': x_soi_2_16_B}, 17: {'A': x_soi_2_17_A, 'B': x_soi_2_17_B}, 18: {'A': x_soi_2_18_A, 'B': x_soi_2_18_B}, 19: {'A': x_soi_2_19_A, 'B': x_soi_2_19_B}}, 3: {0: {'A': x_soi_3_0_A, 'B': x_soi_3_0_B}, 1: {'A': x_soi_3_1_A, 'B': x_soi_3_1_B}, 2: {'A': x_soi_3_2_A, 'B': x_soi_3_2_B}, 3: {'A': x_soi_3_3_A, 'B': x_soi_3_3_B}, 4: {'A': x_soi_3_4_A, 'B': x_soi_3_4_B}, 5: {'A': x_soi_3_5_A, 'B': x_soi_3_5_B}, 6: {'A': x_soi_3_6_A, 'B': x_soi_3_6_B}, 7: {'A': x_soi_3_7_A, 'B': x_soi_3_7_B}, 8: {'A': x_soi_3_8_A, 'B': x_soi_3_8_B}, 9: {'A': x_soi_3_9_A, 'B': x_soi_3_9_B}, 10: {'A': x_soi_3_10_A, 'B': x_soi_3_10_B}, 11: {'A': x_soi_3_11_A, 'B': x_soi_3_11_B}, 12: {'A': x_soi_3_12_A, 'B': x_soi_3_12_B}, 13: {'A': x_soi_3_13_A, 'B': x_soi_3_13_B}, 14: {'A': x_soi_3_14_A, 'B': x_soi_3_14_B}, 15: {'A': x_soi_3_15_A, 'B': x_soi_3_15_B}, 16: {'A': x_soi_3_16_A, 'B': x_soi_3_16_B}, 17: {'A': x_soi_3_17_A, 'B': x_soi_3_17_B}, 18: {'A': x_soi_3_18_A, 'B': x_soi_3_18_B}, 19: {'A': x_soi_3_19_A, 'B': x_soi_3_19_B}}}\n",
      "\n",
      "\n",
      "\n",
      "running milp_model <class 'milp_models.model_dependent_problem_linear_labor_recourse'>\n",
      "using this file SALBP_benchmark/MM_instances/model_data/small_instances/2_models/n=20_2_n=20_3.yaml\n",
      "Running instance n=20_2_n=20_3\n",
      "loading equipment from SALBP_benchmark/MM_instances/equipment_data/random_O20_E4_S4_seed42.yaml\n",
      "generating scenario tree\n",
      "defining problem\n",
      "Set parameter TimeLimit to value 600\n",
      "Set parameter LogFile to value \"model_runs/xp_2023_12_03_mc_debug/model_dependent_linear/lmd_small_instance_debug1.log\"\n",
      "Using license file /Users/letshopethisworks2/gurobi.lic\n",
      "\n",
      "Gurobi Optimizer version 10.0.2 build v10.0.2rc0 (mac64[rosetta2])\n",
      "Copyright (c) 2023, Gurobi Optimization, LLC\n",
      "\n",
      "Read LP format model from file /var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/98ea43d497794260aec3e25e362497c0-pulp.lp\n",
      "Reading time = 0.00 seconds\n",
      "Total_cost: 1053 rows, 641 columns, 7448 nonzeros\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 1053 rows, 641 columns and 7448 nonzeros\n",
      "Model fingerprint: 0x72d6aa29\n",
      "Variable types: 0 continuous, 641 integer (176 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+03]\n",
      "  Objective range  [5e+01, 6e+03]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Presolve removed 448 rows and 192 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 605 rows, 449 columns, 6734 nonzeros\n",
      "Variable types: 0 continuous, 449 integer (176 binary)\n",
      "Found heuristic solution: objective 13129.000000\n",
      "Found heuristic solution: objective 6817.0000000\n",
      "\n",
      "Root relaxation: objective 5.540216e+03, 660 iterations, 0.01 seconds (0.02 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5540.21589    0  247 6817.00000 5540.21589  18.7%     -    0s\n",
      "     0     0     cutoff    0      6817.00000 6817.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (796 simplex iterations) in 0.03 seconds (0.05 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 6817 13129 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.817000000000e+03, best bound 6.817000000000e+03, gap 0.0000%\n",
      "\n",
      "Wrote result file '/var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/98ea43d497794260aec3e25e362497c0-pulp.sol'\n",
      "\n",
      "here are the x_soi variables\n",
      "{0: {0: {'A': x_soi_0_0_A, 'B': x_soi_0_0_B}, 1: {'A': x_soi_0_1_A, 'B': x_soi_0_1_B}, 2: {'A': x_soi_0_2_A, 'B': x_soi_0_2_B}, 3: {'A': x_soi_0_3_A, 'B': x_soi_0_3_B}, 4: {'A': x_soi_0_4_A, 'B': x_soi_0_4_B}, 5: {'A': x_soi_0_5_A, 'B': x_soi_0_5_B}, 6: {'A': x_soi_0_6_A, 'B': x_soi_0_6_B}, 7: {'A': x_soi_0_7_A, 'B': x_soi_0_7_B}, 8: {'A': x_soi_0_8_A, 'B': x_soi_0_8_B}, 9: {'A': x_soi_0_9_A, 'B': x_soi_0_9_B}, 10: {'A': x_soi_0_10_A, 'B': x_soi_0_10_B}, 11: {'A': x_soi_0_11_A, 'B': x_soi_0_11_B}, 12: {'A': x_soi_0_12_A, 'B': x_soi_0_12_B}, 13: {'A': x_soi_0_13_A, 'B': x_soi_0_13_B}, 14: {'A': x_soi_0_14_A, 'B': x_soi_0_14_B}, 15: {'A': x_soi_0_15_A, 'B': x_soi_0_15_B}, 16: {'A': x_soi_0_16_A, 'B': x_soi_0_16_B}, 17: {'A': x_soi_0_17_A, 'B': x_soi_0_17_B}, 18: {'A': x_soi_0_18_A, 'B': x_soi_0_18_B}, 19: {'A': x_soi_0_19_A, 'B': x_soi_0_19_B}}, 1: {0: {'A': x_soi_1_0_A, 'B': x_soi_1_0_B}, 1: {'A': x_soi_1_1_A, 'B': x_soi_1_1_B}, 2: {'A': x_soi_1_2_A, 'B': x_soi_1_2_B}, 3: {'A': x_soi_1_3_A, 'B': x_soi_1_3_B}, 4: {'A': x_soi_1_4_A, 'B': x_soi_1_4_B}, 5: {'A': x_soi_1_5_A, 'B': x_soi_1_5_B}, 6: {'A': x_soi_1_6_A, 'B': x_soi_1_6_B}, 7: {'A': x_soi_1_7_A, 'B': x_soi_1_7_B}, 8: {'A': x_soi_1_8_A, 'B': x_soi_1_8_B}, 9: {'A': x_soi_1_9_A, 'B': x_soi_1_9_B}, 10: {'A': x_soi_1_10_A, 'B': x_soi_1_10_B}, 11: {'A': x_soi_1_11_A, 'B': x_soi_1_11_B}, 12: {'A': x_soi_1_12_A, 'B': x_soi_1_12_B}, 13: {'A': x_soi_1_13_A, 'B': x_soi_1_13_B}, 14: {'A': x_soi_1_14_A, 'B': x_soi_1_14_B}, 15: {'A': x_soi_1_15_A, 'B': x_soi_1_15_B}, 16: {'A': x_soi_1_16_A, 'B': x_soi_1_16_B}, 17: {'A': x_soi_1_17_A, 'B': x_soi_1_17_B}, 18: {'A': x_soi_1_18_A, 'B': x_soi_1_18_B}, 19: {'A': x_soi_1_19_A, 'B': x_soi_1_19_B}}, 2: {0: {'A': x_soi_2_0_A, 'B': x_soi_2_0_B}, 1: {'A': x_soi_2_1_A, 'B': x_soi_2_1_B}, 2: {'A': x_soi_2_2_A, 'B': x_soi_2_2_B}, 3: {'A': x_soi_2_3_A, 'B': x_soi_2_3_B}, 4: {'A': x_soi_2_4_A, 'B': x_soi_2_4_B}, 5: {'A': x_soi_2_5_A, 'B': x_soi_2_5_B}, 6: {'A': x_soi_2_6_A, 'B': x_soi_2_6_B}, 7: {'A': x_soi_2_7_A, 'B': x_soi_2_7_B}, 8: {'A': x_soi_2_8_A, 'B': x_soi_2_8_B}, 9: {'A': x_soi_2_9_A, 'B': x_soi_2_9_B}, 10: {'A': x_soi_2_10_A, 'B': x_soi_2_10_B}, 11: {'A': x_soi_2_11_A, 'B': x_soi_2_11_B}, 12: {'A': x_soi_2_12_A, 'B': x_soi_2_12_B}, 13: {'A': x_soi_2_13_A, 'B': x_soi_2_13_B}, 14: {'A': x_soi_2_14_A, 'B': x_soi_2_14_B}, 15: {'A': x_soi_2_15_A, 'B': x_soi_2_15_B}, 16: {'A': x_soi_2_16_A, 'B': x_soi_2_16_B}, 17: {'A': x_soi_2_17_A, 'B': x_soi_2_17_B}, 18: {'A': x_soi_2_18_A, 'B': x_soi_2_18_B}, 19: {'A': x_soi_2_19_A, 'B': x_soi_2_19_B}}, 3: {0: {'A': x_soi_3_0_A, 'B': x_soi_3_0_B}, 1: {'A': x_soi_3_1_A, 'B': x_soi_3_1_B}, 2: {'A': x_soi_3_2_A, 'B': x_soi_3_2_B}, 3: {'A': x_soi_3_3_A, 'B': x_soi_3_3_B}, 4: {'A': x_soi_3_4_A, 'B': x_soi_3_4_B}, 5: {'A': x_soi_3_5_A, 'B': x_soi_3_5_B}, 6: {'A': x_soi_3_6_A, 'B': x_soi_3_6_B}, 7: {'A': x_soi_3_7_A, 'B': x_soi_3_7_B}, 8: {'A': x_soi_3_8_A, 'B': x_soi_3_8_B}, 9: {'A': x_soi_3_9_A, 'B': x_soi_3_9_B}, 10: {'A': x_soi_3_10_A, 'B': x_soi_3_10_B}, 11: {'A': x_soi_3_11_A, 'B': x_soi_3_11_B}, 12: {'A': x_soi_3_12_A, 'B': x_soi_3_12_B}, 13: {'A': x_soi_3_13_A, 'B': x_soi_3_13_B}, 14: {'A': x_soi_3_14_A, 'B': x_soi_3_14_B}, 15: {'A': x_soi_3_15_A, 'B': x_soi_3_15_B}, 16: {'A': x_soi_3_16_A, 'B': x_soi_3_16_B}, 17: {'A': x_soi_3_17_A, 'B': x_soi_3_17_B}, 18: {'A': x_soi_3_18_A, 'B': x_soi_3_18_B}, 19: {'A': x_soi_3_19_A, 'B': x_soi_3_19_B}}}\n",
      "\n",
      "\n",
      "\n",
      "running milp_model <class 'milp_models.model_dependent_problem_linear_labor_recourse'>\n",
      "using this file SALBP_benchmark/MM_instances/model_data/small_instances/3_models/n=20_2_n=20_3_n=20_4.yaml\n",
      "Running instance n=20_2_n=20_3_n=20_4\n",
      "loading equipment from SALBP_benchmark/MM_instances/equipment_data/random_O20_E4_S4_seed42.yaml\n",
      "generating scenario tree\n",
      "defining problem\n",
      "Set parameter TimeLimit to value 600\n",
      "Set parameter LogFile to value \"model_runs/xp_2023_12_03_mc_debug/model_dependent_linear/lmd_small_instance_debug2.log\"\n",
      "Using license file /Users/letshopethisworks2/gurobi.lic\n",
      "\n",
      "Gurobi Optimizer version 10.0.2 build v10.0.2rc0 (mac64[rosetta2])\n",
      "Copyright (c) 2023, Gurobi Optimization, LLC\n",
      "\n",
      "Read LP format model from file /var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/90c69e20f50843ada4cd6efd536c4686-pulp.lp\n",
      "Reading time = 0.01 seconds\n",
      "Total_cost: 4486 rows, 2606 columns, 34310 nonzeros\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 4486 rows, 2606 columns and 34310 nonzeros\n",
      "Model fingerprint: 0x9555cbce\n",
      "Variable types: 0 continuous, 2606 integer (256 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+03]\n",
      "  Objective range  [4e-01, 6e+03]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Presolve removed 2268 rows and 972 columns\n",
      "Presolve time: 0.06s\n",
      "Presolved: 2218 rows, 1634 columns, 30960 nonzeros\n",
      "Variable types: 0 continuous, 1634 integer (256 binary)\n",
      "Found heuristic solution: objective 13676.000000\n",
      "\n",
      "Root relaxation: objective 5.510120e+03, 2470 iterations, 0.07 seconds (0.21 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5510.12046    0 1490 13676.0000 5510.12046  59.7%     -    0s\n",
      "H    0     0                    11921.000000 5510.12046  53.8%     -    0s\n",
      "H    0     0                    6817.0000000 6733.92034  1.22%     -    0s\n",
      "     0     0     cutoff    0      6817.00000 6817.00000  0.00%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 22\n",
      "  Cover: 14\n",
      "  Implied bound: 401\n",
      "  Clique: 105\n",
      "  MIR: 23\n",
      "  StrongCG: 3\n",
      "  Zero half: 9\n",
      "  RLT: 16\n",
      "  Relax-and-lift: 108\n",
      "\n",
      "Explored 1 nodes (4023 simplex iterations) in 0.35 seconds (0.66 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 6817 11921 13676 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.817000000000e+03, best bound 6.817000000000e+03, gap 0.0000%\n",
      "\n",
      "Wrote result file '/var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/90c69e20f50843ada4cd6efd536c4686-pulp.sol'\n",
      "\n",
      "here are the x_soi variables\n",
      "{0: {0: {'A': x_soi_0_0_A, 'B': x_soi_0_0_B, 'C': x_soi_0_0_C}, 1: {'A': x_soi_0_1_A, 'B': x_soi_0_1_B, 'C': x_soi_0_1_C}, 2: {'A': x_soi_0_2_A, 'B': x_soi_0_2_B, 'C': x_soi_0_2_C}, 3: {'A': x_soi_0_3_A, 'B': x_soi_0_3_B, 'C': x_soi_0_3_C}, 4: {'A': x_soi_0_4_A, 'B': x_soi_0_4_B, 'C': x_soi_0_4_C}, 5: {'A': x_soi_0_5_A, 'B': x_soi_0_5_B, 'C': x_soi_0_5_C}, 6: {'A': x_soi_0_6_A, 'B': x_soi_0_6_B, 'C': x_soi_0_6_C}, 7: {'A': x_soi_0_7_A, 'B': x_soi_0_7_B, 'C': x_soi_0_7_C}, 8: {'A': x_soi_0_8_A, 'B': x_soi_0_8_B, 'C': x_soi_0_8_C}, 9: {'A': x_soi_0_9_A, 'B': x_soi_0_9_B, 'C': x_soi_0_9_C}, 10: {'A': x_soi_0_10_A, 'B': x_soi_0_10_B, 'C': x_soi_0_10_C}, 11: {'A': x_soi_0_11_A, 'B': x_soi_0_11_B, 'C': x_soi_0_11_C}, 12: {'A': x_soi_0_12_A, 'B': x_soi_0_12_B, 'C': x_soi_0_12_C}, 13: {'A': x_soi_0_13_A, 'B': x_soi_0_13_B, 'C': x_soi_0_13_C}, 14: {'A': x_soi_0_14_A, 'B': x_soi_0_14_B, 'C': x_soi_0_14_C}, 15: {'A': x_soi_0_15_A, 'B': x_soi_0_15_B, 'C': x_soi_0_15_C}, 16: {'A': x_soi_0_16_A, 'B': x_soi_0_16_B, 'C': x_soi_0_16_C}, 17: {'A': x_soi_0_17_A, 'B': x_soi_0_17_B, 'C': x_soi_0_17_C}, 18: {'A': x_soi_0_18_A, 'B': x_soi_0_18_B, 'C': x_soi_0_18_C}, 19: {'A': x_soi_0_19_A, 'B': x_soi_0_19_B, 'C': x_soi_0_19_C}}, 1: {0: {'A': x_soi_1_0_A, 'B': x_soi_1_0_B, 'C': x_soi_1_0_C}, 1: {'A': x_soi_1_1_A, 'B': x_soi_1_1_B, 'C': x_soi_1_1_C}, 2: {'A': x_soi_1_2_A, 'B': x_soi_1_2_B, 'C': x_soi_1_2_C}, 3: {'A': x_soi_1_3_A, 'B': x_soi_1_3_B, 'C': x_soi_1_3_C}, 4: {'A': x_soi_1_4_A, 'B': x_soi_1_4_B, 'C': x_soi_1_4_C}, 5: {'A': x_soi_1_5_A, 'B': x_soi_1_5_B, 'C': x_soi_1_5_C}, 6: {'A': x_soi_1_6_A, 'B': x_soi_1_6_B, 'C': x_soi_1_6_C}, 7: {'A': x_soi_1_7_A, 'B': x_soi_1_7_B, 'C': x_soi_1_7_C}, 8: {'A': x_soi_1_8_A, 'B': x_soi_1_8_B, 'C': x_soi_1_8_C}, 9: {'A': x_soi_1_9_A, 'B': x_soi_1_9_B, 'C': x_soi_1_9_C}, 10: {'A': x_soi_1_10_A, 'B': x_soi_1_10_B, 'C': x_soi_1_10_C}, 11: {'A': x_soi_1_11_A, 'B': x_soi_1_11_B, 'C': x_soi_1_11_C}, 12: {'A': x_soi_1_12_A, 'B': x_soi_1_12_B, 'C': x_soi_1_12_C}, 13: {'A': x_soi_1_13_A, 'B': x_soi_1_13_B, 'C': x_soi_1_13_C}, 14: {'A': x_soi_1_14_A, 'B': x_soi_1_14_B, 'C': x_soi_1_14_C}, 15: {'A': x_soi_1_15_A, 'B': x_soi_1_15_B, 'C': x_soi_1_15_C}, 16: {'A': x_soi_1_16_A, 'B': x_soi_1_16_B, 'C': x_soi_1_16_C}, 17: {'A': x_soi_1_17_A, 'B': x_soi_1_17_B, 'C': x_soi_1_17_C}, 18: {'A': x_soi_1_18_A, 'B': x_soi_1_18_B, 'C': x_soi_1_18_C}, 19: {'A': x_soi_1_19_A, 'B': x_soi_1_19_B, 'C': x_soi_1_19_C}}, 2: {0: {'A': x_soi_2_0_A, 'B': x_soi_2_0_B, 'C': x_soi_2_0_C}, 1: {'A': x_soi_2_1_A, 'B': x_soi_2_1_B, 'C': x_soi_2_1_C}, 2: {'A': x_soi_2_2_A, 'B': x_soi_2_2_B, 'C': x_soi_2_2_C}, 3: {'A': x_soi_2_3_A, 'B': x_soi_2_3_B, 'C': x_soi_2_3_C}, 4: {'A': x_soi_2_4_A, 'B': x_soi_2_4_B, 'C': x_soi_2_4_C}, 5: {'A': x_soi_2_5_A, 'B': x_soi_2_5_B, 'C': x_soi_2_5_C}, 6: {'A': x_soi_2_6_A, 'B': x_soi_2_6_B, 'C': x_soi_2_6_C}, 7: {'A': x_soi_2_7_A, 'B': x_soi_2_7_B, 'C': x_soi_2_7_C}, 8: {'A': x_soi_2_8_A, 'B': x_soi_2_8_B, 'C': x_soi_2_8_C}, 9: {'A': x_soi_2_9_A, 'B': x_soi_2_9_B, 'C': x_soi_2_9_C}, 10: {'A': x_soi_2_10_A, 'B': x_soi_2_10_B, 'C': x_soi_2_10_C}, 11: {'A': x_soi_2_11_A, 'B': x_soi_2_11_B, 'C': x_soi_2_11_C}, 12: {'A': x_soi_2_12_A, 'B': x_soi_2_12_B, 'C': x_soi_2_12_C}, 13: {'A': x_soi_2_13_A, 'B': x_soi_2_13_B, 'C': x_soi_2_13_C}, 14: {'A': x_soi_2_14_A, 'B': x_soi_2_14_B, 'C': x_soi_2_14_C}, 15: {'A': x_soi_2_15_A, 'B': x_soi_2_15_B, 'C': x_soi_2_15_C}, 16: {'A': x_soi_2_16_A, 'B': x_soi_2_16_B, 'C': x_soi_2_16_C}, 17: {'A': x_soi_2_17_A, 'B': x_soi_2_17_B, 'C': x_soi_2_17_C}, 18: {'A': x_soi_2_18_A, 'B': x_soi_2_18_B, 'C': x_soi_2_18_C}, 19: {'A': x_soi_2_19_A, 'B': x_soi_2_19_B, 'C': x_soi_2_19_C}}, 3: {0: {'A': x_soi_3_0_A, 'B': x_soi_3_0_B, 'C': x_soi_3_0_C}, 1: {'A': x_soi_3_1_A, 'B': x_soi_3_1_B, 'C': x_soi_3_1_C}, 2: {'A': x_soi_3_2_A, 'B': x_soi_3_2_B, 'C': x_soi_3_2_C}, 3: {'A': x_soi_3_3_A, 'B': x_soi_3_3_B, 'C': x_soi_3_3_C}, 4: {'A': x_soi_3_4_A, 'B': x_soi_3_4_B, 'C': x_soi_3_4_C}, 5: {'A': x_soi_3_5_A, 'B': x_soi_3_5_B, 'C': x_soi_3_5_C}, 6: {'A': x_soi_3_6_A, 'B': x_soi_3_6_B, 'C': x_soi_3_6_C}, 7: {'A': x_soi_3_7_A, 'B': x_soi_3_7_B, 'C': x_soi_3_7_C}, 8: {'A': x_soi_3_8_A, 'B': x_soi_3_8_B, 'C': x_soi_3_8_C}, 9: {'A': x_soi_3_9_A, 'B': x_soi_3_9_B, 'C': x_soi_3_9_C}, 10: {'A': x_soi_3_10_A, 'B': x_soi_3_10_B, 'C': x_soi_3_10_C}, 11: {'A': x_soi_3_11_A, 'B': x_soi_3_11_B, 'C': x_soi_3_11_C}, 12: {'A': x_soi_3_12_A, 'B': x_soi_3_12_B, 'C': x_soi_3_12_C}, 13: {'A': x_soi_3_13_A, 'B': x_soi_3_13_B, 'C': x_soi_3_13_C}, 14: {'A': x_soi_3_14_A, 'B': x_soi_3_14_B, 'C': x_soi_3_14_C}, 15: {'A': x_soi_3_15_A, 'B': x_soi_3_15_B, 'C': x_soi_3_15_C}, 16: {'A': x_soi_3_16_A, 'B': x_soi_3_16_B, 'C': x_soi_3_16_C}, 17: {'A': x_soi_3_17_A, 'B': x_soi_3_17_B, 'C': x_soi_3_17_C}, 18: {'A': x_soi_3_18_A, 'B': x_soi_3_18_B, 'C': x_soi_3_18_C}, 19: {'A': x_soi_3_19_A, 'B': x_soi_3_19_B, 'C': x_soi_3_19_C}}}\n",
      "time for <class 'milp_models.model_dependent_problem_linear_labor_recourse'> 1.2635829448699951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_from_config(config_file, seed = None, \n",
    "                    scenario_generator= make_scenario_tree, base_file_name = 'test', save_variables = False,run_time = 600, **kwargs):\n",
    "   test_instances = []\n",
    "   with open(config_file) as f:\n",
    "      print('Opening config file', config_file)\n",
    "      print('base_file_name', base_file_name)\n",
    "      #Removes file extension from config file name\n",
    "      conf_name = config_file.split('.')[0].split('/')[-1]\n",
    "      print('conf_name', conf_name)\n",
    "      xp_yaml = yaml.load(f, Loader=yaml.FullLoader)\n",
    "      #configuring problem\n",
    "      SEQUENCE_LENGTH = xp_yaml['sequence_length']\n",
    "      NO_WORKERS = xp_yaml['max_workers']\n",
    "      NO_STATIONS = xp_yaml['no_stations']\n",
    "      WORKER_COST = xp_yaml['worker_cost']\n",
    "      RECOURSE_COST = xp_yaml['recourse_cost']\n",
    "      #configuring scenario tree generator\n",
    "      tree_kwargs = {}\n",
    "      if xp_yaml['scenario_generator']== 'monte_carlo_tree':\n",
    "         scenario_generator = monte_carlo_tree\n",
    "         tree_kwargs['n_samples'] = xp_yaml['scenario_generator']['n_samples']\n",
    "         tree_kwargs['enum_depth'] = xp_yaml['scenario_generator']['enum_depth']\n",
    "      else:\n",
    "         scenario_generator = make_scenario_tree\n",
    "      \n",
    "      #copying config file to results folder\n",
    "      print('copying config file to results folder',  config_file, base_file_name +'/'+ config_file)\n",
    "      shutil.copyfile(config_file, base_file_name +'/'+ conf_name + '_config.yaml')\n",
    "      for milp_model in xp_yaml['milp_models']:\n",
    "         if milp_model == 'model_dependent_problem_multi_labor_recourse':\n",
    "            milp_model = model_dependent_problem_multi_labor_recourse\n",
    "            file_name = base_file_name + '/model_dependent/'\n",
    "            #if model_dependent directory does not exist, make it\n",
    "            if not os.path.exists(file_name):\n",
    "               os.makedirs(file_name)\n",
    "            file_name = file_name + 'md_'\n",
    "         elif milp_model == 'dynamic_problem_multi_labor_recourse':\n",
    "            milp_model = dynamic_problem_multi_labor_recourse\n",
    "            file_name = base_file_name + '/dynamic/'\n",
    "            #if model_dependent directory does not exist, make it\n",
    "            if not os.path.exists(file_name):\n",
    "               os.makedirs(file_name)\n",
    "            file_name = file_name + 'd_'\n",
    "         elif milp_model == 'model_dependent_problem_linear_labor_recourse':\n",
    "            milp_model = model_dependent_problem_linear_labor_recourse\n",
    "            file_name = base_file_name + '/model_dependent_linear/'\n",
    "            #if model_dependent directory does not exist, make it\n",
    "            if not os.path.exists(file_name):\n",
    "               os.makedirs(file_name)\n",
    "            file_name = file_name + 'lmd_'\n",
    "         elif milp_model == 'dynamic_problem_linear_labor_recourse':\n",
    "            milp_model = dynamic_problem_linear_labor_recourse\n",
    "            file_name = base_file_name + '/dynamic_linear/'\n",
    "            #if model_dependent directory does not exist, make it\n",
    "            if not os.path.exists(file_name):\n",
    "               os.makedirs(file_name)\n",
    "            file_name = file_name + 'ld_'\n",
    "         else:\n",
    "            raise ValueError('milp_model not recognized')\n",
    "         #Keeps track of time\n",
    "         start_time = time.time()\n",
    "         group_counter = 0\n",
    "         for model_file in xp_yaml['model_files']:\n",
    "            print('\\n\\n')\n",
    "            print('running milp_model', milp_model)\n",
    "            test_instance = MultiModelTaskTimesInstance( init_type='model_data_from_yaml',\n",
    "                                             model_yaml=model_file, \n",
    "                                             sequence_length=SEQUENCE_LENGTH, \n",
    "                                             max_workers=NO_WORKERS, \n",
    "                                             no_stations=NO_STATIONS, \n",
    "                                             worker_cost=WORKER_COST, \n",
    "                                             recourse_cost=RECOURSE_COST)\n",
    "            print('Running instance', test_instance.name)\n",
    "            test_instances.append(test_instance)\n",
    "            #create equipment\n",
    "            if xp_yaml['equipment_files']:\n",
    "               print('loading equipment from', xp_yaml['equipment_files'][0])\n",
    "               equipment = Equipment(generation_method='import_yaml', equipment_file=xp_yaml['equipment_files'][0])\n",
    "               if equipment.no_tasks != test_instance.no_tasks:\n",
    "                  print('equipmen no tasks', equipment.no_tasks)\n",
    "                  print('instance no tasks', test_instance.no_tasks)\n",
    "                  #raises an error if the equipment and instance have different number of tasks\n",
    "                  raise ValueError('Equipment and instance have different number of tasks')\n",
    "            else:\n",
    "               print('creating equipment')\n",
    "               NO_EQUIPMENT = xp_yaml['no_equipment']\n",
    "               equipment = Equipment(test_instance.no_tasks, \n",
    "                                     NO_EQUIPMENT, \n",
    "                                     NO_STATIONS, \n",
    "                                     generate_equipment, \n",
    "                                     seed)\n",
    "            #create scenario tree\n",
    "            print('generating scenario tree')\n",
    "            model_mixtures = test_instance.model_mixtures\n",
    "            scenario_tree_graph, final_sequences = scenario_generator(SEQUENCE_LENGTH, model_mixtures, **tree_kwargs)\n",
    "            print('defining problem')\n",
    "            milp_prob = milp_model(problem_instance = test_instance, \n",
    "                                   equipment_instance = equipment, \n",
    "                                   sequence_length=SEQUENCE_LENGTH, \n",
    "                                   prod_sequences=final_sequences)\n",
    "            start = timer()\n",
    "            solver = plp.GUROBI_CMD(options=[ ('TimeLimit', run_time), ('LogFile', file_name+conf_name + str(group_counter) + \".log\")])#\n",
    "            milp_prob.solve(solver=solver, \n",
    "                            file_name=file_name + conf_name+ str(group_counter))\n",
    "            #writes the lp variables to a file if save_variables is true\n",
    "            if save_variables:\n",
    "               print('here are the x_soi variables')\n",
    "               print(milp_prob.x_soi)\n",
    "               folder_name = file_name + conf_name + str(group_counter) + '_variables/'\n",
    "               if not os.path.exists(folder_name):\n",
    "                  os.makedirs(folder_name)\n",
    "               milp_prob.save_variables(folder_name)\n",
    "\n",
    "            end = timer()\n",
    "            result = milp_prob.get_obj_val_dict()\n",
    "            result['run_time'] = end - start\n",
    "            result_df = pd.DataFrame([result], index=[0])\n",
    "            if group_counter == 0:\n",
    "               results_df = result_df.copy()\n",
    "            else:\n",
    "               results_df = pd.concat([results_df, result_df], axis=0, ignore_index=True)\n",
    "            output_path=file_name + conf_name +  '_results.csv'\n",
    "            results_df.to_csv(output_path)\n",
    "            group_counter += 1\n",
    "         #deletes results df\n",
    "         del results_df\n",
    "         end_time = time.time()\n",
    "         print('time for', milp_model, end_time - start_time)\n",
    "   return 1\n",
    "\n",
    "today = datetime.today().strftime('%Y_%m_%d')\n",
    "xp_name = f\"xp_{today}_mc_debug\"\n",
    "if not os.path.exists('model_runs/'+ xp_name):\n",
    "   os.makedirs('model_runs/'+xp_name)\n",
    "   \n",
    "file_name = 'model_runs/'+xp_name\n",
    "run_from_config('SALBP_benchmark/MM_instances/small_instance_debug.yaml',\n",
    "           base_file_name=file_name, save_variables=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer reporting stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/ipykernel_13142/1626933366.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_runs/xp_2023_10_06_config_test2/dynamic_small_instance_config0.log\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nodelog\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplot_incumbent_vs_bound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_runs/xp_2023_10_06_config_test2/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dynamic_small_instance_config0.log\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/grblogtools/api.py\u001b[0m in \u001b[0;36mprogress\u001b[0;34m(self, section)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         return pd.merge(\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mleft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon_log_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \"\"\"\n\u001b[0;32m--> 347\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "\n",
    "summary = glt.parse(\"model_runs/xp_2023_10_06_config_test2/dynamic_small_instance_config0.log\")\n",
    "nl = summary.progress(\"nodelog\")\n",
    "nl.head()\n",
    "plot_incumbent_vs_bound(\"model_runs/xp_2023_10_06_config_test2/\", \"dynamic_small_instance_config0.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm starting dynamic with model dependent solution for faster solutions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   station model  task  value\n",
      "0        0     A     0    1.0\n",
      "1        0     A     1    1.0\n",
      "2        0     A     2    1.0\n",
      "3        0     A     3    1.0\n",
      "4        0     A     4    1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "#reads the x_soi varaibles into dataframe\n",
    "\n",
    "x_soi_df = pd.read_csv('model_runs/xp_2023_12_02_mc_debug/model_dependent_linear/lmd_small_instance_debug0_variables/x_soi.csv', sep=' ')\n",
    "print(x_soi_df.head())\n",
    "#accesses the element with station = 0, model = A, task = 0\n",
    "print(x_soi_df.loc[(x_soi_df['station'] == 0) & (x_soi_df['model'] == 'A') & (x_soi_df['task'] == 0)]['value'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   station  equipment  value\n",
      "0        0          0    1.0\n",
      "1        0          1    1.0\n",
      "2        0          2    0.0\n",
      "3        0          3    1.0\n",
      "4        1          0    0.0\n",
      "row station      0.0\n",
      "equipment    0.0\n",
      "value        1.0\n",
      "Name: 0, dtype: float64\n",
      "row['station'] 0.0\n",
      "row station      0.0\n",
      "equipment    1.0\n",
      "value        1.0\n",
      "Name: 1, dtype: float64\n",
      "row['station'] 0.0\n",
      "row station      0.0\n",
      "equipment    2.0\n",
      "value        0.0\n",
      "Name: 2, dtype: float64\n",
      "row['station'] 0.0\n",
      "row station      0.0\n",
      "equipment    3.0\n",
      "value        1.0\n",
      "Name: 3, dtype: float64\n",
      "row['station'] 0.0\n",
      "row station      1.0\n",
      "equipment    0.0\n",
      "value        0.0\n",
      "Name: 4, dtype: float64\n",
      "row['station'] 1.0\n",
      "row station      1.0\n",
      "equipment    1.0\n",
      "value        0.0\n",
      "Name: 5, dtype: float64\n",
      "row['station'] 1.0\n",
      "row station      1.0\n",
      "equipment    2.0\n",
      "value        0.0\n",
      "Name: 6, dtype: float64\n",
      "row['station'] 1.0\n",
      "row station      1.0\n",
      "equipment    3.0\n",
      "value        0.0\n",
      "Name: 7, dtype: float64\n",
      "row['station'] 1.0\n",
      "row station      2.0\n",
      "equipment    0.0\n",
      "value        0.0\n",
      "Name: 8, dtype: float64\n",
      "row['station'] 2.0\n",
      "row station      2.0\n",
      "equipment    1.0\n",
      "value        0.0\n",
      "Name: 9, dtype: float64\n",
      "row['station'] 2.0\n",
      "row station      2.0\n",
      "equipment    2.0\n",
      "value        0.0\n",
      "Name: 10, dtype: float64\n",
      "row['station'] 2.0\n",
      "row station      2.0\n",
      "equipment    3.0\n",
      "value        0.0\n",
      "Name: 11, dtype: float64\n",
      "row['station'] 2.0\n",
      "row station      3.0\n",
      "equipment    0.0\n",
      "value        0.0\n",
      "Name: 12, dtype: float64\n",
      "row['station'] 3.0\n",
      "row station      3.0\n",
      "equipment    1.0\n",
      "value        0.0\n",
      "Name: 13, dtype: float64\n",
      "row['station'] 3.0\n",
      "row station      3.0\n",
      "equipment    2.0\n",
      "value        0.0\n",
      "Name: 14, dtype: float64\n",
      "row['station'] 3.0\n",
      "row station      3.0\n",
      "equipment    3.0\n",
      "value        0.0\n",
      "Name: 15, dtype: float64\n",
      "row['station'] 3.0\n"
     ]
    }
   ],
   "source": [
    "u_se_df = pd.read_csv('model_runs/xp_2023_12_02_mc_debug/model_dependent_linear/lmd_small_instance_debug0_variables/u_se.csv', sep=' ')\n",
    "print(u_se_df.head())\n",
    "for index, row in u_se_df.iterrows():\n",
    "    print(\"row\", row)\n",
    "    print(\"row['station']\", row['station'])\n",
    "    station = int(row['station'])\n",
    "    equipment = int(row['equipment'])\n",
    "    # self.u_se[station][equipment]].setInitialValue(round(row['value']))\n",
    "    # if fixed:\n",
    "    #     self.u_se[row['station']][row['equipment']].fixValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using this file SALBP_benchmark/MM_instances/model_data/small_instances/2_models/n=20_1_n=20_2.yaml\n",
      "loading results from model_runs/xp_2023_12_02_mc_debug/model_dependent_linear/lmd_small_instance_debug0_variables/\n",
      "loading u_se.csv\n",
      "  station equipment value\n",
      "0                 0 0 1.0\n",
      "1                 0 1 1.0\n",
      "2                 0 2 0.0\n",
      "3                 0 3 1.0\n",
      "4                 1 0 0.0\n",
      "row station equipment value    0 0 1.0\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/letshopethisworks2/Documents/Phd Paper material/MMABPWW/ALB_instance_tools.py:153: UserWarning: Model probabilities do not sum to 1: 0.9999999999999999\n",
      "  warnings.warn(f'Model probabilities do not sum to 1: {total_probability}')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'station'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3628\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3629\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3630\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'station'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/ipykernel_13807/3476603940.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mequipment_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEquipment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneration_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'import_yaml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequipment_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SALBP_benchmark/MM_instances/equipment_data/random_O20_E4_S4_seed42.yaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mscenario_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_scenario_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_mixtures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mwarmstart_dynamic_problem_linear_labor_recourse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequipment_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_runs/xp_2023_12_02_mc_debug/model_dependent_linear/lmd_small_instance_debug0_variables/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/ipykernel_13807/3476603940.py\u001b[0m in \u001b[0;36mwarmstart_dynamic_problem_linear_labor_recourse\u001b[0;34m(problem_instance, equipment_instance, production_sequences, md_results_folder)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdynamic_problem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdynamic_problem_linear_labor_recourse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblem_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequipment_instance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduction_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#loads the results from the model dependent problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdynamic_problem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_up_from_model_dependent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd_results_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGUROBI_CMD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarmStart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'TimeLimit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'LogFile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dynamic_small_instance_config0.log\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdynamic_problem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmd_results_folder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'dynamic_small_instance_config0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Phd Paper material/MMABPWW/milp_models.py\u001b[0m in \u001b[0;36mset_up_from_model_dependent\u001b[0;34m(self, md_results_folder, fixed)\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loading u_se.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0mmd_u_se\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd_results_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'u_se.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_u_se_from_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd_u_se\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd_results_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'l_wts.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loading l_wts.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Phd Paper material/MMABPWW/milp_models.py\u001b[0m in \u001b[0;36mset_u_se_from_df\u001b[0;34m(self, u_se_df, fixed)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mu_se_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"row\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mstation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'station'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mequipment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'equipment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mu_se\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mequipment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetInitialValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3629\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3630\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3631\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3632\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3633\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'station'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dynamic_warm_start_model(model_instance_obj, start_solution, equipment_instance,no_tasks, \n",
    "#                                      NO_WORKERS, NO_STATIONS,takt_time, sequence_length, \n",
    "#                                      prod_sequences, worker_cost =100, fix_task_assignment = False):\n",
    "#     '''Uses provided task assignments to warm start the dynamic task assignment version of the problem\n",
    "#     For now we assume that the start solution is the model dependent version of the problem'''\n",
    "\n",
    "#     print('Writing problem')\n",
    "#     print('Number of tasks:', no_tasks, 'Number of workers:', NO_WORKERS, '\\n','Number of stations:', NO_STATIONS, 'Takt time:', takt_time, 'Sequence length:', sequence_length, 'worker_cost:', worker_cost)\n",
    "#     workers = list(range(0, NO_WORKERS+1))\n",
    "#     stations = list(range(NO_STATIONS))\n",
    "#     model_instance = model_instance_obj.data\n",
    "#     c_se = equipment_instance.c_se\n",
    "#     R_oe = equipment_instance.r_oe\n",
    "#     equipment = list( range(R_oe.shape[1]))\n",
    "#     takts = list(range(sequence_length+NO_STATIONS-1))\n",
    "#     u_se = plp.LpVariable.dicts('u_se', (stations, equipment), lowBound=0, cat='Binary')\n",
    "#     b_wtsl = plp.LpVariable.dicts('b_wtsl', (prod_sequences.keys(), takts, stations, workers), lowBound=0, cat='Binary') \n",
    "#     #TODO: maybe make this dictionary work different number of tasks for each model\n",
    "#     x_wsoj = plp.LpVariable.dicts('x_wsoj', (prod_sequences.keys(), stations, range(no_tasks), range(sequence_length) ), lowBound=0, cat='Binary')\n",
    "#     Y_w = plp.LpVariable.dicts('Y_w', (prod_sequences.keys()), lowBound=0, cat='Integer')\n",
    "#     #Adding in the start solution\n",
    "#     print('adding in start solution')\n",
    "#     for v in start_solution.variables():\n",
    "#         if 'x_soi' in v.name:\n",
    "#             model_md = v.name.split('_')[4]\n",
    "#             #change the task number to match with the instances\n",
    "#             o = int(v.name.split('_')[3])\n",
    "#             s = int(v.name.split('_')[2])\n",
    "#             for w in prod_sequences.keys():\n",
    "#                 #setting x_wsoj values from the start solution\n",
    "#                 for j, model in enumerate(prod_sequences[w]['sequence']):\n",
    "#                     if model_md == model:\n",
    "#                         x_wsoj[w][s][o][j].setInitialValue(round(v.varValue))\n",
    "#         elif 'b_wtsl' in v.name:\n",
    "#             w = int(v.name.split('_')[2])\n",
    "#             t = int(v.name.split('_')[3])\n",
    "#             s = int(v.name.split('_')[4])\n",
    "#             l = int(v.name.split('_')[5])\n",
    "#             b_wtsl[w][t][s][l].setInitialValue(round(v.varValue)) \n",
    "#         elif 'Y_w' in v.name:\n",
    "#             w = int(v.name.split('_')[2])\n",
    "#             Y_w[w].setInitialValue(round(v.varValue))\n",
    "#         elif 'u_se' in v.name:\n",
    "#             print('equipment', v.name.split('_'))\n",
    "#             s = int(v.name.split('_')[2])\n",
    "#             e = int(v.name.split('_')[3])\n",
    "#             u_se[s][e].setInitialValue(round(v.varValue))\n",
    "#     #Defining LP problem\n",
    "#     prob = plp.LpProblem(\"stochastic_problem\", plp.LpMinimize)\n",
    "#     #Objective function\n",
    "#     prob += (plp.lpSum([c_se[s][e]*u_se[s][e]\n",
    "#                          for s in stations\n",
    "#                            for e in equipment]\n",
    "#                       +\n",
    "#                       [prod_sequences[w]['probability']*Y_w[w]* worker_cost\n",
    "#                          for w in prod_sequences.keys()\n",
    "#                         ]),\n",
    "#                 \"Total cost\")\n",
    "#     #Constraints\n",
    "#     #Constraint 1 -- Must hire Y workers if we use Y workers in a given takt\n",
    "#     for w in prod_sequences.keys():\n",
    "#         for t in takts:\n",
    "#             prob += (plp.lpSum([l*b_wtsl[w][t][s][l] for s in stations for l in workers]) <= Y_w[w], f'Y_w_{w}_{t}')\n",
    "#     #Constraint 2 -- can only assign l number of workers to a station for a given scenario and stage\n",
    "#     for w in prod_sequences.keys():\n",
    "#         for t in takts:\n",
    "#             for s in stations:\n",
    "#                 prob += (plp.lpSum([b_wtsl[w][t][s][l] for l in workers]) == 1, f'b_wtsl_{w}_{t}_{s}')\n",
    "#         #Constraint 3 all tasks must be assigned to a station\n",
    "#     for w in prod_sequences.keys():\n",
    "#         for j, model in enumerate(prod_sequences[w]['sequence']):\n",
    "#             #Not strictly necessary if all models have the same number of tasks, could have just looped over no tasks\n",
    "#             #but this is more general\n",
    "#             for o in range(model_instance[model]['num_tasks']): \n",
    "#                 prob += (plp.lpSum([x_wsoj[w][s][o][j] for s in stations]) == 1, f'x_wsoj_{w}_s_{o}_{j}')\n",
    "#         #Constraint 4 -- sum of task times for assigned tasks must be less than takt time times the number of workers for a given station\n",
    "#     for w in prod_sequences.keys():\n",
    "#         for t in takts:\n",
    "#             for s in stations:\n",
    "#                 #Get the model at the current scenario, stage, and station\n",
    "#                 if 0<= t-s < sequence_length:\n",
    "#                     j = t-s\n",
    "#                     model = prod_sequences[w]['sequence'][j]\n",
    "#                     task_times = model_instance[model]['task_times']\n",
    "#                     prob += (plp.lpSum([task_times[o]*x_wsoj[w][s][int(o)-1][j] \n",
    "#                                         for o in task_times]) \n",
    "#                                         <= \n",
    "#                                         takt_time*plp.lpSum([l * b_wtsl[w][t][s][l] for l in workers]), f'task_time_wts_{w}_{t}_{s}')\n",
    "\n",
    "#     #Constraint 5 -- tasks can only be assigned to a station with the correct equipment\n",
    "#     for w in prod_sequences.keys():\n",
    "#         for j, model in enumerate(prod_sequences[w]['sequence']):\n",
    "#             for s in stations:\n",
    "#                 for o in range(model_instance[model]['num_tasks']):\n",
    "#                     prob += x_wsoj[w][s][o][j] <= plp.lpSum([R_oe[o][e]*u_se[s][e] for  e in equipment]), f'equipment_wsoj_{w}_{s}_{o}_{j}'\n",
    "#         #Constraint 6 -- precedence constraints\n",
    "#     for w in prod_sequences.keys():\n",
    "#         for j, model in enumerate(prod_sequences[w]['sequence']):\n",
    "#             for (pred, suc) in model_instance[model]['precedence_relations']:\n",
    "#                 prob += (plp.lpSum([ (s+1)  * x_wsoj[w][s][int(pred)-1][j] for s in stations])\n",
    "#                          <=  \n",
    "#                          plp.lpSum([ (s+1)  * x_wsoj[w][s][int(suc)-1][j] for s in stations]), \n",
    "#                          f'task{pred} before task{suc} for model{model}, item {j} seq {w}' )\n",
    "#         #Constraint 7 -- non-anticipativity constraints\n",
    "#     for w in prod_sequences.keys():\n",
    "#         for w_prime in prod_sequences.keys():\n",
    "#             if w_prime > w:\n",
    "#                 add_non_anticipation(prob, w, w_prime , prod_sequences, model_instance, x_wsoj, sequence_length, NO_STATIONS)\n",
    "\n",
    "                \n",
    "#     return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('time for normal run', normal_time)\n",
    "# print('time for warm start run', warm_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heuristic section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructive heuristic for model dependent task assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tasks selection methods\n",
    "def longest_processing_time(model, candidate_list, **kwargs):\n",
    "    max_task_time = 0\n",
    "    for candidate in candidate_list:\n",
    "        if model['task_times'][candidate] > max_task_time:\n",
    "            max_task_time = model['task_times'][candidate]\n",
    "            selected_task = candidate\n",
    "    return selected_task\n",
    "\n",
    "\n",
    "#Methods for the construction heurisitc\n",
    "\n",
    "def calculate_takt_time(model, NO_S, TAKT_TIME):\n",
    "    \"\"\"\n",
    "    Calculate the takt time for the model dependent model\n",
    "    \"\"\"\n",
    "    total_task_time = sum(model['task_times'].values())\n",
    "    new_takt_time = max(total_task_time/NO_S, TAKT_TIME)\n",
    "    return new_takt_time\n",
    "\n",
    "def model_task_assignment(model, all_tasks, NO_S, TAKT_TIME, selection_method, **kwargs):\n",
    "    '''This function assigns the tasks of a model '''\n",
    "    print('model', model)\n",
    "    x_so = np.zeros((NO_S,len(all_tasks)))\n",
    "    new_takt_time = calculate_takt_time( model, NO_S, TAKT_TIME)\n",
    "    prec_matrix = construct_precedence_matrix(model)\n",
    "    number_of_predecessor = np.sum(prec_matrix, axis=0)\n",
    "    for station in range(NO_S):\n",
    "        s_total_assingments = 0\n",
    "        while s_total_assingments < new_takt_time and np.any(number_of_predecessor != -1):\n",
    "            candidate_list = []\n",
    "            for task in model['task_times']:\n",
    "                task_in = int(task)-1\n",
    "                if number_of_predecessor[task_in] == 0:\n",
    "                    candidate_list.append(task)\n",
    "            selected_task = selection_method(model, candidate_list,  **kwargs)\n",
    "            selected_task_in = int(selected_task)-1\n",
    "            x_so[station, selected_task_in] = 1\n",
    "            s_total_assingments += model['task_times'][selected_task]\n",
    "            number_of_predecessor -= prec_matrix[selected_task_in]\n",
    "            number_of_predecessor[selected_task_in] = -1\n",
    "        #If all the elements in number of predecessor are -1, then all tasks are assigned\n",
    "        if np.all(number_of_predecessor == -1):\n",
    "            break\n",
    "    return x_so\n",
    "\n",
    "def constructive_heurisitc(instance, NO_S, TAKT_TIME, selection_method):\n",
    "    \"\"\"\n",
    "    Constructive heuristic for the model dependent model\n",
    "    \"\"\"\n",
    "    print('instance', instance)\n",
    "    all_tasks = get_task_union(instance, 'A', 'B')\n",
    "    print('all_tasks', all_tasks)\n",
    "    assignments = []\n",
    "    #heuristic asssigns tasks for each model in instance\n",
    "    for model in instance:\n",
    "        x_so = model_task_assignment( instance[model], all_tasks, NO_S, TAKT_TIME, selection_method)\n",
    "        assignments.append(x_so)\n",
    "    #combines assignments list into a single numpy array, where eac\n",
    "    x_soi = np.stack(assignments, axis=-1)\n",
    "    return x_soi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_constructive_heuristic(instance_list, NO_S, TAKT_TIME, MODEL_MIXTURES):\n",
    "    \"\"\"\n",
    "    Runs the constructive heuristic for all instances in the instance list\n",
    "    \"\"\"\n",
    "    heuristics = []\n",
    "    instance_groups = pair_instances(instance_list, MODEL_MIXTURES)\n",
    "    for group in instance_groups:\n",
    "        instance = create_instance_pair_stochastic(group)\n",
    "        heuristics.append(constructive_heurisitc(instance, NO_S, TAKT_TIME, longest_processing_time))\n",
    "    return heuristics\n",
    "\n",
    "def solve_from_initial_task_asssingments(instance, NO_S, TAKT_TIME, task_assignments):\n",
    "    \"\"\"\n",
    "    Solves the instance using the given task assignments\n",
    "    \"\"\"\n",
    "\n",
    "instance_list = [ \"SALBP_benchmark/small data set_n=20/instance_n=20_1.alb\",\n",
    "   \"SALBP_benchmark/small data set_n=20/instance_n=20_2.alb\",\n",
    "   ]\n",
    "NO_S = 4\n",
    "MODEL_MIXTURES = {'A': 0.5, 'B': 0.5}\n",
    "results_heuristic = run_constructive_heuristic(instance_list, NO_S, TAKT_TIME, MODEL_MIXTURES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix and Optimize LNS, starting with model dependent and going to dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will take a solution of the model depedent problem and use it as the first solution for the dynamic case. Here, instead of reoptimizing the entire thing, we choose 2-3 adjacent stations and reoptimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_and_optimize(instance, seed, no_iterations = 10, scenario_generator= make_scenario_tree, file_name = 'fix_and_optimize test', **kwargs):\n",
    "    \"\"\"\n",
    "    Fixes the task assignments and solves the instance\n",
    "    \"\"\"\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
