{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pulp as plp\n",
    "import networkx as nx\n",
    "from ALB_instance_tools import *\n",
    "from milp_models import *\n",
    "from collections import namedtuple\n",
    "import glob\n",
    "import os\n",
    "import string\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NO_TAKTS = 4\n",
    "scenario_tree_graph, final_sequences = make_scenario_tree(NO_TAKTS, {'A':0.60, 'B':0.4})\n",
    "# restricted_graph, restricted_sequences = make_consecutive_luxury_models_restricted_scenario_tree(NO_TAKTS, {'A':0.75, 'B':0.25}, max_consecutive=3, luxury_models=['A', 'B'])\n",
    "# restricted_total = sum_prob(restricted_sequences)\n",
    "# restricted_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'A', 'A', 'A'] probability 0.1296\n",
      "['A', 'A', 'A', 'B'] probability 0.0864\n",
      "['A', 'A', 'B', 'A'] probability 0.08639999999999999\n",
      "['A', 'A', 'B', 'B'] probability 0.0576\n",
      "['A', 'B', 'A', 'A'] probability 0.08639999999999999\n",
      "['A', 'B', 'A', 'B'] probability 0.0576\n",
      "['A', 'B', 'B', 'A'] probability 0.0576\n",
      "['A', 'B', 'B', 'B'] probability 0.038400000000000004\n",
      "['B', 'A', 'A', 'A'] probability 0.08639999999999999\n",
      "['B', 'A', 'A', 'B'] probability 0.0576\n",
      "['B', 'A', 'B', 'A'] probability 0.0576\n",
      "['B', 'A', 'B', 'B'] probability 0.038400000000000004\n",
      "['B', 'B', 'A', 'A'] probability 0.057600000000000005\n",
      "['B', 'B', 'A', 'B'] probability 0.03840000000000001\n",
      "['B', 'B', 'B', 'A'] probability 0.03840000000000001\n",
      "['B', 'B', 'B', 'B'] probability 0.025600000000000008\n"
     ]
    }
   ],
   "source": [
    "for number, sequence in final_sequences.items():\n",
    "\n",
    "    print(sequence['sequence'], 'probability', sequence['probability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[A, A, A, A]</td>\n",
       "      <td>0.1296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[A, A, A, B]</td>\n",
       "      <td>0.0864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[A, A, B, A]</td>\n",
       "      <td>0.0864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[A, A, B, B]</td>\n",
       "      <td>0.0576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[A, B, A, A]</td>\n",
       "      <td>0.0864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[A, B, A, B]</td>\n",
       "      <td>0.0576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[A, B, B, A]</td>\n",
       "      <td>0.0576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[A, B, B, B]</td>\n",
       "      <td>0.0384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[B, A, A, A]</td>\n",
       "      <td>0.0864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[B, A, A, B]</td>\n",
       "      <td>0.0576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[B, A, B, A]</td>\n",
       "      <td>0.0576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[B, A, B, B]</td>\n",
       "      <td>0.0384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[B, B, A, A]</td>\n",
       "      <td>0.0576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[B, B, A, B]</td>\n",
       "      <td>0.0384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[B, B, B, A]</td>\n",
       "      <td>0.0384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[B, B, B, B]</td>\n",
       "      <td>0.0256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sequence probability\n",
       "0   [A, A, A, A]      0.1296\n",
       "1   [A, A, A, B]      0.0864\n",
       "2   [A, A, B, A]      0.0864\n",
       "3   [A, A, B, B]      0.0576\n",
       "4   [A, B, A, A]      0.0864\n",
       "5   [A, B, A, B]      0.0576\n",
       "6   [A, B, B, A]      0.0576\n",
       "7   [A, B, B, B]      0.0384\n",
       "8   [B, A, A, A]      0.0864\n",
       "9   [B, A, A, B]      0.0576\n",
       "10  [B, A, B, A]      0.0576\n",
       "11  [B, A, B, B]      0.0384\n",
       "12  [B, B, A, A]      0.0576\n",
       "13  [B, B, A, B]      0.0384\n",
       "14  [B, B, B, A]      0.0384\n",
       "15  [B, B, B, B]      0.0256"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = pd.DataFrame(final_sequences).T\n",
    "sequences.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data {'A': {'num_tasks': 20, 'cycle_time': 1000, 'order_strength': 0.279, 'task_times': {'1': 51, '2': 319, '3': 63, '4': 212, '5': 131, '6': 47, '7': 189, '8': 173, '9': 62, '10': 82, '11': 206, '12': 183, '13': 44, '14': 137, '15': 93, '16': 57, '17': 223, '18': 120, '19': 159, '20': 215}, 'precedence_relations': [['1', '14'], ['2', '14'], ['4', '8'], ['5', '6'], ['5', '7'], ['6', '14'], ['7', '9'], ['7', '11'], ['7', '12'], ['8', '10'], ['8', '13'], ['9', '14'], ['11', '15'], ['13', '16'], ['14', '17'], ['14', '18'], ['14', '19'], ['14', '20']], 'probability': 0.6}, 'B': {'num_tasks': 20, 'cycle_time': 1000, 'order_strength': 0.3, 'task_times': {'1': 61, '2': 367, '3': 145, '4': 205, '5': 297, '6': 65, '7': 238, '8': 38, '9': 108, '10': 82, '11': 33, '12': 256, '13': 188, '14': 194, '15': 216, '16': 101, '17': 52, '18': 162, '19': 87, '20': 35}, 'precedence_relations': [['1', '7'], ['2', '7'], ['3', '7'], ['4', '7'], ['5', '8'], ['5', '9'], ['7', '10'], ['7', '11'], ['7', '12'], ['7', '13'], ['9', '14'], ['11', '16'], ['11', '17'], ['12', '15'], ['14', '18'], ['18', '19'], ['18', '20']], 'probability': 0.4}}\n",
      "Running instance n=20_11_n=20_12_\n",
      "creating equipment\n",
      "generating scenario tree\n",
      "defining problem\n",
      "Set parameter TimeLimit to value 300\n",
      "Set parameter LogFile to value \"gurobi.log\"\n",
      "Using license file /Users/letshopethisworks2/gurobi.lic\n",
      "\n",
      "Gurobi Optimizer version 10.0.2 build v10.0.2rc0 (mac64[rosetta2])\n",
      "Copyright (c) 2023, Gurobi Optimization, LLC\n",
      "\n",
      "Read LP format model from file /var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/ef9f8257fe4f4cdab49d037a6cf6ab57-pulp.lp\n",
      "Reading time = 0.01 seconds\n",
      "Total_cost: 1051 rows, 2433 columns, 11560 nonzeros\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 1051 rows, 2433 columns and 11560 nonzeros\n",
      "Model fingerprint: 0x9e47b314\n",
      "Variable types: 0 continuous, 2433 integer (2416 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 4e+03]\n",
      "  Objective range  [3e+01, 5e+02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 192 rows and 1478 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 859 rows, 955 columns, 8518 nonzeros\n",
      "Variable types: 0 continuous, 955 integer (938 binary)\n",
      "Found heuristic solution: objective 1684.0000000\n",
      "\n",
      "Root relaxation: objective 1.597604e+03, 1275 iterations, 0.02 seconds (0.04 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 1597.60404    0  335 1684.00000 1597.60404  5.13%     -    0s\n",
      "     0     0 1597.60404    0  335 1684.00000 1597.60404  5.13%     -    0s\n",
      "H    0     0                    1651.0000000 1597.60404  3.23%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 7\n",
      "  Cover: 21\n",
      "  Clique: 1\n",
      "  MIR: 150\n",
      "  StrongCG: 3\n",
      "  Zero half: 7\n",
      "  RLT: 50\n",
      "\n",
      "Explored 1 nodes (1470 simplex iterations) in 0.11 seconds (0.11 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 1651 1684 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.651000000000e+03, best bound 1.651000000000e+03, gap 0.0000%\n",
      "\n",
      "Wrote result file '/var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/ef9f8257fe4f4cdab49d037a6cf6ab57-pulp.sol'\n",
      "\n",
      "   scenario  scenario_workers  fixed_workers\n",
      "0         0                 0              3\n",
      "1         1                 0              3\n",
      "2        10                 0              3\n",
      "3        11                 0              3\n",
      "4        12                 0              3\n",
      "5        13                 0              3\n",
      "6        14                 0              3\n",
      "7        15                 0              3\n",
      "8         2                 0              3\n",
      "9         3                 0              3\n",
      "10        4                 0              3\n",
      "11        5                 0              3\n",
      "12        6                 0              3\n",
      "13        7                 0              3\n",
      "14        8                 0              3\n",
      "15        9                 0              3\n",
      "data {'A': {'num_tasks': 20, 'cycle_time': 1000, 'order_strength': 0.279, 'task_times': {'1': 51, '2': 319, '3': 63, '4': 212, '5': 131, '6': 47, '7': 189, '8': 173, '9': 62, '10': 82, '11': 206, '12': 183, '13': 44, '14': 137, '15': 93, '16': 57, '17': 223, '18': 120, '19': 159, '20': 215}, 'precedence_relations': [['1', '14'], ['2', '14'], ['4', '8'], ['5', '6'], ['5', '7'], ['6', '14'], ['7', '9'], ['7', '11'], ['7', '12'], ['8', '10'], ['8', '13'], ['9', '14'], ['11', '15'], ['13', '16'], ['14', '17'], ['14', '18'], ['14', '19'], ['14', '20']], 'probability': 0.6}, 'B': {'num_tasks': 20, 'cycle_time': 1000, 'order_strength': 0.3, 'task_times': {'1': 61, '2': 367, '3': 145, '4': 205, '5': 297, '6': 65, '7': 238, '8': 38, '9': 108, '10': 82, '11': 33, '12': 256, '13': 188, '14': 194, '15': 216, '16': 101, '17': 52, '18': 162, '19': 87, '20': 35}, 'precedence_relations': [['1', '7'], ['2', '7'], ['3', '7'], ['4', '7'], ['5', '8'], ['5', '9'], ['7', '10'], ['7', '11'], ['7', '12'], ['7', '13'], ['9', '14'], ['11', '16'], ['11', '17'], ['12', '15'], ['14', '18'], ['18', '19'], ['18', '20']], 'probability': 0.4}}\n",
      "Running instance n=20_11_n=20_12_\n",
      "creating equipment\n",
      "generating scenario tree\n",
      "defining problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/letshopethisworks2/Documents/Phd Paper material/MMABPWW/milp_models.py:733: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  task_assignments_df = task_assignments_df.groupby(['station', 'model'])['task', 'task_times'].agg({'task':lambda x: ','.join(x.astype(str)), 'task_times': sum }).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 300\n",
      "Set parameter LogFile to value \"gurobi.log\"\n",
      "Using license file /Users/letshopethisworks2/gurobi.lic\n",
      "\n",
      "Gurobi Optimizer version 10.0.2 build v10.0.2rc0 (mac64[rosetta2])\n",
      "Copyright (c) 2023, Gurobi Optimization, LLC\n",
      "\n",
      "Read LP format model from file /var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/c30b52f6b61240e6a99a92df3ba5fc51-pulp.lp\n",
      "Reading time = 0.02 seconds\n",
      "Total_cost: 10896 rows, 7393 columns, 52640 nonzeros\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 10896 rows, 7393 columns and 52640 nonzeros\n",
      "Model fingerprint: 0xd7c20df4\n",
      "Variable types: 0 continuous, 7393 integer (7376 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 4e+03]\n",
      "  Objective range  [3e+01, 5e+02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 4452 rows and 2876 columns\n",
      "Presolve time: 0.06s\n",
      "Presolved: 6444 rows, 4517 columns, 30828 nonzeros\n",
      "Variable types: 0 continuous, 4517 integer (4500 binary)\n",
      "Found heuristic solution: objective 2892.6000000\n",
      "\n",
      "Root relaxation: objective 1.078955e+03, 25635 iterations, 1.38 seconds (2.17 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 1078.95529    0 2704 2892.60000 1078.95529  62.7%     -    1s\n",
      "H    0     0                    1902.0000000 1078.95529  43.3%     -    1s\n",
      "     0     0 1206.21339    0 2957 1902.00000 1206.21339  36.6%     -    3s\n",
      "     0     0 1207.26159    0 2855 1902.00000 1207.26159  36.5%     -    3s\n",
      "     0     0 1207.26159    0 2824 1902.00000 1207.26159  36.5%     -    3s\n",
      "     0     0 1207.26159    0 2824 1902.00000 1207.26159  36.5%     -    3s\n",
      "     0     0 1219.70509    0 2812 1902.00000 1219.70509  35.9%     -    4s\n",
      "     0     0 1219.70509    0 2825 1902.00000 1219.70509  35.9%     -    4s\n",
      "     0     0 1261.41795    0 2820 1902.00000 1261.41795  33.7%     -    5s\n",
      "     0     0 1261.41795    0 2562 1902.00000 1261.41795  33.7%     -    5s\n",
      "     0     2 1261.41795    0 2562 1902.00000 1261.41795  33.7%     -    6s\n",
      "    36    42 1353.00000    7  283 1902.00000 1270.20197  33.2%  2769   10s\n",
      "H   73    81                    1853.0000000 1270.20197  31.5%  1631   10s\n",
      "H  239   215                    1779.0000000 1270.20197  28.6%   676   12s\n",
      "H  239   215                    1353.0000000 1270.20197  6.12%   676   12s\n",
      "H  617   491                    1279.0000000 1279.00000  0.00%   282   13s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 7\n",
      "  Cover: 431\n",
      "  Clique: 42\n",
      "  MIR: 49\n",
      "  StrongCG: 5\n",
      "  GUB cover: 34\n",
      "  Zero half: 20\n",
      "  RLT: 111\n",
      "\n",
      "Explored 671 nodes (228799 simplex iterations) in 13.52 seconds (26.37 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 6: 1279 1353 1779 ... 2892.6\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.279000000000e+03, best bound 1.279000000000e+03, gap 0.0000%\n",
      "\n",
      "Wrote result file '/var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/c30b52f6b61240e6a99a92df3ba5fc51-pulp.sol'\n",
      "\n",
      "--- 14.268349170684814 seconds --- model dependent time 0.3004438877105713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/letshopethisworks2/Documents/Phd Paper material/MMABPWW/milp_models.py:383: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  task_assignments_df = task_assignments_df.groupby(['scenario','station', 'sequence_loc','model'])['task', 'task_times'].agg({'task':lambda x: ','.join(x.astype(str)), 'task_times': sum }).reset_index()\n"
     ]
    }
   ],
   "source": [
    "# instance_dicts = [\n",
    "#    {'fp': \"SALBP_benchmark/debugging_ds/instance_n=5_1.alb\",'name':'A', 'probability':0.75},\n",
    "#    {'fp': \"SALBP_benchmark/debugging_ds/instance_n=5_2.alb\",'name':'B', 'probability':0.25}\n",
    "# ]\n",
    "\n",
    "\n",
    "instance_list = read_instance_folder(\"SALBP_benchmark/small data set_n=20/\")[10:12]\n",
    "# instance_dicts = [\n",
    "#    {'fp': \"SALBP_benchmark/small data set_n=20/instance_n=20_1.alb\",'name':'A', 'probability':0.75},\n",
    "#    {'fp': \"SALBP_benchmark/small data set_n=20/instance_n=20_2.alb\",'name':'B', 'probability':0.25}\n",
    "# ]\n",
    "# instance_list = [ \"SALBP_benchmark/debugging_ds/instance_n=7_1.alb\",\n",
    "#    \"SALBP_benchmark/debugging_ds/instance_n=7_2.alb\",\n",
    "#    ]\n",
    "# instance_list = [ \"SALBP_benchmark/small data set_n=20/instance_n=20_1.alb\",\n",
    "#    \"SALBP_benchmark/small data set_n=20/instance_n=20_18.alb\",]\n",
    "#test_instances = create_instance_pair_stochastic(instance_list)\n",
    "\n",
    "\n",
    "NO_EQUIPMENT = 4\n",
    "seed = 1\n",
    "NO_WORKERS =4\n",
    "NO_STATIONS = 4\n",
    "WORKER_COST = 500\n",
    "RECOURSE_COST = WORKER_COST * 2\n",
    "TAKT_TIME = 1000\n",
    "SEQUENCE_LENGTH = 4\n",
    "#MODEL_MIXTURES = {'A':0.34, 'B':0.33, 'C':0.33}\n",
    "MODEL_MIXTURES = {'A':0.60, 'B':0.40}\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def multi_run(instance_list, milp_model, NO_EQUIPMENT,  NO_WORKERS, \n",
    "              NO_STATIONS, WORKER_COST, TAKT_TIME, SEQUENCE_LENGTH, MODEL_MIXTURES, seed, RECOURSE_COST = WORKER_COST * 2,\n",
    "              scenario_generator= make_scenario_tree, file_name = 'test', **kwargs):\n",
    "   instance_groups = pair_instances(instance_list, MODEL_MIXTURES)\n",
    "   test_results = []\n",
    "   group_counter = 0\n",
    "   test_instances = []\n",
    "   instance_results = []\n",
    "   for group in instance_groups:\n",
    "      test_instance = MultiModelInstance(group, takt_time=TAKT_TIME, sequence_length=SEQUENCE_LENGTH, max_workers=NO_WORKERS, no_stations=NO_STATIONS, worker_cost=WORKER_COST, recourse_cost=RECOURSE_COST)\n",
    "      print('Running instance', test_instance.name)\n",
    "      test_instances.append(test_instance)\n",
    "      #create equipment\n",
    "      print('creating equipment')\n",
    "      equipment = Equipment(test_instance.all_tasks, NO_EQUIPMENT, NO_STATIONS, generate_equipment, seed)\n",
    "      #create scenario tree\n",
    "      print('generating scenario tree')\n",
    "      scenario_tree_graph, final_sequences = scenario_generator(SEQUENCE_LENGTH, MODEL_MIXTURES, **kwargs)\n",
    "      print('defining problem')\n",
    "      milp_prob = milp_model(problem_instance = test_instance, equipment_instance = equipment, sequence_length=SEQUENCE_LENGTH, prod_sequences=final_sequences, **kwargs)\n",
    "      #prob = milp_model(test_instance, equipment,test_instance.no_tasks, NO_WORKERS, NO_STATIONS, TAKT_TIME, SEQUENCE_LENGTH, final_sequences, worker_cost=WORKER_COST)\n",
    "      solver = plp.GUROBI_CMD(options=[('TimeLimit', 300)])#\n",
    "      milp_prob.solve(solver=solver, file_name=file_name + str(group_counter))\n",
    "      result = milp_prob.get_obj_val_dict()\n",
    "      instance_results.append(result)\n",
    "      group_counter += 1\n",
    "   instance_results = pd.DataFrame(instance_results)\n",
    "   instance_results.to_csv(file_name + '_results.csv')\n",
    "   return instance_results, test_instances\n",
    "\n",
    "xp_name = \"xpsept_12_split_60_40_small_data_set_10_through_25_Recourse\"\n",
    "#makes a folder of xp_name if it does not exist already\n",
    "\n",
    "if not os.path.exists('model_runs/'+ xp_name):\n",
    "   os.makedirs('model_runs/'+xp_name)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "file_name = 'model_runs/'+xp_name+f'/Model_dependent_{NO_STATIONS}_E{NO_EQUIPMENT}_L{NO_WORKERS}_T{SEQUENCE_LENGTH}_C{TAKT_TIME}_LC{WORKER_COST}_'\n",
    "results_md_df, instances_md = multi_run(instance_list, model_dependent_problem_linear_labour_recourse, NO_EQUIPMENT,  NO_WORKERS, \n",
    "          NO_STATIONS, WORKER_COST, TAKT_TIME, SEQUENCE_LENGTH, MODEL_MIXTURES, seed, RECOURSE_COST,\n",
    "          scenario_generator=make_scenario_tree,\n",
    "           file_name=file_name)\n",
    "md_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "file_name = 'model_runs/'+xp_name+f'/dynamic_{NO_STATIONS}_E{NO_EQUIPMENT}_L{NO_WORKERS}_T{SEQUENCE_LENGTH}_C{TAKT_TIME}_LC{WORKER_COST}_'\n",
    "results_md_df, instances_md = multi_run(instance_list, dynamic_problem_linear_labour_recourse, NO_EQUIPMENT,  NO_WORKERS, \n",
    "          NO_STATIONS, WORKER_COST, TAKT_TIME, SEQUENCE_LENGTH, MODEL_MIXTURES, seed, RECOURSE_COST,\n",
    "          scenario_generator=make_scenario_tree,\n",
    "           file_name=file_name)\n",
    "dynamic_time = time.time() - start_time\n",
    "print(\"--- %s seconds ---\" % (dynamic_time), \"model dependent time\", md_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_runs/xpsept_12_split_60_40_small_data_set_10_through_25_Recourse/dynamic_4_E4_L4_T4_C1000_LC500_'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance_groups = pair_instances(instance_list, MODEL_MIXTURES)\n",
    "# group = instance_groups[0]\n",
    "# test_instance = MultiModelInstance(group, takt_time=TAKT_TIME, sequence_length=SEQUENCE_LENGTH, \n",
    "#                                    max_workers=NO_WORKERS, no_stations=NO_STATIONS, worker_cost=WORKER_COST)\n",
    "# print('Running instance', test_instance.name)\n",
    "\n",
    "# #create equipment\n",
    "# print('creating equipment')\n",
    "# equipment = Equipment(test_instance.all_tasks, NO_EQUIPMENT, NO_STATIONS, generate_equipment, seed)\n",
    "# #create scenario tree\n",
    "# print('generating scenario tree')\n",
    "# scenario_tree_graph, final_sequences = make_scenario_tree(SEQUENCE_LENGTH, MODEL_MIXTURES)\n",
    "# print('defining problem')\n",
    "# milp_prob = dynamic_problem_linear_labour(problem_instance = test_instance, \n",
    "#                                           equipment_instance = equipment, sequence_length=SEQUENCE_LENGTH, prod_sequences=final_sequences)\n",
    "# #prob = milp_model(test_instance, equipment,test_instance.no_tasks, NO_WORKERS, NO_STATIONS, TAKT_TIME, SEQUENCE_LENGTH, final_sequences, worker_cost=WORKER_COST)\n",
    "# solver = plp.GUROBI_CMD(options=[('TimeLimit', 30)])#\n",
    "# milp_prob.solve(solver=solver, file_name=file_name + str('blarg'))\n",
    "# result = milp_prob.get_obj_val_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'milp_prob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/ipykernel_19494/1575825365.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtask_assignment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabor_assignment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmilp_prob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'blarg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'milp_prob' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "task_assignment, labor_assignment = milp_prob.generate_report(file_name=file_name + str('blarg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labor_assignment[labor_assignment['scenario'] == '1'].head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm starting dynamic with model dependent solution for faster solutions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_warm_start_model(model_instance_obj, start_solution, equipment_instance,no_tasks, \n",
    "                                     NO_WORKERS, NO_STATIONS,takt_time, sequence_length, \n",
    "                                     prod_sequences, worker_cost =100, fix_task_assignment = False):\n",
    "    '''Uses provided task assignments to warm start the dynamic task assignment version of the problem\n",
    "    For now we assume that the start solution is the model dependent version of the problem'''\n",
    "\n",
    "    print('Writing problem')\n",
    "    print('Number of tasks:', no_tasks, 'Number of workers:', NO_WORKERS, '\\n','Number of stations:', NO_STATIONS, 'Takt time:', takt_time, 'Sequence length:', sequence_length, 'worker_cost:', worker_cost)\n",
    "    workers = list(range(0, NO_WORKERS+1))\n",
    "    stations = list(range(NO_STATIONS))\n",
    "    model_instance = model_instance_obj.data\n",
    "    c_se = equipment_instance.c_se\n",
    "    R_oe = equipment_instance.r_oe\n",
    "    equipment = list( range(R_oe.shape[1]))\n",
    "    takts = list(range(sequence_length+NO_STATIONS-1))\n",
    "    u_se = plp.LpVariable.dicts('u_se', (stations, equipment), lowBound=0, cat='Binary')\n",
    "    b_wtsl = plp.LpVariable.dicts('b_wtsl', (prod_sequences.keys(), takts, stations, workers), lowBound=0, cat='Binary') \n",
    "    #TODO: maybe make this dictionary work different number of tasks for each model\n",
    "    x_wsoj = plp.LpVariable.dicts('x_wsoj', (prod_sequences.keys(), stations, range(no_tasks), range(sequence_length) ), lowBound=0, cat='Binary')\n",
    "    Y_w = plp.LpVariable.dicts('Y_w', (prod_sequences.keys()), lowBound=0, cat='Integer')\n",
    "    #Adding in the start solution\n",
    "    print('adding in start solution')\n",
    "    for v in start_solution.variables():\n",
    "        if 'x_soi' in v.name:\n",
    "            model_md = v.name.split('_')[4]\n",
    "            #change the task number to match with the instances\n",
    "            o = int(v.name.split('_')[3])\n",
    "            s = int(v.name.split('_')[2])\n",
    "            for w in prod_sequences.keys():\n",
    "                #setting x_wsoj values from the start solution\n",
    "                for j, model in enumerate(prod_sequences[w]['sequence']):\n",
    "                    if model_md == model:\n",
    "                        x_wsoj[w][s][o][j].setInitialValue(round(v.varValue))\n",
    "        elif 'b_wtsl' in v.name:\n",
    "            w = int(v.name.split('_')[2])\n",
    "            t = int(v.name.split('_')[3])\n",
    "            s = int(v.name.split('_')[4])\n",
    "            l = int(v.name.split('_')[5])\n",
    "            b_wtsl[w][t][s][l].setInitialValue(round(v.varValue)) \n",
    "        elif 'Y_w' in v.name:\n",
    "            w = int(v.name.split('_')[2])\n",
    "            Y_w[w].setInitialValue(round(v.varValue))\n",
    "        elif 'u_se' in v.name:\n",
    "            print('equipment', v.name.split('_'))\n",
    "            s = int(v.name.split('_')[2])\n",
    "            e = int(v.name.split('_')[3])\n",
    "            u_se[s][e].setInitialValue(round(v.varValue))\n",
    "    #Defining LP problem\n",
    "    prob = plp.LpProblem(\"stochastic_problem\", plp.LpMinimize)\n",
    "    #Objective function\n",
    "    prob += (plp.lpSum([c_se[s][e]*u_se[s][e]\n",
    "                         for s in stations\n",
    "                           for e in equipment]\n",
    "                      +\n",
    "                      [prod_sequences[w]['probability']*Y_w[w]* worker_cost\n",
    "                         for w in prod_sequences.keys()\n",
    "                        ]),\n",
    "                \"Total cost\")\n",
    "    #Constraints\n",
    "    #Constraint 1 -- Must hire Y workers if we use Y workers in a given takt\n",
    "    for w in prod_sequences.keys():\n",
    "        for t in takts:\n",
    "            prob += (plp.lpSum([l*b_wtsl[w][t][s][l] for s in stations for l in workers]) <= Y_w[w], f'Y_w_{w}_{t}')\n",
    "    #Constraint 2 -- can only assign l number of workers to a station for a given scenario and stage\n",
    "    for w in prod_sequences.keys():\n",
    "        for t in takts:\n",
    "            for s in stations:\n",
    "                prob += (plp.lpSum([b_wtsl[w][t][s][l] for l in workers]) == 1, f'b_wtsl_{w}_{t}_{s}')\n",
    "        #Constraint 3 all tasks must be assigned to a station\n",
    "    for w in prod_sequences.keys():\n",
    "        for j, model in enumerate(prod_sequences[w]['sequence']):\n",
    "            #Not strictly necessary if all models have the same number of tasks, could have just looped over no tasks\n",
    "            #but this is more general\n",
    "            for o in range(model_instance[model]['num_tasks']): \n",
    "                prob += (plp.lpSum([x_wsoj[w][s][o][j] for s in stations]) == 1, f'x_wsoj_{w}_s_{o}_{j}')\n",
    "        #Constraint 4 -- sum of task times for assigned tasks must be less than takt time times the number of workers for a given station\n",
    "    for w in prod_sequences.keys():\n",
    "        for t in takts:\n",
    "            for s in stations:\n",
    "                #Get the model at the current scenario, stage, and station\n",
    "                if 0<= t-s < sequence_length:\n",
    "                    j = t-s\n",
    "                    model = prod_sequences[w]['sequence'][j]\n",
    "                    task_times = model_instance[model]['task_times']\n",
    "                    prob += (plp.lpSum([task_times[o]*x_wsoj[w][s][int(o)-1][j] \n",
    "                                        for o in task_times]) \n",
    "                                        <= \n",
    "                                        takt_time*plp.lpSum([l * b_wtsl[w][t][s][l] for l in workers]), f'task_time_wts_{w}_{t}_{s}')\n",
    "\n",
    "    #Constraint 5 -- tasks can only be assigned to a station with the correct equipment\n",
    "    for w in prod_sequences.keys():\n",
    "        for j, model in enumerate(prod_sequences[w]['sequence']):\n",
    "            for s in stations:\n",
    "                for o in range(model_instance[model]['num_tasks']):\n",
    "                    prob += x_wsoj[w][s][o][j] <= plp.lpSum([R_oe[o][e]*u_se[s][e] for  e in equipment]), f'equipment_wsoj_{w}_{s}_{o}_{j}'\n",
    "        #Constraint 6 -- precedence constraints\n",
    "    for w in prod_sequences.keys():\n",
    "        for j, model in enumerate(prod_sequences[w]['sequence']):\n",
    "            for (pred, suc) in model_instance[model]['precedence_relations']:\n",
    "                prob += (plp.lpSum([ (s+1)  * x_wsoj[w][s][int(pred)-1][j] for s in stations])\n",
    "                         <=  \n",
    "                         plp.lpSum([ (s+1)  * x_wsoj[w][s][int(suc)-1][j] for s in stations]), \n",
    "                         f'task{pred} before task{suc} for model{model}, item {j} seq {w}' )\n",
    "        #Constraint 7 -- non-anticipativity constraints\n",
    "    for w in prod_sequences.keys():\n",
    "        for w_prime in prod_sequences.keys():\n",
    "            if w_prime > w:\n",
    "                add_non_anticipation(prob, w, w_prime , prod_sequences, model_instance, x_wsoj, sequence_length, NO_STATIONS)\n",
    "\n",
    "                \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warm_start_dynamic(instance_list, NO_EQUIPMENT,  NO_WORKERS, NO_STATIONS, WORKER_COST, TAKT_TIME, NO_TAKTS, MODEL_MIXTURES, seed, scenario_generator= make_scenario_tree, file_name = 'test', **kwargs):\n",
    "    instance_groups = pair_instances(instance_list, MODEL_MIXTURES)\n",
    "    print(instance_groups)\n",
    "    test_results = []\n",
    "    group_counter = 0\n",
    "    test_instances = []\n",
    "    instance_results = []\n",
    "    for group in instance_groups:\n",
    "        test_instance = MultiModelInstance(group)\n",
    "        print('Running instances', group)\n",
    "        print('\\n test_instance', test_instance)\n",
    "        test_instances.append(test_instance)\n",
    "        #create equipment\n",
    "        print('creating equipment')\n",
    "        equipment = Equipment(test_instance.all_tasks, NO_EQUIPMENT, NO_STATIONS, generate_equipment, seed)\n",
    "        #create scenario tree\n",
    "        print('generating scenario tree')\n",
    "        scenario_tree_graph, final_sequences = scenario_generator(NO_TAKTS, MODEL_MIXTURES, **kwargs)\n",
    "        print('defining problem')\n",
    "        md_prob = model_dependent_eq_linear_labour(test_instance, equipment,test_instance.no_tasks, NO_WORKERS, NO_STATIONS, TAKT_TIME, NO_TAKTS, final_sequences, worker_cost=WORKER_COST)\n",
    "        print('solving problem')\n",
    "        solver = plp.GUROBI_CMD(options=[('TimeLimit', 300),( 'LPWarmStart',2)])#\n",
    "        md_prob.solve(solver=solver)\n",
    "        print('\\n writing results')\n",
    "        print('model dependent objective value: ', md_prob.objective.value())\n",
    "        print('\\n solving dynamic problem')\n",
    "        dynamic_prob = dynamic_warm_start_model(test_instance, md_prob, equipment,test_instance.no_tasks, NO_WORKERS, NO_STATIONS, TAKT_TIME, NO_TAKTS, final_sequences, worker_cost=WORKER_COST)\n",
    "        dynamic_prob.solve(solver=solver)\n",
    "        md_result = obj_val_dict(group, md_prob.objective.value(),md_prob.status, test_instance.data)\n",
    "        dynamic_result = obj_val_dict(group, dynamic_prob.objective.value(),dynamic_prob.status, test_instance.data)\n",
    "        result = {**md_result, **dynamic_result}\n",
    "        instance_results.append(result)\n",
    "        print('test_instance', test_instance)\n",
    "        out_name = file_name + str(group_counter)\n",
    "        task_assignment, labor_assignment = generate_report_md(md_prob, final_sequences, test_instance.data, out_name + 'md')\n",
    "        task_assignment, labor_assignment = generate_report_dynamic(dynamic_prob, final_sequences, test_instance.data, out_name + 'dynamic')\n",
    "        group_counter += 1\n",
    "\n",
    "    instance_results = pd.DataFrame(instance_results)\n",
    "    instance_results.to_csv(file_name + '_results.csv')\n",
    "    return instance_results, test_instances\n",
    "\n",
    "start_time = time.time()\n",
    "file_name = 'model_runs/'+xp_name+f'/Warm_start_{NO_STATIONS}_E{NO_EQUIPMENT}_L{NO_WORKERS}_T{NO_TAKTS}_C{TAKT_TIME}_LC{WORKER_COST}_'\n",
    "print('writing to ', file_name)\n",
    "results_df, instances = warm_start_dynamic(instance_list, NO_EQUIPMENT,  NO_WORKERS, NO_STATIONS, WORKER_COST, TAKT_TIME, NO_TAKTS, MODEL_MIXTURES, seed, file_name = file_name)\n",
    "warm_start_time= time.time() - start_time\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('time for normal run', normal_time)\n",
    "print('time for warm start run', warm_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heuristic section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructive heuristic for model dependent task assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tasks selection methods\n",
    "def longest_processing_time(model, candidate_list, **kwargs):\n",
    "    max_task_time = 0\n",
    "    for candidate in candidate_list:\n",
    "        if model['task_times'][candidate] > max_task_time:\n",
    "            max_task_time = model['task_times'][candidate]\n",
    "            selected_task = candidate\n",
    "    return selected_task\n",
    "\n",
    "\n",
    "#Methods for the construction heurisitc\n",
    "\n",
    "def calculate_takt_time(model, NO_S, TAKT_TIME):\n",
    "    \"\"\"\n",
    "    Calculate the takt time for the model dependent model\n",
    "    \"\"\"\n",
    "    total_task_time = sum(model['task_times'].values())\n",
    "    new_takt_time = max(total_task_time/NO_S, TAKT_TIME)\n",
    "    return new_takt_time\n",
    "\n",
    "def model_task_assignment(model, all_tasks, NO_S, TAKT_TIME, selection_method, **kwargs):\n",
    "    '''This function assigns the tasks of a model '''\n",
    "    print('model', model)\n",
    "    x_so = np.zeros((NO_S,len(all_tasks)))\n",
    "    new_takt_time = calculate_takt_time( model, NO_S, TAKT_TIME)\n",
    "    prec_matrix = construct_precedence_matrix(model)\n",
    "    number_of_predecessor = np.sum(prec_matrix, axis=0)\n",
    "    for station in range(NO_S):\n",
    "        s_total_assingments = 0\n",
    "        while s_total_assingments < new_takt_time and np.any(number_of_predecessor != -1):\n",
    "            candidate_list = []\n",
    "            for task in model['task_times']:\n",
    "                task_in = int(task)-1\n",
    "                if number_of_predecessor[task_in] == 0:\n",
    "                    candidate_list.append(task)\n",
    "            selected_task = selection_method(model, candidate_list,  **kwargs)\n",
    "            selected_task_in = int(selected_task)-1\n",
    "            x_so[station, selected_task_in] = 1\n",
    "            s_total_assingments += model['task_times'][selected_task]\n",
    "            number_of_predecessor -= prec_matrix[selected_task_in]\n",
    "            number_of_predecessor[selected_task_in] = -1\n",
    "        #If all the elements in number of predecessor are -1, then all tasks are assigned\n",
    "        if np.all(number_of_predecessor == -1):\n",
    "            break\n",
    "    return x_so\n",
    "\n",
    "def constructive_heurisitc(instance, NO_S, TAKT_TIME, selection_method):\n",
    "    \"\"\"\n",
    "    Constructive heuristic for the model dependent model\n",
    "    \"\"\"\n",
    "    print('instance', instance)\n",
    "    all_tasks = get_task_union(instance, 'A', 'B')\n",
    "    print('all_tasks', all_tasks)\n",
    "    assignments = []\n",
    "    #heuristic asssigns tasks for each model in instance\n",
    "    for model in instance:\n",
    "        x_so = model_task_assignment( instance[model], all_tasks, NO_S, TAKT_TIME, selection_method)\n",
    "        assignments.append(x_so)\n",
    "    #combines assignments list into a single numpy array, where eac\n",
    "    x_soi = np.stack(assignments, axis=-1)\n",
    "    return x_soi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_constructive_heuristic(instance_list, NO_S, TAKT_TIME, MODEL_MIXTURES):\n",
    "    \"\"\"\n",
    "    Runs the constructive heuristic for all instances in the instance list\n",
    "    \"\"\"\n",
    "    heuristics = []\n",
    "    instance_groups = pair_instances(instance_list, MODEL_MIXTURES)\n",
    "    for group in instance_groups:\n",
    "        instance = create_instance_pair_stochastic(group)\n",
    "        heuristics.append(constructive_heurisitc(instance, NO_S, TAKT_TIME, longest_processing_time))\n",
    "    return heuristics\n",
    "\n",
    "def solve_from_initial_task_asssingments(instance, NO_S, TAKT_TIME, task_assignments):\n",
    "    \"\"\"\n",
    "    Solves the instance using the given task assignments\n",
    "    \"\"\"\n",
    "\n",
    "instance_list = [ \"SALBP_benchmark/small data set_n=20/instance_n=20_1.alb\",\n",
    "   \"SALBP_benchmark/small data set_n=20/instance_n=20_2.alb\",\n",
    "   ]\n",
    "NO_S = 4\n",
    "MODEL_MIXTURES = {'A': 0.5, 'B': 0.5}\n",
    "results_heuristic = run_constructive_heuristic(instance_list, NO_S, TAKT_TIME, MODEL_MIXTURES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix and Optimize LNS, starting with model dependent and going to dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will take a solution of the model depedent problem and use it as the first solution for the dynamic case. Here, instead of reoptimizing the entire thing, we choose 2-3 adjacent stations and reoptimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_and_optimize(instance, seed, no_iterations = 10, scenario_generator= make_scenario_tree, file_name = 'fix_and_optimize test', **kwargs):\n",
    "    \"\"\"\n",
    "    Fixes the task assignments and solves the instance\n",
    "    \"\"\"\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
