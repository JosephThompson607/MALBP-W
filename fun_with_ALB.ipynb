{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pulp as plp\n",
    "from ALB_instance_tools import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Gets list of all instance (.alb) files in the SALBP_benchmark/small\\ data\\ set_n\\=20 folder\n",
    "#instance_list = get_instance_list('SALBP_benchmark/small data set_n=20')\n",
    "instance_list = get_instance_list('SALBP_benchmark/large data set_n=100')\n",
    "#sorts instance list by instance number\n",
    "instance_list = sorted(instance_list, key=lambda k: int(k['name'].split(\"_\")[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def define_ALBP_1_problem(instance, max_stations = 20):\n",
    "    prob = plp.LpProblem(\"ALPB_1\", plp.LpMinimize)\n",
    "    #creating decision variables\n",
    "    tasks = plp.LpVariable.dicts(\"task_o_s\", (instance['task_times'].keys(), range(1,max_stations + 1)), cat='Binary')\n",
    "    #objective function\n",
    "    prob += plp.lpSum([ station * tasks[task][station] for station in range(1,max_stations + 1) for task in instance['task_times'].keys()])\n",
    "    #definining constraints\n",
    "    #constraint 1 only choose 1 station for each task\n",
    "    for task in instance['task_times'].keys():\n",
    "        prob += plp.lpSum([tasks[task][station] for station in range(1,max_stations + 1)]) == 1\n",
    "    #constraint 2 task and station assignment must respect takt time\n",
    "    for station in range(1,max_stations + 1):\n",
    "        prob += plp.lpSum([instance['task_times'][task] * tasks[task][station] for task in instance['task_times'].keys()]) <= instance['cycle_time']\n",
    "    #constraint 3 tasks must respect precedence constraints\n",
    "    for precedence in instance['precedence_relations']:\n",
    "        prob += plp.lpSum([station * tasks[precedence[0]][station] for station in range(1,max_stations + 1)]) <= plp.lpSum([station * tasks[precedence[1]][station] for station in range(1,max_stations + 1)])\n",
    "    return prob\n",
    "\n",
    "def solve_ALBP_1(instance, max_stations = 20):\n",
    "    prob = define_ALBP_1_problem(instance, max_stations)\n",
    "    prob.solve(solver=plp.XPRESS_PY( msg=False))\n",
    "    max_station = -10\n",
    "    task_assignment = {}\n",
    "    for variable in prob.variables():\n",
    "        if variable.varValue > 0:\n",
    "            task = variable.name.split(\"_\")[3]\n",
    "            station = variable.name.split(\"_\")[4]\n",
    "            #Adds dictionary where key is the task and value is the station\n",
    "            task_assignment[task] = station\n",
    "            #Find the largest station number that is used\n",
    "            if int(station) > max_station:\n",
    "                max_station = int(station)\n",
    "    return max_station, task_assignment\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ALBP_solutions(problems_list, ALBP_solver = solve_ALBP_1, max_stations = 20, **kwargs):\n",
    "    solutions = []\n",
    "    for problem in problems_list:\n",
    "        instance = parse_alb(problem['location'])\n",
    "        print('solving problem', problem['name'])\n",
    "        no_stations, task_assignment = ALBP_solver(instance, max_stations = max_stations,**kwargs)\n",
    "        #creates a new dictionary entry that contains the data on the instances\n",
    "        \n",
    "        entry = {'name':problem['name']}\n",
    "        entry['no_tasks'] = len(instance['task_times'].keys())\n",
    "        entry['order_strength'] = instance['order_strength']\n",
    "        entry['cycle_time'] = instance['cycle_time']\n",
    "        entry['no_stations'] = no_stations\n",
    "        entry['task_assignment'] = task_assignment\n",
    "        solutions.append(entry)\n",
    "    return solutions\n",
    "solution_outputs = get_ALBP_solutions([instance_list[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_outputs = pd.DataFrame(solution_outputs)\n",
    "# solution_outputs.to_csv('ALBP_1_solutions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scoring functions\n",
    "def task_time_weight(tasks_dict, instance):\n",
    "    for task in tasks_dict.keys():\n",
    "        tasks_dict[task]['score'] = instance['task_times'][task]\n",
    "\n",
    "def backwards_recursive_positional_weight(tasks_dict, instance):\n",
    "    #calculates the positional weight of each task of the instance\n",
    "    p_graph = nx.DiGraph()\n",
    "    p_graph.add_nodes_from([(key, {'task_time':value}) for key, value in instance[\"task_times\"].items()])\n",
    "    p_graph.add_edges_from(instance[\"precedence_relations\"], color=\"r\")\n",
    "    weights = {}\n",
    "    while len(p_graph.nodes) > 0:\n",
    "        leaves = []\n",
    "        for n in p_graph.nodes():\n",
    "            if not list(p_graph.successors(n)):\n",
    "                weights[n] = p_graph.nodes[n]['task_time']\n",
    "                leaves.append(n)\n",
    "                for p in p_graph.predecessors(n):\n",
    "                    p_graph.nodes[p]['task_time'] += p_graph.nodes[n]['task_time']\n",
    "        p_graph.remove_nodes_from(leaves)\n",
    "    for weight in weights.keys():\n",
    "        tasks_dict[weight]['score'] = weights[weight]\n",
    "\n",
    "\n",
    "def collect_parents(p_graph):\n",
    "    '''Collects the parents of each node in a graph and returns a dictionary with the node as key and the set of parents as value'''\n",
    "    weight_set = {}\n",
    "    while len(p_graph.nodes) > 0:\n",
    "        leaves = []\n",
    "        for n in p_graph.nodes():\n",
    "            if not list(p_graph.successors(n)):\n",
    "                weight_set[n] = p_graph.nodes[n]['task_set']\n",
    "                leaves.append(n)\n",
    "                for p in p_graph.predecessors(n):\n",
    "                    p_graph.nodes[p]['task_set'] =  p_graph.nodes[p]['task_set'].union(p_graph.nodes[n]['task_set'])\n",
    "        p_graph.remove_nodes_from(leaves)\n",
    "    return weight_set\n",
    "\n",
    "def reverse_positional_weight(tasks_dict, instance):\n",
    "    #calculates the reverse positional weight of each task of the instance\n",
    "    p_graph = nx.DiGraph()\n",
    "    p_graph.add_nodes_from([(key, {'task_time':value, 'task_set':set([key])}) for key, value in instance[\"task_times\"].items()])\n",
    "    p_graph.add_edges_from(instance[\"precedence_relations\"], color=\"r\")\n",
    "    p_graph = p_graph.reverse()\n",
    "    weight_set = collect_parents(p_graph)\n",
    "    for weight in weight_set.keys():\n",
    "        tasks_dict[weight]['score'] = sum([instance['task_times'][task] for task in weight_set[weight]])\n",
    "\n",
    "def positional_weight(tasks_dict, instance):\n",
    "    #calculates the positional weight of each task of the instance\n",
    "    p_graph = nx.DiGraph()\n",
    "    p_graph.add_nodes_from([(key, {'task_time':value, 'task_set':set([key])}) for key, value in instance[\"task_times\"].items()])\n",
    "    p_graph.add_edges_from(instance[\"precedence_relations\"], color=\"r\")\n",
    "    weight_set = collect_parents(p_graph)\n",
    "    for weight in weight_set.keys():\n",
    "        tasks_dict[weight]['score'] = sum([instance['task_times'][task] for task in weight_set[weight]])\n",
    "\n",
    "\n",
    "def rank_and_assign_initialization(instance,score_function, max_stations = 20):\n",
    "    station_capacities = [instance['cycle_time'] for i in range(0, max_stations)]\n",
    "    tasks_dict = {}\n",
    "    for task in instance['task_times'].keys():\n",
    "        task_dict = {}\n",
    "        task_dict['predecessors'] = [precedence[0] for precedence in instance['precedence_relations'] if precedence[1] == task]\n",
    "        tasks_dict[task] = task_dict\n",
    "    score_function(tasks_dict, instance)\n",
    "    #sorts tasks_dict by score\n",
    "    tasks_dict = {k: v for k, v in sorted(tasks_dict.items(), key=lambda item: item[1]['score'])}\n",
    "     \n",
    "    return tasks_dict, station_capacities\n",
    "\n",
    "#fills up each station with available tasks in order of score\n",
    "def insert_task(tasks_dict, station_capacities, assignment_dict):\n",
    "    for index, station in enumerate(station_capacities):\n",
    "            for task in tasks_dict.keys():\n",
    "                if instance['task_times'][task] <= station and all(predecessor not in tasks_dict.keys() for predecessor in tasks_dict[task]['predecessors']):\n",
    "                    station_capacities[index] -= instance['task_times'][task]\n",
    "                    assignment_dict[task] = index + 1\n",
    "                    tasks_dict.pop(task)\n",
    "                    return\n",
    "    raise ValueError(f'no task can be assigned to any station (try adding more stations)')\n",
    "\n",
    "# RA heuristic as described in \"A comparative Evaluation of Heuristics for the Assembly Line Balancing Problem\" by Ponnanbalam et. al              \n",
    "def rank_and_assign( instance,score_function, max_stations = 20):\n",
    "    task_assignment = {}\n",
    "    tasks_dict, station_capacities = rank_and_assign_initialization(instance, score_function, max_stations)\n",
    "    #Inserts tasks into stations until there are no more tasks\n",
    "    while len(tasks_dict.keys()) > 0:\n",
    "        insert_task(tasks_dict, station_capacities, task_assignment)\n",
    "    return station_capacities, task_assignment, sum([1 for station in station_capacities if station < instance['cycle_time']])\n",
    "\n",
    "instance = parse_alb(instance_list[0]['location'])\n",
    "\n",
    "station_capacities1, task_assignment1, stations = rank_and_assign(instance, positional_weight, max_stations = 30)\n",
    "station_capacities1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p_graph = nx.DiGraph()\n",
    "\n",
    "p_graph.add_nodes_from([(key, {'task_time':value}) for key, value in instance[\"task_times\"].items()])\n",
    "p_graph.add_edges_from(instance[\"precedence_relations\"], color=\"r\")\n",
    "    \n",
    "colors = [p_graph[u][v][\"color\"] for u, v in p_graph.edges]\n",
    "weights = []\n",
    "while len(p_graph.nodes) > 1:\n",
    "    leaves = []\n",
    "    for n in p_graph.nodes():\n",
    "        if not list(p_graph.successors(n)):\n",
    "            weights.append({'task': n, 'pos_weight':p_graph.nodes[n]['task_time']})\n",
    "            leaves.append(n)\n",
    "            for p in p_graph.predecessors(n):\n",
    "                p_graph.nodes[p]['task_time'] += p_graph.nodes[n]['task_time']\n",
    "    p_graph.remove_nodes_from(leaves)\n",
    "\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserts tasks into first available station\n",
    "def insert_task_iuff(tasks_dict, station_capacities):\n",
    "    for task in tasks_dict.keys():\n",
    "        if tasks_dict[task]['status'] == 'available':\n",
    "            for index, station in enumerate(station_capacities):\n",
    "                if instance['task_times'][task] <= station:\n",
    "                    station_capacities[index] -= instance['task_times'][task]\n",
    "                    tasks_dict[task]['status'] = index + 1\n",
    "                    return\n",
    "    raise ValueError('No available stations')\n",
    "\n",
    "def update_tasks(tasks_dict):\n",
    "    for task in tasks_dict.keys():\n",
    "        if tasks_dict[task]['status'] == 'unavailable':\n",
    "            #if all predecessors are assigned to a station, mark task as available\n",
    "            for predecessor in tasks_dict[task]['predecessors']:\n",
    "                if tasks_dict[predecessor]['status'] not in  ['available', 'unavailable']:\n",
    "                    tasks_dict[task]['status'] = 'available'\n",
    "                    return\n",
    "\n",
    "def iuff_initialization(instance, score_function, max_stations = 20):\n",
    "    station_capacities = [instance['cycle_time'] for i in range(0, max_stations)]\n",
    "    tasks_dict = {}\n",
    "    for task in instance['task_times'].keys():\n",
    "        task_dict = {}\n",
    "        task_dict['predecessors'] = [precedence[0] for precedence in instance['precedence_relations'] if precedence[1] == task]\n",
    "        #adds tasks with no predecessors to available tasks\n",
    "        if not task_dict['predecessors']:\n",
    "            task_dict['status'] = 'available'\n",
    "        else:\n",
    "            task_dict['status'] = 'unavailable'\n",
    "        tasks_dict[task] = task_dict\n",
    "    #sorts tasks_dict by score\n",
    "    score_function(tasks_dict, instance)\n",
    "    tasks_dict = {k: v for k, v in sorted(tasks_dict.items(), key=lambda item: item[1]['score'], reverse=True)}\n",
    "\n",
    "    return tasks_dict, station_capacities\n",
    "    \n",
    "     \n",
    "# IUFF heuristic as described in \"A comparative Evaluation of Heuristics for the Assembly Line Balancing Problem\" by Ponnanbalam et. al              \n",
    "def immediate_update_first_fit( instance,score_function = None, max_stations = 20):\n",
    "    tasks_dict, station_capacities = iuff_initialization(instance, score_function, max_stations)\n",
    "\n",
    "    while not all(task['status'] not in ['unavailable', 'available'] for task in tasks_dict.values()):\n",
    "        insert_task_iuff(tasks_dict, station_capacities)\n",
    "        update_tasks(tasks_dict)\n",
    "    task_assignment = {task: tasks_dict[task]['status'] for task in tasks_dict.keys()}\n",
    "    return  sum([1 for station in station_capacities if station < instance['cycle_time']]), task_assignment\n",
    "\n",
    "instance = parse_alb(instance_list[1]['location'])\n",
    "no_stations, task_assignment = immediate_update_first_fit(instance,positional_weight, max_stations=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_outputs = get_ALBP_solutions(instance_list, ALBP_solver = immediate_update_first_fit, score_function = reverse_positional_weight, max_stations = 60)\n",
    "solution_outputs = pd.DataFrame(solution_outputs)\n",
    "solution_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
