{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pulp as plp\n",
    "from ALB_instance_tools import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/letshopethisworks2/Documents/Phd Paper material/MMABPWW\n"
     ]
    }
   ],
   "source": [
    "! pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Gets list of all instance (.alb) files in the SALBP_benchmark/small\\ data\\ set_n\\=20 folder\n",
    "instance_list = get_instance_list('SALBP_benchmark/small data set_n=20')\n",
    "#instance_list = get_instance_list('SALBP_benchmark/large data set_n=100')\n",
    "#sorts instance list by instance number\n",
    "instance_list = sorted(instance_list, key=lambda k: int(k['name'].split(\"_\")[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def define_ALBP_1_problem(instance, max_stations = 20):\n",
    "    prob = plp.LpProblem(\"ALPB_1\", plp.LpMinimize)\n",
    "    #creating decision variables\n",
    "    tasks = plp.LpVariable.dicts(\"task_o_s\", (instance['task_times'].keys(), range(1,max_stations + 1)), cat='Binary')\n",
    "    #objective function\n",
    "    prob += plp.lpSum([ station * tasks[task][station] for station in range(1,max_stations + 1) for task in instance['task_times'].keys()])\n",
    "    #definining constraints\n",
    "    #constraint 1 only choose 1 station for each task\n",
    "    for task in instance['task_times'].keys():\n",
    "        prob += plp.lpSum([tasks[task][station] for station in range(1,max_stations + 1)]) == 1\n",
    "    #constraint 2 task and station assignment must respect takt time\n",
    "    for station in range(1,max_stations + 1):\n",
    "        prob += plp.lpSum([instance['task_times'][task] * tasks[task][station] for task in instance['task_times'].keys()]) <= instance['cycle_time']\n",
    "    #constraint 3 tasks must respect precedence constraints\n",
    "    for precedence in instance['precedence_relations']:\n",
    "        prob += plp.lpSum([station * tasks[precedence[0]][station] for station in range(1,max_stations + 1)]) <= plp.lpSum([station * tasks[precedence[1]][station] for station in range(1,max_stations + 1)])\n",
    "    return prob\n",
    "\n",
    "def solve_ALBP_1(instance, max_stations = 20):\n",
    "    prob = define_ALBP_1_problem(instance, max_stations)\n",
    "    prob.solve(solver=plp.XPRESS_PY( msg=False))\n",
    "    max_station = -10\n",
    "    task_assignment = {}\n",
    "    for variable in prob.variables():\n",
    "        if variable.varValue > 0:\n",
    "            task = variable.name.split(\"_\")[3]\n",
    "            station = variable.name.split(\"_\")[4]\n",
    "            #Adds dictionary where key is the task and value is the station\n",
    "            task_assignment[task] = station\n",
    "            #Find the largest station number that is used\n",
    "            if int(station) > max_station:\n",
    "                max_station = int(station)\n",
    "    return max_station, task_assignment\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solving problem 20_1\n"
     ]
    }
   ],
   "source": [
    "def get_ALBP_solutions(problems_list, ALBP_solver = solve_ALBP_1, max_stations = 20, **kwargs):\n",
    "    solutions = []\n",
    "    for problem in problems_list:\n",
    "        instance = parse_alb(problem['location'])\n",
    "        print('solving problem', problem['name'])\n",
    "        no_stations, task_assignment = ALBP_solver(instance, max_stations = max_stations,**kwargs)\n",
    "        #creates a new dictionary entry that contains the data on the instances\n",
    "        \n",
    "        entry = {'name':problem['name']}\n",
    "        entry['no_tasks'] = len(instance['task_times'].keys())\n",
    "        entry['order_strength'] = instance['order_strength']\n",
    "        entry['cycle_time'] = instance['cycle_time']\n",
    "        entry['no_stations'] = no_stations\n",
    "        entry['task_assignment'] = task_assignment\n",
    "        solutions.append(entry)\n",
    "    return solutions\n",
    "solution_outputs = get_ALBP_solutions([instance_list[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solving problem 20_16\n"
     ]
    }
   ],
   "source": [
    "solution_outputs = get_ALBP_solutions([instance_list[15]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': '20_16',\n",
       "  'no_tasks': 20,\n",
       "  'order_strength': 0.232,\n",
       "  'cycle_time': 1000,\n",
       "  'no_stations': 12,\n",
       "  'task_assignment': {'10': '11',\n",
       "   '11': '9',\n",
       "   '12': '7',\n",
       "   '13': '3',\n",
       "   '14': '7',\n",
       "   '15': '10',\n",
       "   '16': '5',\n",
       "   '17': '4',\n",
       "   '18': '12',\n",
       "   '19': '11',\n",
       "   '1': '4',\n",
       "   '20': '5',\n",
       "   '2': '1',\n",
       "   '3': '2',\n",
       "   '4': '1',\n",
       "   '5': '8',\n",
       "   '6': '6',\n",
       "   '7': '2',\n",
       "   '8': '3',\n",
       "   '9': '6'}}]"
      ]
     },
     "execution_count": 942,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_outputs = pd.DataFrame(solution_outputs)\n",
    "# solution_outputs.to_csv('ALBP_1_solutions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 944,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scoring functions\n",
    "def task_time_weight(tasks_dict, instance):\n",
    "    for task in tasks_dict.keys():\n",
    "        tasks_dict[task]['score'] = instance['task_times'][task]\n",
    "\n",
    "def backwards_recursive_positional_weight(tasks_dict, instance):\n",
    "    #calculates the positional weight of each task of the instance\n",
    "    p_graph = nx.DiGraph()\n",
    "    p_graph.add_nodes_from([(key, {'task_time':value}) for key, value in instance[\"task_times\"].items()])\n",
    "    p_graph.add_edges_from(instance[\"precedence_relations\"], color=\"r\")\n",
    "    weights = {}\n",
    "    while len(p_graph.nodes) > 0:\n",
    "        leaves = []\n",
    "        for n in p_graph.nodes():\n",
    "            if not list(p_graph.successors(n)):\n",
    "                weights[n] = p_graph.nodes[n]['task_time']\n",
    "                leaves.append(n)\n",
    "                for p in p_graph.predecessors(n):\n",
    "                    p_graph.nodes[p]['task_time'] += p_graph.nodes[n]['task_time']\n",
    "        p_graph.remove_nodes_from(leaves)\n",
    "    for weight in weights.keys():\n",
    "        tasks_dict[weight]['score'] = weights[weight]\n",
    "\n",
    "\n",
    "def collect_parents(p_graph):\n",
    "    '''Collects the parents of each node in a graph and returns a dictionary with the node as key and the set of parents as value'''\n",
    "    weight_set = {}\n",
    "    while len(p_graph.nodes) > 0:\n",
    "        leaves = []\n",
    "        for n in p_graph.nodes():\n",
    "            if not list(p_graph.successors(n)):\n",
    "                weight_set[n] = p_graph.nodes[n]['task_set']\n",
    "                leaves.append(n)\n",
    "                for p in p_graph.predecessors(n):\n",
    "                    p_graph.nodes[p]['task_set'] =  p_graph.nodes[p]['task_set'].union(p_graph.nodes[n]['task_set'])\n",
    "        p_graph.remove_nodes_from(leaves)\n",
    "    return weight_set\n",
    "\n",
    "def reverse_positional_weight(tasks_dict, instance):\n",
    "    #calculates the reverse positional weight of each task of the instance\n",
    "    p_graph = nx.DiGraph()\n",
    "    p_graph.add_nodes_from([(key, {'task_time':value, 'task_set':set([key])}) for key, value in instance[\"task_times\"].items()])\n",
    "    p_graph.add_edges_from(instance[\"precedence_relations\"], color=\"r\")\n",
    "    p_graph = p_graph.reverse()\n",
    "    weight_set = collect_parents(p_graph)\n",
    "    for weight in weight_set.keys():\n",
    "        tasks_dict[weight]['score'] = sum([instance['task_times'][task] for task in weight_set[weight]])\n",
    "\n",
    "def positional_weight(tasks_dict, instance):\n",
    "    #calculates the positional weight of each task of the instance\n",
    "    p_graph = nx.DiGraph()\n",
    "    p_graph.add_nodes_from([(key, {'task_time':value, 'task_set':set([key])}) for key, value in instance[\"task_times\"].items()])\n",
    "    p_graph.add_edges_from(instance[\"precedence_relations\"], color=\"r\")\n",
    "    weight_set = collect_parents(p_graph)\n",
    "    for weight in weight_set.keys():\n",
    "        tasks_dict[weight]['score'] = sum([instance['task_times'][task] for task in weight_set[weight]])\n",
    "\n",
    "\n",
    "def rank_and_assign_initialization(instance,score_function, max_stations = 20):\n",
    "    station_capacities = [instance['cycle_time'] for i in range(0, max_stations)]\n",
    "    tasks_dict = {}\n",
    "    for task in instance['task_times'].keys():\n",
    "        task_dict = {}\n",
    "        task_dict['predecessors'] = [precedence[0] for precedence in instance['precedence_relations'] if precedence[1] == task]\n",
    "        tasks_dict[task] = task_dict\n",
    "    score_function(tasks_dict, instance)\n",
    "    #sorts tasks_dict by score\n",
    "    tasks_dict = {k: v for k, v in sorted(tasks_dict.items(), key=lambda item: item[1]['score'])}\n",
    "     \n",
    "    return tasks_dict, station_capacities\n",
    "\n",
    "#fills up each station with available tasks in order of score\n",
    "def insert_task(instance, tasks_dict, station_capacities, assignment_dict):\n",
    "    for index, station in enumerate(station_capacities):\n",
    "            for task in tasks_dict.keys():\n",
    "                if instance['task_times'][task] <= station and all(predecessor not in tasks_dict.keys() for predecessor in tasks_dict[task]['predecessors']):\n",
    "                    station_capacities[index] -= instance['task_times'][task]\n",
    "                    assignment_dict[task] = index + 1\n",
    "                    tasks_dict.pop(task)\n",
    "                    return\n",
    "    raise ValueError(f'no task can be assigned to any station (try adding more stations)')\n",
    "\n",
    "# RA heuristic as described in \"A comparative Evaluation of Heuristics for the Assembly Line Balancing Problem\" by Ponnanbalam et. al              \n",
    "def rank_and_assign( instance,score_function, max_stations = 20):\n",
    "    task_assignment = {}\n",
    "    tasks_dict, station_capacities = rank_and_assign_initialization(instance, score_function, max_stations)\n",
    "    #Inserts tasks into stations until there are no more tasks\n",
    "    while len(tasks_dict.keys()) > 0:\n",
    "        insert_task(instance, tasks_dict, station_capacities, task_assignment)\n",
    "    return  sum([1 for station in station_capacities if station < instance['cycle_time']]),task_assignment\n",
    "\n",
    "instance = parse_alb(instance_list[16]['location'])\n",
    "\n",
    "stations, task_assignment1  = rank_and_assign(instance, positional_weight, max_stations = 30)\n",
    "stations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'task': '5', 'pos_weight': 271}, {'task': '6', 'pos_weight': 386}, {'task': '11', 'pos_weight': 409}, {'task': '14', 'pos_weight': 334}, {'task': '15', 'pos_weight': 491}, {'task': '16', 'pos_weight': 420}, {'task': '17', 'pos_weight': 513}, {'task': '18', 'pos_weight': 409}, {'task': '19', 'pos_weight': 381}, {'task': '20', 'pos_weight': 698}, {'task': '12', 'pos_weight': 1128}, {'task': '13', 'pos_weight': 2883}, {'task': '1', 'pos_weight': 3407}, {'task': '2', 'pos_weight': 3536}, {'task': '7', 'pos_weight': 3443}, {'task': '9', 'pos_weight': 2159}, {'task': '10', 'pos_weight': 3183}, {'task': '4', 'pos_weight': 2639}, {'task': '8', 'pos_weight': 3656}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p_graph = nx.DiGraph()\n",
    "\n",
    "p_graph.add_nodes_from([(key, {'task_time':value}) for key, value in instance[\"task_times\"].items()])\n",
    "p_graph.add_edges_from(instance[\"precedence_relations\"], color=\"r\")\n",
    "    \n",
    "colors = [p_graph[u][v][\"color\"] for u, v in p_graph.edges]\n",
    "weights = []\n",
    "while len(p_graph.nodes) > 1:\n",
    "    leaves = []\n",
    "    for n in p_graph.nodes():\n",
    "        if not list(p_graph.successors(n)):\n",
    "            weights.append({'task': n, 'pos_weight':p_graph.nodes[n]['task_time']})\n",
    "            leaves.append(n)\n",
    "            for p in p_graph.predecessors(n):\n",
    "                p_graph.nodes[p]['task_time'] += p_graph.nodes[n]['task_time']\n",
    "    p_graph.remove_nodes_from(leaves)\n",
    "\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserts tasks into first available station\n",
    "def insert_task_iuff(instance, task, tasks_dict,assignment_dict, station_capacities):\n",
    "    for index, station_cap in enumerate(station_capacities):\n",
    "            if instance['task_times'][task] <= station_cap:\n",
    "                if tasks_dict[task]['available_after'] <= index + 1:\n",
    "                    station_capacities[index] -= instance['task_times'][task]\n",
    "                    assignment_dict[task] = index + 1\n",
    "                    tasks_dict.pop(task)\n",
    "                    return\n",
    "\n",
    "\n",
    "def update_tasks(tasks_dict, assignment_dict):\n",
    "    available_tasks = []\n",
    "    for task in tasks_dict.keys():\n",
    "            #if all predecessors are assigned to a station, mark task as available\n",
    "            if tasks_dict[task]['available_after'] == 'unavailable':\n",
    "                if all([predecessor in  assignment_dict.keys() for predecessor in tasks_dict[task]['predecessors']]):\n",
    "                    tasks_dict[task]['available_after'] = max([assignment_dict[predecessor] for predecessor in tasks_dict[task]['predecessors']])\n",
    "                    return task\n",
    "            else:\n",
    "                return task\n",
    "\n",
    "\n",
    "def iuff_initialization(instance, score_function, max_stations = 20, **kwargs):\n",
    "    station_capacities = [instance['cycle_time'] for i in range(0, max_stations)]\n",
    "    tasks_dict = {}\n",
    "    available_tasks = []\n",
    "    for task in instance['task_times'].keys():\n",
    "        task_dict = {}\n",
    "        task_dict['predecessors'] = [precedence[0] for precedence in instance['precedence_relations'] if precedence[1] == task]\n",
    "        #adds tasks with no predecessors to available tasks\n",
    "        if not task_dict['predecessors']:\n",
    "            task_dict['available_after'] = 0\n",
    "            available_tasks.append(task)\n",
    "        else:\n",
    "            task_dict['available_after'] = 'unavailable'\n",
    "        tasks_dict[task] = task_dict\n",
    "    #sorts tasks_dict by score\n",
    "    score_function(tasks_dict, instance, **kwargs)\n",
    "    tasks_dict = {k: v for k, v in sorted(tasks_dict.items(), key=lambda item: item[1]['score'], reverse=True)}\n",
    "    return tasks_dict, available_tasks[0], station_capacities\n",
    "    \n",
    "     \n",
    "# IUFF heuristic as described in \"A comparative Evaluation of Heuristics for the Assembly Line Balancing Problem\" by Ponnanbalam et. al              \n",
    "def immediate_update_first_fit( instance,score_function = None, max_stations = 20, **kwargs):\n",
    "    tasks_dict, available_task, station_capacities = iuff_initialization(instance, score_function, max_stations)\n",
    "    assignment_dict = {}\n",
    "    while tasks_dict:\n",
    "        insert_task_iuff(instance, available_task, tasks_dict, assignment_dict, station_capacities, **kwargs)\n",
    "        available_task = update_tasks(tasks_dict, assignment_dict)\n",
    "   \n",
    "    return  sum([1 for station in station_capacities if station < instance['cycle_time']]), assignment_dict\n",
    "\n",
    "instance = parse_alb('SALBP_benchmark/debugging_ds/instance_n=5_1.alb')\n",
    "no_stations, task_assignment = immediate_update_first_fit(instance,positional_weight, max_stations=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = {'cat':(1,4)}\n",
    "\n",
    "if number['cat'][0] == 1:\n",
    "    if number['cat'][1] == 2:\n",
    "        print('yes')\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 948,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solving problem 20_1\n",
      "solving problem 20_2\n",
      "solving problem 20_3\n",
      "solving problem 20_4\n",
      "solving problem 20_5\n",
      "solving problem 20_6\n",
      "solving problem 20_7\n",
      "solving problem 20_8\n",
      "solving problem 20_9\n",
      "solving problem 20_10\n",
      "solving problem 20_11\n",
      "solving problem 20_12\n",
      "solving problem 20_13\n",
      "solving problem 20_14\n",
      "solving problem 20_15\n",
      "solving problem 20_16\n",
      "solving problem 20_17\n",
      "solving problem 20_18\n",
      "solving problem 20_19\n",
      "solving problem 20_20\n",
      "solving problem 20_21\n",
      "solving problem 20_22\n",
      "solving problem 20_23\n",
      "solving problem 20_24\n",
      "solving problem 20_25\n",
      "solving problem 20_26\n",
      "solving problem 20_27\n",
      "solving problem 20_28\n",
      "solving problem 20_29\n",
      "solving problem 20_30\n",
      "solving problem 20_31\n",
      "solving problem 20_32\n",
      "solving problem 20_33\n",
      "solving problem 20_34\n",
      "solving problem 20_35\n",
      "solving problem 20_36\n",
      "solving problem 20_37\n",
      "solving problem 20_38\n",
      "solving problem 20_39\n",
      "solving problem 20_40\n",
      "solving problem 20_41\n",
      "solving problem 20_42\n",
      "solving problem 20_43\n",
      "solving problem 20_44\n",
      "solving problem 20_45\n",
      "solving problem 20_46\n",
      "solving problem 20_47\n",
      "solving problem 20_48\n",
      "solving problem 20_49\n",
      "solving problem 20_50\n",
      "solving problem 20_51\n",
      "solving problem 20_52\n",
      "solving problem 20_53\n",
      "solving problem 20_54\n",
      "solving problem 20_55\n",
      "solving problem 20_56\n",
      "solving problem 20_57\n",
      "solving problem 20_58\n",
      "solving problem 20_59\n",
      "solving problem 20_60\n",
      "solving problem 20_61\n",
      "solving problem 20_62\n",
      "solving problem 20_63\n",
      "solving problem 20_64\n",
      "solving problem 20_65\n",
      "solving problem 20_66\n",
      "solving problem 20_67\n",
      "solving problem 20_68\n",
      "solving problem 20_69\n",
      "solving problem 20_70\n",
      "solving problem 20_71\n",
      "solving problem 20_72\n",
      "solving problem 20_73\n",
      "solving problem 20_74\n",
      "solving problem 20_75\n",
      "solving problem 20_76\n",
      "solving problem 20_77\n",
      "solving problem 20_78\n",
      "solving problem 20_79\n",
      "solving problem 20_80\n",
      "solving problem 20_81\n",
      "solving problem 20_82\n",
      "solving problem 20_83\n",
      "solving problem 20_84\n",
      "solving problem 20_85\n",
      "solving problem 20_86\n",
      "solving problem 20_87\n",
      "solving problem 20_88\n",
      "solving problem 20_89\n",
      "solving problem 20_90\n",
      "solving problem 20_91\n",
      "solving problem 20_92\n",
      "solving problem 20_93\n",
      "solving problem 20_94\n",
      "solving problem 20_95\n",
      "solving problem 20_96\n",
      "solving problem 20_97\n",
      "solving problem 20_98\n",
      "solving problem 20_99\n",
      "solving problem 20_100\n",
      "solving problem 20_101\n",
      "solving problem 20_102\n",
      "solving problem 20_103\n",
      "solving problem 20_104\n",
      "solving problem 20_105\n",
      "solving problem 20_106\n",
      "solving problem 20_107\n",
      "solving problem 20_108\n",
      "solving problem 20_109\n",
      "solving problem 20_110\n",
      "solving problem 20_111\n",
      "solving problem 20_112\n",
      "solving problem 20_113\n",
      "solving problem 20_114\n",
      "solving problem 20_115\n",
      "solving problem 20_116\n",
      "solving problem 20_117\n",
      "solving problem 20_118\n",
      "solving problem 20_119\n",
      "solving problem 20_120\n",
      "solving problem 20_121\n",
      "solving problem 20_122\n",
      "solving problem 20_123\n",
      "solving problem 20_124\n",
      "solving problem 20_125\n",
      "solving problem 20_126\n",
      "solving problem 20_127\n",
      "solving problem 20_128\n",
      "solving problem 20_129\n",
      "solving problem 20_130\n",
      "solving problem 20_131\n",
      "solving problem 20_132\n",
      "solving problem 20_133\n",
      "solving problem 20_134\n",
      "solving problem 20_135\n",
      "solving problem 20_136\n",
      "solving problem 20_137\n",
      "solving problem 20_138\n",
      "solving problem 20_139\n",
      "solving problem 20_140\n",
      "solving problem 20_141\n",
      "solving problem 20_142\n",
      "solving problem 20_143\n",
      "solving problem 20_144\n",
      "solving problem 20_145\n",
      "solving problem 20_146\n",
      "solving problem 20_147\n",
      "solving problem 20_148\n",
      "solving problem 20_149\n",
      "solving problem 20_150\n",
      "solving problem 20_151\n",
      "solving problem 20_152\n",
      "solving problem 20_153\n",
      "solving problem 20_154\n",
      "solving problem 20_155\n",
      "solving problem 20_156\n",
      "solving problem 20_157\n",
      "solving problem 20_158\n",
      "solving problem 20_159\n",
      "solving problem 20_160\n",
      "solving problem 20_161\n",
      "solving problem 20_162\n",
      "solving problem 20_163\n",
      "solving problem 20_164\n",
      "solving problem 20_165\n",
      "solving problem 20_166\n",
      "solving problem 20_167\n",
      "solving problem 20_168\n",
      "solving problem 20_169\n",
      "solving problem 20_170\n",
      "solving problem 20_171\n",
      "solving problem 20_172\n",
      "solving problem 20_173\n",
      "solving problem 20_174\n",
      "solving problem 20_175\n",
      "solving problem 20_176\n",
      "solving problem 20_177\n",
      "solving problem 20_178\n",
      "solving problem 20_179\n",
      "solving problem 20_180\n",
      "solving problem 20_181\n",
      "solving problem 20_182\n",
      "solving problem 20_183\n",
      "solving problem 20_184\n",
      "solving problem 20_185\n",
      "solving problem 20_186\n",
      "solving problem 20_187\n",
      "solving problem 20_188\n",
      "solving problem 20_189\n",
      "solving problem 20_190\n",
      "solving problem 20_191\n",
      "solving problem 20_192\n",
      "solving problem 20_193\n",
      "solving problem 20_194\n",
      "solving problem 20_195\n",
      "solving problem 20_196\n",
      "solving problem 20_197\n",
      "solving problem 20_198\n",
      "solving problem 20_199\n",
      "solving problem 20_200\n",
      "solving problem 20_201\n",
      "solving problem 20_202\n",
      "solving problem 20_203\n",
      "solving problem 20_204\n",
      "solving problem 20_205\n",
      "solving problem 20_206\n",
      "solving problem 20_207\n",
      "solving problem 20_208\n",
      "solving problem 20_209\n",
      "solving problem 20_210\n",
      "solving problem 20_211\n",
      "solving problem 20_212\n",
      "solving problem 20_213\n",
      "solving problem 20_214\n",
      "solving problem 20_215\n",
      "solving problem 20_216\n",
      "solving problem 20_217\n",
      "solving problem 20_218\n",
      "solving problem 20_219\n",
      "solving problem 20_220\n",
      "solving problem 20_221\n",
      "solving problem 20_222\n",
      "solving problem 20_223\n",
      "solving problem 20_224\n",
      "solving problem 20_225\n",
      "solving problem 20_226\n",
      "solving problem 20_227\n",
      "solving problem 20_228\n",
      "solving problem 20_229\n",
      "solving problem 20_230\n",
      "solving problem 20_231\n",
      "solving problem 20_232\n",
      "solving problem 20_233\n",
      "solving problem 20_234\n",
      "solving problem 20_235\n",
      "solving problem 20_236\n",
      "solving problem 20_237\n",
      "solving problem 20_238\n",
      "solving problem 20_239\n",
      "solving problem 20_240\n",
      "solving problem 20_241\n",
      "solving problem 20_242\n",
      "solving problem 20_243\n",
      "solving problem 20_244\n",
      "solving problem 20_245\n",
      "solving problem 20_246\n",
      "solving problem 20_247\n",
      "solving problem 20_248\n",
      "solving problem 20_249\n",
      "solving problem 20_250\n",
      "solving problem 20_251\n",
      "solving problem 20_252\n",
      "solving problem 20_253\n",
      "solving problem 20_254\n",
      "solving problem 20_255\n",
      "solving problem 20_256\n",
      "solving problem 20_257\n",
      "solving problem 20_258\n",
      "solving problem 20_259\n",
      "solving problem 20_260\n",
      "solving problem 20_261\n",
      "solving problem 20_262\n",
      "solving problem 20_263\n",
      "solving problem 20_264\n",
      "solving problem 20_265\n",
      "solving problem 20_266\n",
      "solving problem 20_267\n",
      "solving problem 20_268\n",
      "solving problem 20_269\n",
      "solving problem 20_270\n",
      "solving problem 20_271\n",
      "solving problem 20_272\n",
      "solving problem 20_273\n",
      "solving problem 20_274\n",
      "solving problem 20_275\n",
      "solving problem 20_276\n",
      "solving problem 20_277\n",
      "solving problem 20_278\n",
      "solving problem 20_279\n",
      "solving problem 20_280\n",
      "solving problem 20_281\n",
      "solving problem 20_282\n",
      "solving problem 20_283\n",
      "solving problem 20_284\n",
      "solving problem 20_285\n",
      "solving problem 20_286\n",
      "solving problem 20_287\n",
      "solving problem 20_288\n",
      "solving problem 20_289\n",
      "solving problem 20_290\n",
      "solving problem 20_291\n",
      "solving problem 20_292\n",
      "solving problem 20_293\n",
      "solving problem 20_294\n",
      "solving problem 20_295\n",
      "solving problem 20_296\n",
      "solving problem 20_297\n",
      "solving problem 20_298\n",
      "solving problem 20_299\n",
      "solving problem 20_300\n",
      "solving problem 20_301\n",
      "solving problem 20_302\n",
      "solving problem 20_303\n",
      "solving problem 20_304\n",
      "solving problem 20_305\n",
      "solving problem 20_306\n",
      "solving problem 20_307\n",
      "solving problem 20_308\n",
      "solving problem 20_309\n",
      "solving problem 20_310\n",
      "solving problem 20_311\n",
      "solving problem 20_312\n",
      "solving problem 20_313\n",
      "solving problem 20_314\n",
      "solving problem 20_315\n",
      "solving problem 20_316\n",
      "solving problem 20_317\n",
      "solving problem 20_318\n",
      "solving problem 20_319\n",
      "solving problem 20_320\n",
      "solving problem 20_321\n",
      "solving problem 20_322\n",
      "solving problem 20_323\n",
      "solving problem 20_324\n",
      "solving problem 20_325\n",
      "solving problem 20_326\n",
      "solving problem 20_327\n",
      "solving problem 20_328\n",
      "solving problem 20_329\n",
      "solving problem 20_330\n",
      "solving problem 20_331\n",
      "solving problem 20_332\n",
      "solving problem 20_333\n",
      "solving problem 20_334\n",
      "solving problem 20_335\n",
      "solving problem 20_336\n",
      "solving problem 20_337\n",
      "solving problem 20_338\n",
      "solving problem 20_339\n",
      "solving problem 20_340\n",
      "solving problem 20_341\n",
      "solving problem 20_342\n",
      "solving problem 20_343\n",
      "solving problem 20_344\n",
      "solving problem 20_345\n",
      "solving problem 20_346\n",
      "solving problem 20_347\n",
      "solving problem 20_348\n",
      "solving problem 20_349\n",
      "solving problem 20_350\n",
      "solving problem 20_351\n",
      "solving problem 20_352\n",
      "solving problem 20_353\n",
      "solving problem 20_354\n",
      "solving problem 20_355\n",
      "solving problem 20_356\n",
      "solving problem 20_357\n",
      "solving problem 20_358\n",
      "solving problem 20_359\n",
      "solving problem 20_360\n",
      "solving problem 20_361\n",
      "solving problem 20_362\n",
      "solving problem 20_363\n",
      "solving problem 20_364\n",
      "solving problem 20_365\n",
      "solving problem 20_366\n",
      "solving problem 20_367\n",
      "solving problem 20_368\n",
      "solving problem 20_369\n",
      "solving problem 20_370\n",
      "solving problem 20_371\n",
      "solving problem 20_372\n",
      "solving problem 20_373\n",
      "solving problem 20_374\n",
      "solving problem 20_375\n",
      "solving problem 20_376\n",
      "solving problem 20_377\n",
      "solving problem 20_378\n",
      "solving problem 20_379\n",
      "solving problem 20_380\n",
      "solving problem 20_381\n",
      "solving problem 20_382\n",
      "solving problem 20_383\n",
      "solving problem 20_384\n",
      "solving problem 20_385\n",
      "solving problem 20_386\n",
      "solving problem 20_387\n",
      "solving problem 20_388\n",
      "solving problem 20_389\n",
      "solving problem 20_390\n",
      "solving problem 20_391\n",
      "solving problem 20_392\n",
      "solving problem 20_393\n",
      "solving problem 20_394\n",
      "solving problem 20_395\n",
      "solving problem 20_396\n",
      "solving problem 20_397\n",
      "solving problem 20_398\n",
      "solving problem 20_399\n",
      "solving problem 20_400\n",
      "solving problem 20_401\n",
      "solving problem 20_402\n",
      "solving problem 20_403\n",
      "solving problem 20_404\n",
      "solving problem 20_405\n",
      "solving problem 20_406\n",
      "solving problem 20_407\n",
      "solving problem 20_408\n",
      "solving problem 20_409\n",
      "solving problem 20_410\n",
      "solving problem 20_411\n",
      "solving problem 20_412\n",
      "solving problem 20_413\n",
      "solving problem 20_414\n",
      "solving problem 20_415\n",
      "solving problem 20_416\n",
      "solving problem 20_417\n",
      "solving problem 20_418\n",
      "solving problem 20_419\n",
      "solving problem 20_420\n",
      "solving problem 20_421\n",
      "solving problem 20_422\n",
      "solving problem 20_423\n",
      "solving problem 20_424\n",
      "solving problem 20_425\n",
      "solving problem 20_426\n",
      "solving problem 20_427\n",
      "solving problem 20_428\n",
      "solving problem 20_429\n",
      "solving problem 20_430\n",
      "solving problem 20_431\n",
      "solving problem 20_432\n",
      "solving problem 20_433\n",
      "solving problem 20_434\n",
      "solving problem 20_435\n",
      "solving problem 20_436\n",
      "solving problem 20_437\n",
      "solving problem 20_438\n",
      "solving problem 20_439\n",
      "solving problem 20_440\n",
      "solving problem 20_441\n",
      "solving problem 20_442\n",
      "solving problem 20_443\n",
      "solving problem 20_444\n",
      "solving problem 20_445\n",
      "solving problem 20_446\n",
      "solving problem 20_447\n",
      "solving problem 20_448\n",
      "solving problem 20_449\n",
      "solving problem 20_450\n",
      "solving problem 20_451\n",
      "solving problem 20_452\n",
      "solving problem 20_453\n",
      "solving problem 20_454\n",
      "solving problem 20_455\n",
      "solving problem 20_456\n",
      "solving problem 20_457\n",
      "solving problem 20_458\n",
      "solving problem 20_459\n",
      "solving problem 20_460\n",
      "solving problem 20_461\n",
      "solving problem 20_462\n",
      "solving problem 20_463\n",
      "solving problem 20_464\n",
      "solving problem 20_465\n",
      "solving problem 20_466\n",
      "solving problem 20_467\n",
      "solving problem 20_468\n",
      "solving problem 20_469\n",
      "solving problem 20_470\n",
      "solving problem 20_471\n",
      "solving problem 20_472\n",
      "solving problem 20_473\n",
      "solving problem 20_474\n",
      "solving problem 20_475\n",
      "solving problem 20_476\n",
      "solving problem 20_477\n",
      "solving problem 20_478\n",
      "solving problem 20_479\n",
      "solving problem 20_480\n",
      "solving problem 20_481\n",
      "solving problem 20_482\n",
      "solving problem 20_483\n",
      "solving problem 20_484\n",
      "solving problem 20_485\n",
      "solving problem 20_486\n",
      "solving problem 20_487\n",
      "solving problem 20_488\n",
      "solving problem 20_489\n",
      "solving problem 20_490\n",
      "solving problem 20_491\n",
      "solving problem 20_492\n",
      "solving problem 20_493\n",
      "solving problem 20_494\n",
      "solving problem 20_495\n",
      "solving problem 20_496\n",
      "solving problem 20_497\n",
      "solving problem 20_498\n",
      "solving problem 20_499\n",
      "solving problem 20_500\n",
      "solving problem 20_501\n",
      "solving problem 20_502\n",
      "solving problem 20_503\n",
      "solving problem 20_504\n",
      "solving problem 20_505\n",
      "solving problem 20_506\n",
      "solving problem 20_507\n",
      "solving problem 20_508\n",
      "solving problem 20_509\n",
      "solving problem 20_510\n",
      "solving problem 20_511\n",
      "solving problem 20_512\n",
      "solving problem 20_513\n",
      "solving problem 20_514\n",
      "solving problem 20_515\n",
      "solving problem 20_516\n",
      "solving problem 20_517\n",
      "solving problem 20_518\n",
      "solving problem 20_519\n",
      "solving problem 20_520\n",
      "solving problem 20_521\n",
      "solving problem 20_522\n",
      "solving problem 20_523\n",
      "solving problem 20_524\n",
      "solving problem 20_525\n"
     ]
    }
   ],
   "source": [
    "solution_outputs = get_ALBP_solutions(instance_list, ALBP_solver = immediate_update_first_fit, score_function = positional_weight, max_stations = 60)\n",
    "solution_outputs = pd.DataFrame(solution_outputs)\n",
    "solution_outputs['name'] = solution_outputs['name'].apply(lambda x: int(x.split(\"_\")[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name  no_tasks  order_strength  cycle_time  no_stations  \\\n",
      "1       1        20           0.268        1000            3   \n",
      "2       2        20           0.300        1000            3   \n",
      "3       3        20           0.300        1000            3   \n",
      "4       4        20           0.289        1000            3   \n",
      "5       5        20           0.289        1000            3   \n",
      "..    ...       ...             ...         ...          ...   \n",
      "521   521        20           0.263        1000            3   \n",
      "522   522        20           0.300        1000            4   \n",
      "523   523        20           0.279        1000            3   \n",
      "524   524        20           0.263        1000            3   \n",
      "525   525        20           0.300        1000            3   \n",
      "\n",
      "                                       task_assignment  \n",
      "1    {'1': 1, '4': 1, '6': 1, '8': 1, '2': 1, '10':...  \n",
      "2    {'1': 1, '4': 1, '2': 1, '6': 1, '5': 1, '7': ...  \n",
      "3    {'1': 1, '3': 1, '7': 1, '6': 1, '2': 1, '9': ...  \n",
      "4    {'1': 1, '5': 1, '7': 1, '6': 1, '3': 1, '2': ...  \n",
      "5    {'1': 1, '3': 1, '7': 1, '4': 1, '8': 1, '6': ...  \n",
      "..                                                 ...  \n",
      "521  {'1': 1, '4': 1, '3': 1, '2': 1, '8': 1, '12':...  \n",
      "522  {'1': 1, '4': 1, '3': 1, '2': 1, '6': 1, '5': ...  \n",
      "523  {'1': 1, '2': 1, '3': 1, '4': 1, '8': 1, '6': ...  \n",
      "524  {'1': 1, '4': 1, '3': 1, '2': 1, '7': 1, '6': ...  \n",
      "525  {'1': 1, '5': 1, '6': 1, '3': 1, '2': 1, '11':...  \n",
      "\n",
      "[525 rows x 6 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>no_tasks</th>\n",
       "      <th>order_strength</th>\n",
       "      <th>cycle_time</th>\n",
       "      <th>no_stations</th>\n",
       "      <th>task_assignment</th>\n",
       "      <th>instance_no</th>\n",
       "      <th>&lt;Filename&gt;</th>\n",
       "      <th>&lt;Graph structure&gt;</th>\n",
       "      <th>&lt;Desired OS&gt;</th>\n",
       "      <th>&lt;Times distribution&gt;</th>\n",
       "      <th>trickiness_category</th>\n",
       "      <th>optimal_no_stations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.268</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>{'1': 1, '4': 1, '6': 1, '8': 1, '2': 1, '10':...</td>\n",
       "      <td>1</td>\n",
       "      <td>instance_n=20_1</td>\n",
       "      <td>BN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>peak at the bottom</td>\n",
       "      <td>less tricky</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>{'1': 1, '4': 1, '2': 1, '6': 1, '5': 1, '7': ...</td>\n",
       "      <td>2</td>\n",
       "      <td>instance_n=20_2</td>\n",
       "      <td>BN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>peak at the bottom</td>\n",
       "      <td>less tricky</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>{'1': 1, '3': 1, '7': 1, '6': 1, '2': 1, '9': ...</td>\n",
       "      <td>3</td>\n",
       "      <td>instance_n=20_3</td>\n",
       "      <td>BN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>peak at the bottom</td>\n",
       "      <td>less tricky</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.289</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>{'1': 1, '5': 1, '7': 1, '6': 1, '3': 1, '2': ...</td>\n",
       "      <td>4</td>\n",
       "      <td>instance_n=20_4</td>\n",
       "      <td>BN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>peak at the bottom</td>\n",
       "      <td>less tricky</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.289</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>{'1': 1, '3': 1, '7': 1, '4': 1, '8': 1, '6': ...</td>\n",
       "      <td>5</td>\n",
       "      <td>instance_n=20_5</td>\n",
       "      <td>BN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>peak at the bottom</td>\n",
       "      <td>less tricky</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>521</td>\n",
       "      <td>20</td>\n",
       "      <td>0.263</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>{'1': 1, '4': 1, '3': 1, '2': 1, '8': 1, '12':...</td>\n",
       "      <td>521</td>\n",
       "      <td>instance_n=20_521</td>\n",
       "      <td>BN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>peak at the bottom</td>\n",
       "      <td>less tricky</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>522</td>\n",
       "      <td>20</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>{'1': 1, '4': 1, '3': 1, '2': 1, '6': 1, '5': ...</td>\n",
       "      <td>522</td>\n",
       "      <td>instance_n=20_522</td>\n",
       "      <td>BN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>peak at the bottom</td>\n",
       "      <td>tricky</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>523</td>\n",
       "      <td>20</td>\n",
       "      <td>0.279</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>{'1': 1, '2': 1, '3': 1, '4': 1, '8': 1, '6': ...</td>\n",
       "      <td>523</td>\n",
       "      <td>instance_n=20_523</td>\n",
       "      <td>BN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>peak at the bottom</td>\n",
       "      <td>less tricky</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>524</td>\n",
       "      <td>20</td>\n",
       "      <td>0.263</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>{'1': 1, '4': 1, '3': 1, '2': 1, '7': 1, '6': ...</td>\n",
       "      <td>524</td>\n",
       "      <td>instance_n=20_524</td>\n",
       "      <td>BN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>peak at the bottom</td>\n",
       "      <td>less tricky</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>525</td>\n",
       "      <td>20</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>{'1': 1, '5': 1, '6': 1, '3': 1, '2': 1, '11':...</td>\n",
       "      <td>525</td>\n",
       "      <td>instance_n=20_525</td>\n",
       "      <td>BN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>peak at the bottom</td>\n",
       "      <td>less tricky</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>521 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  no_tasks  order_strength  cycle_time  no_stations  \\\n",
       "0       1        20           0.268        1000            3   \n",
       "1       2        20           0.300        1000            3   \n",
       "2       3        20           0.300        1000            3   \n",
       "3       4        20           0.289        1000            3   \n",
       "4       5        20           0.289        1000            3   \n",
       "..    ...       ...             ...         ...          ...   \n",
       "520   521        20           0.263        1000            3   \n",
       "521   522        20           0.300        1000            4   \n",
       "522   523        20           0.279        1000            3   \n",
       "523   524        20           0.263        1000            3   \n",
       "524   525        20           0.300        1000            3   \n",
       "\n",
       "                                       task_assignment  instance_no  \\\n",
       "0    {'1': 1, '4': 1, '6': 1, '8': 1, '2': 1, '10':...            1   \n",
       "1    {'1': 1, '4': 1, '2': 1, '6': 1, '5': 1, '7': ...            2   \n",
       "2    {'1': 1, '3': 1, '7': 1, '6': 1, '2': 1, '9': ...            3   \n",
       "3    {'1': 1, '5': 1, '7': 1, '6': 1, '3': 1, '2': ...            4   \n",
       "4    {'1': 1, '3': 1, '7': 1, '4': 1, '8': 1, '6': ...            5   \n",
       "..                                                 ...          ...   \n",
       "520  {'1': 1, '4': 1, '3': 1, '2': 1, '8': 1, '12':...          521   \n",
       "521  {'1': 1, '4': 1, '3': 1, '2': 1, '6': 1, '5': ...          522   \n",
       "522  {'1': 1, '2': 1, '3': 1, '4': 1, '8': 1, '6': ...          523   \n",
       "523  {'1': 1, '4': 1, '3': 1, '2': 1, '7': 1, '6': ...          524   \n",
       "524  {'1': 1, '5': 1, '6': 1, '3': 1, '2': 1, '11':...          525   \n",
       "\n",
       "        <Filename>     <Graph structure>  <Desired OS>  <Times distribution>  \\\n",
       "0      instance_n=20_1                BN            0.2   peak at the bottom   \n",
       "1      instance_n=20_2                BN            0.2   peak at the bottom   \n",
       "2      instance_n=20_3                BN            0.2   peak at the bottom   \n",
       "3      instance_n=20_4                BN            0.2   peak at the bottom   \n",
       "4      instance_n=20_5                BN            0.2   peak at the bottom   \n",
       "..                 ...               ...            ...                  ...   \n",
       "520  instance_n=20_521                BN            0.2   peak at the bottom   \n",
       "521  instance_n=20_522                BN            0.2   peak at the bottom   \n",
       "522  instance_n=20_523                BN            0.2   peak at the bottom   \n",
       "523  instance_n=20_524                BN            0.2   peak at the bottom   \n",
       "524  instance_n=20_525                BN            0.2   peak at the bottom   \n",
       "\n",
       "    trickiness_category optimal_no_stations  \n",
       "0           less tricky                   3  \n",
       "1           less tricky                   3  \n",
       "2           less tricky                   3  \n",
       "3           less tricky                   3  \n",
       "4           less tricky                   3  \n",
       "..                  ...                 ...  \n",
       "520         less tricky                   3  \n",
       "521              tricky                   3  \n",
       "522         less tricky                   3  \n",
       "523         less tricky                   3  \n",
       "524         less tricky                   3  \n",
       "\n",
       "[521 rows x 13 columns]"
      ]
     },
     "execution_count": 950,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution_outputs.index += 1\n",
    "solutions_details =  pd.read_excel('SALBP_benchmark/Details of the small data set (n=20).xlsx', header=[1])\n",
    "solutions_details.columns\n",
    "heuristic_eval = solution_outputs.merge(solutions_details, left_index=True, right_index=True)\n",
    "#solution_outputs\n",
    "solutions_details.index += 1\n",
    "print(solution_outputs)\n",
    "#solutions_details\n",
    "heuristic_eval = solution_outputs.merge(solutions_details.loc[ :, ('<No>'):('<No of stations in optimum>')], left_on='name',right_on='<No>')\n",
    "heuristic_eval = heuristic_eval.rename(columns={'<No>':'instance_no', '<No of stations in optimum>':'optimal_no_stations', '<Trickiness category>': 'trickiness_category'})\n",
    "#filters out instances where the problem type is open\n",
    "heuristic_eval = heuristic_eval[heuristic_eval['trickiness_category'] != 'open (not known yet)']\n",
    "#filters out non-numeric values for 'trickiness_category'\n",
    "\n",
    "\n",
    "heuristic_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>no_tasks</th>\n",
       "      <th>order_strength</th>\n",
       "      <th>cycle_time</th>\n",
       "      <th>no_stations</th>\n",
       "      <th>task_assignment</th>\n",
       "      <th>instance_no</th>\n",
       "      <th>&lt;Filename&gt;</th>\n",
       "      <th>&lt;Graph structure&gt;</th>\n",
       "      <th>&lt;Desired OS&gt;</th>\n",
       "      <th>&lt;Times distribution&gt;</th>\n",
       "      <th>trickiness_category</th>\n",
       "      <th>optimal_no_stations</th>\n",
       "      <th>is_optimal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>0.289</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>{'1': 1, '5': 1, '3': 1, '6': 1, '2': 1, '11':...</td>\n",
       "      <td>9</td>\n",
       "      <td>instance_n=20_9</td>\n",
       "      <td>BN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>peak at the bottom</td>\n",
       "      <td>tricky</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>{'1': 1, '2': 1, '4': 1, '3': 1, '7': 2, '5': ...</td>\n",
       "      <td>12</td>\n",
       "      <td>instance_n=20_12</td>\n",
       "      <td>BN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>peak at the bottom</td>\n",
       "      <td>tricky</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>0.263</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>{'1': 1, '4': 1, '3': 1, '2': 1, '7': 1, '6': ...</td>\n",
       "      <td>14</td>\n",
       "      <td>instance_n=20_14</td>\n",
       "      <td>BN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>peak at the bottom</td>\n",
       "      <td>very tricky</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>0.295</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>{'1': 1, '4': 1, '7': 1, '6': 1, '9': 2, '8': ...</td>\n",
       "      <td>15</td>\n",
       "      <td>instance_n=20_15</td>\n",
       "      <td>BN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>peak at the bottom</td>\n",
       "      <td>very tricky</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>0.295</td>\n",
       "      <td>1000</td>\n",
       "      <td>11</td>\n",
       "      <td>{'1': 1, '3': 1, '8': 2, '2': 3, '7': 4, '10':...</td>\n",
       "      <td>17</td>\n",
       "      <td>instance_n=20_17</td>\n",
       "      <td>BN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>peak in the middle</td>\n",
       "      <td>extremely tricky</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>510</td>\n",
       "      <td>20</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>{'1': 1, '2': 1, '5': 1, '3': 2, '4': 1, '7': ...</td>\n",
       "      <td>510</td>\n",
       "      <td>instance_n=20_510</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>0.9</td>\n",
       "      <td>bimodal</td>\n",
       "      <td>less tricky</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>512</td>\n",
       "      <td>20</td>\n",
       "      <td>0.805</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>{'1': 1, '2': 2, '4': 1, '3': 2, '5': 1, '7': ...</td>\n",
       "      <td>512</td>\n",
       "      <td>instance_n=20_512</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>0.9</td>\n",
       "      <td>bimodal</td>\n",
       "      <td>tricky</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>517</td>\n",
       "      <td>20</td>\n",
       "      <td>0.295</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>{'1': 1, '3': 1, '8': 1, '2': 1, '9': 1, '4': ...</td>\n",
       "      <td>517</td>\n",
       "      <td>instance_n=20_517</td>\n",
       "      <td>BN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>peak at the bottom</td>\n",
       "      <td>tricky</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>519</td>\n",
       "      <td>20</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>{'1': 1, '4': 1, '9': 1, '5': 1, '7': 1, '6': ...</td>\n",
       "      <td>519</td>\n",
       "      <td>instance_n=20_519</td>\n",
       "      <td>BN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>peak at the bottom</td>\n",
       "      <td>tricky</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>522</td>\n",
       "      <td>20</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>{'1': 1, '4': 1, '3': 1, '2': 1, '6': 1, '5': ...</td>\n",
       "      <td>522</td>\n",
       "      <td>instance_n=20_522</td>\n",
       "      <td>BN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>peak at the bottom</td>\n",
       "      <td>tricky</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  no_tasks  order_strength  cycle_time  no_stations  \\\n",
       "8       9        20           0.289        1000            4   \n",
       "11     12        20           0.300        1000            4   \n",
       "13     14        20           0.263        1000            4   \n",
       "14     15        20           0.295        1000            4   \n",
       "16     17        20           0.295        1000           11   \n",
       "..    ...       ...             ...         ...          ...   \n",
       "509   510        20           0.816        1000            6   \n",
       "511   512        20           0.805        1000            6   \n",
       "516   517        20           0.295        1000            4   \n",
       "518   519        20           0.300        1000            4   \n",
       "521   522        20           0.300        1000            4   \n",
       "\n",
       "                                       task_assignment  instance_no  \\\n",
       "8    {'1': 1, '5': 1, '3': 1, '6': 1, '2': 1, '11':...            9   \n",
       "11   {'1': 1, '2': 1, '4': 1, '3': 1, '7': 2, '5': ...           12   \n",
       "13   {'1': 1, '4': 1, '3': 1, '2': 1, '7': 1, '6': ...           14   \n",
       "14   {'1': 1, '4': 1, '7': 1, '6': 1, '9': 2, '8': ...           15   \n",
       "16   {'1': 1, '3': 1, '8': 2, '2': 3, '7': 4, '10':...           17   \n",
       "..                                                 ...          ...   \n",
       "509  {'1': 1, '2': 1, '5': 1, '3': 2, '4': 1, '7': ...          510   \n",
       "511  {'1': 1, '2': 2, '4': 1, '3': 2, '5': 1, '7': ...          512   \n",
       "516  {'1': 1, '3': 1, '8': 1, '2': 1, '9': 1, '4': ...          517   \n",
       "518  {'1': 1, '4': 1, '9': 1, '5': 1, '7': 1, '6': ...          519   \n",
       "521  {'1': 1, '4': 1, '3': 1, '2': 1, '6': 1, '5': ...          522   \n",
       "\n",
       "        <Filename>     <Graph structure>  <Desired OS>  <Times distribution>  \\\n",
       "8      instance_n=20_9                BN            0.2   peak at the bottom   \n",
       "11    instance_n=20_12                BN            0.2   peak at the bottom   \n",
       "13    instance_n=20_14                BN            0.2   peak at the bottom   \n",
       "14    instance_n=20_15                BN            0.2   peak at the bottom   \n",
       "16    instance_n=20_17                BN            0.2   peak in the middle   \n",
       "..                 ...               ...            ...                  ...   \n",
       "509  instance_n=20_510             MIXED            0.9              bimodal   \n",
       "511  instance_n=20_512             MIXED            0.9              bimodal   \n",
       "516  instance_n=20_517                BN            0.2   peak at the bottom   \n",
       "518  instance_n=20_519                BN            0.2   peak at the bottom   \n",
       "521  instance_n=20_522                BN            0.2   peak at the bottom   \n",
       "\n",
       "    trickiness_category optimal_no_stations  is_optimal  \n",
       "8                tricky                   3       False  \n",
       "11               tricky                   3       False  \n",
       "13          very tricky                   3       False  \n",
       "14          very tricky                   3       False  \n",
       "16     extremely tricky                  10       False  \n",
       "..                  ...                 ...         ...  \n",
       "509         less tricky                   5       False  \n",
       "511              tricky                   5       False  \n",
       "516              tricky                   3       False  \n",
       "518              tricky                   3       False  \n",
       "521              tricky                   3       False  \n",
       "\n",
       "[163 rows x 14 columns]"
      ]
     },
     "execution_count": 951,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heuristic_eval['is_optimal'] = heuristic_eval['no_stations'] == heuristic_eval['optimal_no_stations']\n",
    "whoopsy = heuristic_eval[heuristic_eval['no_stations'].astype(int) > heuristic_eval['optimal_no_stations'].astype(int)]\n",
    "whoopsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 1,\n",
       " '5': 1,\n",
       " '3': 1,\n",
       " '6': 1,\n",
       " '2': 1,\n",
       " '7': 1,\n",
       " '12': 1,\n",
       " '4': 1,\n",
       " '11': 2,\n",
       " '14': 2,\n",
       " '15': 2,\n",
       " '18': 2,\n",
       " '10': 2,\n",
       " '16': 3,\n",
       " '8': 3,\n",
       " '17': 3,\n",
       " '13': 3,\n",
       " '19': 3,\n",
       " '9': 3,\n",
       " '20': 4}"
      ]
     },
     "execution_count": 952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(sorted(whoopsy.iloc[0]['task_assignment'].items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_precedence_matrix(instance):\n",
    "    precedence_matrix = np.zeros((len(instance['task_times'].keys()), len(instance['task_times'].keys())))\n",
    "    for precedence in instance['precedence_relations']:\n",
    "        precedence_matrix[int(precedence[0]) - 1][int(precedence[1]) - 1] = 1\n",
    "    return precedence_matrix\n",
    "\n",
    "\n",
    "def code_search(best_code_number, best_time, total_time, previous_code_number, assignment_dict, instance,  precedence_matrix,  current_station = 1, depth = 0, right_of = 0):\n",
    "    takt_time = instance['cycle_time']\n",
    "    #returns if all elements of code number are less than zero\n",
    "    for task in np.where(previous_code_number== 0)[0]:\n",
    "        branch_code_number = previous_code_number.copy()\n",
    "        node_time = total_time\n",
    "        print('previous_code_number', branch_code_number)\n",
    "        print('task', task, 'depth', depth)\n",
    "        print('total_time', node_time)\n",
    "        print(instance['task_times'][str(task+1)])\n",
    "        if task < right_of:\n",
    "            continue\n",
    "        if node_time + instance['task_times'][str(task+1)]> takt_time:\n",
    "            continue\n",
    "        else:\n",
    "            #print('code_number before', previous_code_number)\n",
    "            trial_code_number = branch_code_number.copy()\n",
    "            trial_assignment_dict = assignment_dict.copy()\n",
    "            trial_assignment_dict[str(task+1)] = str(current_station)\n",
    "            trial_code_number -= precedence_matrix[task] \n",
    "            trial_code_number[task] = -1\n",
    "            node_time += instance['task_times'][str(task+1)]\n",
    "            code_number, node_time, new_assignment_dict = code_search(best_code_number, best_time, total_time, trial_code_number, trial_assignment_dict, instance, precedence_matrix, current_station, depth = depth+1, right_of=task)\n",
    "            if node_time > best_time:\n",
    "                print('new best time', total_time)\n",
    "                print('new best code number', code_number)\n",
    "                print('depth', depth)\n",
    "                best_time = node_time\n",
    "                best_code_number = code_number.copy()\n",
    "                assignment_dict = new_assignment_dict.copy()\n",
    "\n",
    "    if np.all(best_code_number < 0):\n",
    "        return best_code_number, total_time, assignment_dict       \n",
    "            \n",
    "    if depth == 0:\n",
    "        print('next_station!')\n",
    "        print(best_code_number)\n",
    "        print(assignment_dict)\n",
    "        previous_code_number, total_time, assignment_dict = code_search(best_code_number, 0, 0, best_code_number, trial_assignment_dict, instance, precedence_matrix, current_station+ 1, depth=0)\n",
    "    print('returning this shit', previous_code_number, total_time, assignment_dict, depth)\n",
    "    return previous_code_number, total_time, assignment_dict\n",
    "\n",
    "def modified_hoffman_heuristic(instance, max_stations = 20):\n",
    "    ''''Modified hoffman heuristic from A Branch, Bound, and Remember Algorithm forthe Simple Assembly Line Balancing Problem  Sewell, Jacobson'''\n",
    "\n",
    "    precedence_matrix = construct_precedence_matrix(instance)\n",
    "    #initializes the station capacities\n",
    "    station_capacities = [instance['cycle_time'] for i in range(0, max_stations)]\n",
    "    #create first code number\n",
    "    code_number = precedence_matrix.sum(axis=0)\n",
    "    #search for best assignments\n",
    "    #station_assignments = code_search(code_number, precedence_matrix, instance)\n",
    "    assignment_dict = {}\n",
    "    station_assignments = code_search(code_number, 0,0, code_number, assignment_dict, instance, precedence_matrix)\n",
    "    print(station_assignments)\n",
    "    return station_assignments\n",
    "\n",
    "#instance = parse_alb('SALBP_benchmark/debugging_ds/instance_n=4_1.alb')\n",
    "#print(instance)\n",
    "#modified_hoffman_heuristic(instance)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = parse_alb('SALBP_benchmark/small data set_n=20/instance_n=20_489.alb')\n",
    "p_graph = nx.DiGraph()\n",
    "p_graph.add_nodes_from([(key, {'task_time':value}) for key, value in instance[\"task_times\"].items()])\n",
    "p_graph.add_edges_from(instance['precedence_relations'], color = 'r')\n",
    "\n",
    "nx.write_gexf(p_graph, 'test_graph.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx.draw(p_graph, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [1, 2, 3]])"
      ]
     },
     "execution_count": 956,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "a = np.expand_dims(a, 0)\n",
    "np.vstack((a,a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = parse_alb('SALBP_benchmark/small data set_n=20/instance_n=20_489.alb')\n",
    "instance['precedence_relations'] = [[int(precedence[0]) - 1, int(precedence[1]) - 1] for precedence in instance['precedence_relations']]\n",
    "edge_index = torch.tensor(instance['precedence_relations'], dtype=torch.long)\n",
    "x = torch.tensor([[instance['task_times'][str(task)],1] for task in instance['task_times'].keys()], dtype=torch.float)\n",
    "data = Data(x=x, edge_index=edge_index.t().contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[442.,   1.],\n",
       "        [560.,   1.],\n",
       "        [403.,   1.],\n",
       "        [462.,   1.],\n",
       "        [415.,   1.],\n",
       "        [461.,   1.],\n",
       "        [372.,   1.],\n",
       "        [762.,   1.],\n",
       "        [664.,   1.],\n",
       "        [706.,   1.],\n",
       "        [328.,   1.],\n",
       "        [304.,   1.],\n",
       "        [740.,   1.],\n",
       "        [621.,   1.],\n",
       "        [635.,   1.],\n",
       "        [332.,   1.],\n",
       "        [399.,   1.],\n",
       "        [544.,   1.],\n",
       "        [561.,   1.],\n",
       "        [350.,   1.]])"
      ]
     },
     "execution_count": 959,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 960,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 961,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 962,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 963,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.is_directed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[442.,   1.],\n",
       "        [560.,   1.],\n",
       "        [403.,   1.],\n",
       "        [462.,   1.],\n",
       "        [415.,   1.],\n",
       "        [461.,   1.],\n",
       "        [372.,   1.],\n",
       "        [762.,   1.],\n",
       "        [664.,   1.],\n",
       "        [706.,   1.],\n",
       "        [328.,   1.],\n",
       "        [304.,   1.],\n",
       "        [740.,   1.],\n",
       "        [621.,   1.],\n",
       "        [635.,   1.],\n",
       "        [332.,   1.],\n",
       "        [399.,   1.],\n",
       "        [544.,   1.],\n",
       "        [561.,   1.],\n",
       "        [350.,   1.]])"
      ]
     },
     "execution_count": 964,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(2, 16)\n",
    "        self.conv2 = GCNConv(16, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        print(x)\n",
    "        print(edge_index)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so it looks like the most straightforward way of going about this is to do a policy based reinforcement learning technique. Our actions would be the selection of an action to perform (this gets added to a priority list). The episode ends when all tasks are assigned to the priority list. Reward is (-number of stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('mps')\n",
    "model = GCN().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_assignment( tasks_dict, instance, assignments = []):\n",
    "    '''Copies over priority list from another priority list'''\n",
    "    for task in tasks_dict:\n",
    "        tasks_dict['score'] = len(tasks_dict) - assignments.index(int(task)-1)\n",
    "\n",
    "\n",
    "\n",
    "#enivorment for reinforcement learning of priority rules\n",
    "class Env:\n",
    "    def __init__(self, instance) -> None:\n",
    "        precedence_relations = [[int(precedence[0]) - 1, int(precedence[1]) - 1] for precedence in instance['precedence_relations']]\n",
    "        self.edge_index = torch.tensor(precedence_relations, dtype=torch.long)\n",
    "        self.x = torch.tensor([[instance['task_times'][str(task)],1] for task in instance['task_times'].keys()], dtype=torch.float)\n",
    "        self.data = Data(x=x, edge_index=edge_index.t().contiguous())\n",
    "        self.action_mask = torch.ones((x.shape[0]))\n",
    "        self.priority_list = []\n",
    "        self.instance = instance\n",
    "\n",
    "    \n",
    "    def update_state(self, task_index):\n",
    "        '''Updates the state of the priority list and graph, \n",
    "        and returns reward if at the end of the episode'''\n",
    "        #update the mask that bans certain actions\n",
    "        self.action_mask[task_index] = 0\n",
    "        #Update the network to reflect that a task has been listed\n",
    "        print('self.x', self.x)\n",
    "        print('self.x shape', self.x.shape)\n",
    "        print('task index', task_index)\n",
    "        print('self.x[task_index]', self.x[task_index])\n",
    "        print('action mask', self.action_mask)\n",
    "\n",
    "        self.x[task_index, 1] = 0\n",
    "        self.priority_list.append(task_index)\n",
    "        if torch.sum(self.action_mask)== 0:\n",
    "            no_stations, task_assignment = immediate_update_first_fit(self.instance, import_assignment, max_stations=30, assignments_dict=self.priority_list)\n",
    "            return -no_stations, True\n",
    "        return 0, False\n",
    "    \n",
    "    def reset(self):\n",
    "        self.action_mask = torch.ones((x.shape[0]))\n",
    "        self.priority_list = []\n",
    "        self.x = torch.tensor([[self.instance['task_times'][str(task)],1] for task in self.instance['task_times'].keys()], dtype=torch.float)\n",
    "        self.data = Data(x=x, edge_index=self.edge_index.t().contiguous())\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(Env, model, device = 'cpu'):\n",
    "    '''Gets the action from the model and returns the action and the log probability of the action'''\n",
    "    print('Env.data',Env.data)\n",
    "    action_probs = model(Env.data.to(device)).squeeze()\n",
    "    print('action probs shape',action_probs.shape)\n",
    "    print('action probs',action_probs)\n",
    "\n",
    "    print('action mask',Env.action_mask)\n",
    "    print('action mask shape',Env.action_mask.shape)\n",
    "    action_probs = action_probs * Env.action_mask.to(device)\n",
    "    print('action probs after mask shape',action_probs.shape)\n",
    "    print('action probs after mask',action_probs)\n",
    "    #action_probs = F.softmax(action_probs, dim=0)\n",
    "    #print('action probs shape',action_probs.shape)\n",
    "    #print('action probs',action_probs)\n",
    "    action = torch.multinomial(action_probs, 1)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "EpisodeStep = namedtuple('EpisodeStep', field_names=['observation', 'action'])\n",
    "Episode = namedtuple('Episode', field_names=['reward', 'steps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env.data Data(x=[20, 2], edge_index=[2, 32])\n",
      "tensor([[442.,   1.],\n",
      "        [560.,   1.],\n",
      "        [403.,   1.],\n",
      "        [462.,   1.],\n",
      "        [415.,   1.],\n",
      "        [461.,   1.],\n",
      "        [372.,   1.],\n",
      "        [762.,   1.],\n",
      "        [664.,   1.],\n",
      "        [706.,   1.],\n",
      "        [328.,   1.],\n",
      "        [304.,   1.],\n",
      "        [740.,   1.],\n",
      "        [621.,   1.],\n",
      "        [635.,   1.],\n",
      "        [332.,   1.],\n",
      "        [399.,   1.],\n",
      "        [544.,   1.],\n",
      "        [561.,   1.],\n",
      "        [350.,   1.]])\n",
      "tensor([[ 0,  0,  1,  1,  2,  2,  2,  3,  3,  4,  4,  4,  5,  5,  5,  6,  7,  7,\n",
      "          9,  9, 10, 10, 11, 12, 12, 12, 13, 13, 14, 15, 16, 16],\n",
      "        [ 1,  2,  3,  8,  3,  4,  5,  6,  7,  6,  7,  8,  6,  7,  8,  9, 11, 13,\n",
      "         10, 11, 12, 13, 12, 14, 15, 16, 15, 16, 18, 17, 18, 19]])\n",
      "action probs shape torch.Size([20])\n",
      "action probs tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9283e-36,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5105e-30,\n",
      "        9.5913e-38, 8.9390e-28], grad_fn=<SqueezeBackward0>)\n",
      "action mask tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "action mask shape torch.Size([20])\n",
      "action probs after mask shape torch.Size([20])\n",
      "action probs after mask tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9283e-36,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5105e-30,\n",
      "        9.5913e-38, 8.9390e-28], grad_fn=<MulBackward0>)\n",
      "action tensor([19])\n",
      "observation Data(x=[20, 2], edge_index=[2, 32])\n",
      "self.x tensor([[442.,   1.],\n",
      "        [560.,   1.],\n",
      "        [403.,   1.],\n",
      "        [462.,   1.],\n",
      "        [415.,   1.],\n",
      "        [461.,   1.],\n",
      "        [372.,   1.],\n",
      "        [762.,   1.],\n",
      "        [664.,   1.],\n",
      "        [706.,   1.],\n",
      "        [328.,   1.],\n",
      "        [304.,   1.],\n",
      "        [740.,   1.],\n",
      "        [621.,   1.],\n",
      "        [635.,   1.],\n",
      "        [332.,   1.],\n",
      "        [399.,   1.],\n",
      "        [544.,   1.],\n",
      "        [561.,   1.],\n",
      "        [350.,   1.]])\n",
      "self.x shape torch.Size([20, 2])\n",
      "task index tensor([19])\n",
      "self.x[task_index] tensor([[350.,   1.]])\n",
      "action mask tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0.])\n",
      "Env.data Data(x=[20, 2], edge_index=[2, 32])\n",
      "tensor([[442.,   1.],\n",
      "        [560.,   1.],\n",
      "        [403.,   1.],\n",
      "        [462.,   1.],\n",
      "        [415.,   1.],\n",
      "        [461.,   1.],\n",
      "        [372.,   1.],\n",
      "        [762.,   1.],\n",
      "        [664.,   1.],\n",
      "        [706.,   1.],\n",
      "        [328.,   1.],\n",
      "        [304.,   1.],\n",
      "        [740.,   1.],\n",
      "        [621.,   1.],\n",
      "        [635.,   1.],\n",
      "        [332.,   1.],\n",
      "        [399.,   1.],\n",
      "        [544.,   1.],\n",
      "        [561.,   1.],\n",
      "        [350.,   1.]])\n",
      "tensor([[ 0,  0,  1,  1,  2,  2,  2,  3,  3,  4,  4,  4,  5,  5,  5,  6,  7,  7,\n",
      "          9,  9, 10, 10, 11, 12, 12, 12, 13, 13, 14, 15, 16, 16],\n",
      "        [ 1,  2,  3,  8,  3,  4,  5,  6,  7,  6,  7,  8,  6,  7,  8,  9, 11, 13,\n",
      "         10, 11, 12, 13, 12, 14, 15, 16, 15, 16, 18, 17, 18, 19]])\n",
      "action probs shape torch.Size([20])\n",
      "action probs tensor([1.7742e-28, 1.1250e-31, 3.6919e-30, 1.0126e-17, 0.0000e+00, 1.2542e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        1.4931e-33, 2.5435e-33], grad_fn=<SqueezeBackward0>)\n",
      "action mask tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0.])\n",
      "action mask shape torch.Size([20])\n",
      "action probs after mask shape torch.Size([20])\n",
      "action probs after mask tensor([1.7742e-28, 1.1250e-31, 3.6919e-30, 1.0126e-17, 0.0000e+00, 1.2542e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        1.4931e-33, 0.0000e+00], grad_fn=<MulBackward0>)\n",
      "action tensor([3])\n",
      "observation Data(x=[20, 2], edge_index=[2, 32])\n",
      "self.x tensor([[442.,   1.],\n",
      "        [560.,   1.],\n",
      "        [403.,   1.],\n",
      "        [462.,   1.],\n",
      "        [415.,   1.],\n",
      "        [461.,   1.],\n",
      "        [372.,   1.],\n",
      "        [762.,   1.],\n",
      "        [664.,   1.],\n",
      "        [706.,   1.],\n",
      "        [328.,   1.],\n",
      "        [304.,   1.],\n",
      "        [740.,   1.],\n",
      "        [621.,   1.],\n",
      "        [635.,   1.],\n",
      "        [332.,   1.],\n",
      "        [399.,   1.],\n",
      "        [544.,   1.],\n",
      "        [561.,   1.],\n",
      "        [350.,   0.]])\n",
      "self.x shape torch.Size([20, 2])\n",
      "task index tensor([3])\n",
      "self.x[task_index] tensor([[462.,   1.]])\n",
      "action mask tensor([1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0.])\n",
      "Env.data Data(x=[20, 2], edge_index=[2, 32])\n",
      "tensor([[442.,   1.],\n",
      "        [560.,   1.],\n",
      "        [403.,   1.],\n",
      "        [462.,   1.],\n",
      "        [415.,   1.],\n",
      "        [461.,   1.],\n",
      "        [372.,   1.],\n",
      "        [762.,   1.],\n",
      "        [664.,   1.],\n",
      "        [706.,   1.],\n",
      "        [328.,   1.],\n",
      "        [304.,   1.],\n",
      "        [740.,   1.],\n",
      "        [621.,   1.],\n",
      "        [635.,   1.],\n",
      "        [332.,   1.],\n",
      "        [399.,   1.],\n",
      "        [544.,   1.],\n",
      "        [561.,   1.],\n",
      "        [350.,   1.]])\n",
      "tensor([[ 0,  0,  1,  1,  2,  2,  2,  3,  3,  4,  4,  4,  5,  5,  5,  6,  7,  7,\n",
      "          9,  9, 10, 10, 11, 12, 12, 12, 13, 13, 14, 15, 16, 16],\n",
      "        [ 1,  2,  3,  8,  3,  4,  5,  6,  7,  6,  7,  8,  6,  7,  8,  9, 11, 13,\n",
      "         10, 11, 12, 13, 12, 14, 15, 16, 15, 16, 18, 17, 18, 19]])\n",
      "action probs shape torch.Size([20])\n",
      "action probs tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "action mask tensor([1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0.])\n",
      "action mask shape torch.Size([20])\n",
      "action probs after mask shape torch.Size([20])\n",
      "action probs after mask tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid multinomial distribution (sum of probabilities <= 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/ipykernel_23139/3139152125.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0miter_no\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/6v/7nrd1rj91hx3tb4q5npbdf0w0000gn/T/ipykernel_23139/3902982715.py\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(Env, model, device)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#print('action probs shape',action_probs.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#print('action probs',action_probs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid multinomial distribution (sum of probabilities <= 0)"
     ]
    }
   ],
   "source": [
    "Env = Env(instance)\n",
    "episode_steps = []\n",
    "batch = []\n",
    "total_reward = 0.0\n",
    "gamma = 0.99\n",
    "percentile = 70\n",
    "BATCH_SIZE = 5\n",
    "iter_no = 0\n",
    "for i in range(100000):\n",
    "    action = get_action(Env, model)\n",
    "    observation = Env.data.clone()\n",
    "    print('action', action)\n",
    "    print('observation', observation)\n",
    "    reward, end_of_episode = Env.update_state(action)\n",
    "    episode_steps.append(EpisodeStep(observation=observation, action=action))\n",
    "    total_reward += reward\n",
    "    if end_of_episode:\n",
    "        print('end of episode')\n",
    "        batch.append(Episode(total_reward, episode_steps))\n",
    "        episode_steps = []\n",
    "        Env.reset()\n",
    "        total_reward = 0.0\n",
    "        if len(batch) == BATCH_SIZE:\n",
    "            reward_mean = float(np.mean(list(map(lambda s: s.reward, batch))))\n",
    "            disc_rewards = list(map(lambda s: s.reward * (gamma ** len(s.steps)), batch))\n",
    "            reward_bound = np.percentile(disc_rewards, percentile)\n",
    "            elite_candidates =batch\n",
    "            train_obs = []\n",
    "            train_act = []\n",
    "            elite_batch = []\n",
    "            # for example, discounted_reward in zip(batch, disc_rewards):\n",
    "            #     if discounted_reward > reward_bound:\n",
    "            #         train_obs.extend(map(lambda step: step.observation, example.steps))\n",
    "            #         train_act.extend(map(lambda step: step.action, example.steps))\n",
    "            #         elite_batch.append(example)\n",
    "            # full_batch = elite_batch \n",
    "            # states = train_obs\n",
    "            # actions = train_act\n",
    "            # if len(full_batch) != 0 : # just in case empty during an iteration\n",
    "            #             state_t = torch.FloatTensor(states).to(device)\n",
    "            #             acts_t = torch.LongTensor(actions).to(device)\n",
    "            #             optimizer.zero_grad()\n",
    "            #             action_scores_t = model(state_t)\n",
    "            #             loss_t = objective(action_scores_t, acts_t)\n",
    "            #             loss_t.backward()\n",
    "            #             optimizer.step()\n",
    "            #             print(\"%d: loss=%.3f, reward_mean=%.3f\" % (iter_no, loss_t.item(), reward_mean))\n",
    "            #             iter_no += 1\n",
    "            #             batch = []\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones((x.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
